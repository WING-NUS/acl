<?xml version='1.0' encoding='UTF-8'?>
<collection id="2021.sigtyp">
  <volume id="1" ingest-date="2021-05-21">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Computational Typology and Multilingual NLP</booktitle>
      <editor><first>Ekaterina</first><last>Vylomova</last></editor>
      <editor><first>Elizabeth</first><last>Salesky</last></editor>
      <editor><first>Sabrina</first><last>Mielke</last></editor>
      <editor><first>Gabriella</first><last>Lapesa</last></editor>
      <editor><first>Ritesh</first><last>Kumar</last></editor>
      <editor><first>Harald</first><last>Hammarström</last></editor>
      <editor><first>Ivan</first><last>Vulić</last></editor>
      <editor><first>Anna</first><last>Korhonen</last></editor>
      <editor><first>Roi</first><last>Reichart</last></editor>
      <editor><first>Edoardo Maria</first><last>Ponti</last></editor>
      <editor><first>Ryan</first><last>Cotterell</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.sigtyp-1</url>
    </meta>
    <frontmatter>
      <url hash="446be641">2021.sigtyp-1.0</url>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>OTEANN</fixed-case>: Estimating the Transparency of Orthographies with an Artificial Neural Network</title>
      <author><first>Xavier</first><last>Marjou</last></author>
      <pages>1–9</pages>
      <abstract>To transcribe spoken language to written medium, most alphabets enable an unambiguous sound-to-letter rule. However, some writing systems have distanced themselves from this simple concept and little work exists in Natural Language Processing (NLP) on measuring such distance. In this study, we use an Artificial Neural Network (ANN) model to evaluate the transparency between written words and their pronunciation, hence its name Orthographic Transparency Estimation with an ANN (OTEANN). Based on datasets derived from Wikimedia dictionaries, we trained and tested this model to score the percentage of false predictions in phoneme-to-grapheme and grapheme-to-phoneme translation tasks. The scores obtained on 17 orthographies were in line with the estimations of other studies. Interestingly, the model also provided insight into typical mistakes made by learners who only consider the phonemic rule in reading and writing.</abstract>
      <url hash="e6fba9f1">2021.sigtyp-1.1</url>
    </paper>
    <paper id="2">
      <title>Inferring Morphological Complexity from Syntactic Dependency Networks: A Test</title>
      <author><first>Guglielmo</first><last>Inglese</last></author>
      <author><first>Luca</first><last>Brigada Villa</last></author>
      <pages>10–21</pages>
      <abstract>Research in linguistic typology has shown that languages do not fall into the neat morphological types (synthetic vs. analytic) postulated in the 19th century. Instead, analytic and synthetic must be viewed as two poles of a continuum and languages may show a mix analytic and synthetic strategies to different degrees. Unfortunately, empirical studies that offer a more fine-grained morphological classification of languages based on these parameters remain few. In this paper, we build upon previous research by Liu &amp; Xu (2011) and investigate the possibility of inferring information on morphological complexity from syntactic dependency networks.</abstract>
      <url hash="a43dc480">2021.sigtyp-1.2</url>
    </paper>
    <paper id="3">
      <title>A <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies Corpora Maintenance Methodology Using Downstream Application</title>
      <author><first>Ran</first><last>Iwamoto</last></author>
      <author><first>Hiroshi</first><last>Kanayama</last></author>
      <author><first>Alexandre</first><last>Rademaker</last></author>
      <author><first>Takuya</first><last>Ohko</last></author>
      <pages>22–30</pages>
      <abstract>This paper investigates updates of Universal Dependencies (UD) treebanks in 23 languages and their impact on a downstream application. Numerous people are involved in updating UD’s annotation guidelines and treebanks in various languages. However, it is not easy to verify whether the updated resources maintain universality with other language resources. Thus, validity and consistency of multilingual corpora should be tested through application tasks involving syntactic structures with PoS tags, dependency labels, and universal features. We apply the syntactic parsers trained on UD treebanks from multiple versions (2.0 to 2.7) to a clause-level sentiment extractor. We then analyze the relationships between attachment scores of dependency parsers and performance in application tasks. For future UD developments, we show examples of outputs that differ depending on version.</abstract>
      <url hash="bdd6d808">2021.sigtyp-1.3</url>
    </paper>
    <paper id="4">
      <title>Improving Cross-Lingual Sentiment Analysis via Conditional Language Adversarial Nets</title>
      <author><first>Hemanth</first><last>Kandula</last></author>
      <author><first>Bonan</first><last>Min</last></author>
      <pages>31–36</pages>
      <abstract>Sentiment analysis has come a long way for high-resource languages due to the availability of large annotated corpora. However, it still suffers from lack of training data for low-resource languages. To tackle this problem, we propose Conditional Language Adversarial Network (CLAN), an end-to-end neural architecture for cross-lingual sentiment analysis without cross-lingual supervision. CLAN differs from prior work in that it allows the adversarial training to be conditioned on both learned features and the sentiment prediction, to increase discriminativity for learned representation in the cross-lingual setting. Experimental results demonstrate that CLAN outperforms previous methods on the multilingual multi-domain Amazon review dataset. Our source code is released at https://github.com/hemanthkandula/clan.</abstract>
      <url hash="0d0390e3">2021.sigtyp-1.4</url>
    </paper>
    <paper id="5">
      <title>Improving the Performance of <fixed-case>UD</fixed-case>ify with Linguistic Typology Knowledge</title>
      <author><first>Chinmay</first><last>Choudhary</last></author>
      <pages>37–59</pages>
      <abstract>UDify is the state-of-the-art language-agnostic dependency parser which is trained on a polyglot corpus of 75 languages. This multilingual modeling enables the model to generalize over unknown/lesser-known languages, thus leading to improved performance on low-resource languages. In this work we used linguistic typology knowledge available in URIEL database, to improve the cross-lingual transferring ability of UDify even further.</abstract>
      <url hash="12724abd">2021.sigtyp-1.5</url>
    </paper>
    <paper id="6">
      <title><fixed-case>F</fixed-case>rame<fixed-case>N</fixed-case>et and Typology</title>
      <author><first>Michael</first><last>Ellsworth</last></author>
      <author><first>Collin</first><last>Baker</last></author>
      <author><first>Miriam R. L.</first><last>Petruck</last></author>
      <pages>60–65</pages>
      <abstract>FrameNet and the Multilingual FrameNet project have produced multilingual semantic annotations of parallel texts that yield extremely fine-grained typological insights. Moreover, frame semantic annotation of a wide cross-section of languages would provide information on the limits of Frame Semantics (Fillmore 1982, Fillmore1985). Multilingual semantic annotation offers critical input for research on linguistic diversity and recurrent patterns in computational typology. Drawing on results from FrameNet annotation of parallel texts, this paper proposes frame semantic annotation as a new component to complement the state of the art in computational semantic typology.</abstract>
      <url hash="1fa0a3b6">2021.sigtyp-1.6</url>
    </paper>
    <paper id="7">
      <title>Family of Origin and Family of Choice: Massively Parallel Lexiconized Iterative Pretraining for Severely Low Resource Text-based Translation</title>
      <author><first>Zhong</first><last>Zhou</last></author>
      <author><first>Alexander</first><last>Waibel</last></author>
      <pages>66–79</pages>
      <abstract>We translate a closed text that is known in advance into a severely low resource language by leveraging massive source parallelism. In other words, given a text in 124 source languages, we translate it into a severely low resource language using only ∼1,000 lines of low resource data without any external help. Firstly, we propose a systematic method to rank and choose source languages that are close to the low resource language. We call the linguistic definition of language family Family of Origin (FAMO), and we call the empirical definition of higher-ranked languages using our metrics Family of Choice (FAMC). Secondly, we build an Iteratively Pretrained Multilingual Order-preserving Lexiconized Transformer (IPML) to train on ∼1,000 lines (∼3.5%) of low resource data. In order to translate named entities well, we build a massive lexicon table for 2,939 Bible named entities in 124 source languages, and include many that occur once and covers more than 66 severely low resource languages. Moreover, we also build a novel method of combining translations from different source languages into one. Using English as a hypothetical low resource language, we get a +23.9 BLEU increase over a multilingual baseline, and a +10.3 BLEU increase over our asymmetric baseline in the Bible dataset. We get a 42.8 BLEU score for Portuguese-English translation on the medical EMEA dataset. We also have good results for a real severely low resource Mayan language, Eastern Pokomchi.</abstract>
      <url hash="e22d304c">2021.sigtyp-1.7</url>
    </paper>
    <paper id="8">
      <title>Measuring Prefixation and Suffixation in the Languages of the World</title>
      <author><first>Harald</first><last>Hammarström</last></author>
      <pages>80–88</pages>
      <abstract>It has long been recognized that suffixing is more common than prefixing in the languages of the world. More detailed statistics on this tendency are needed to sharpen proposed explanations for this tendency. The classic approach to gathering data on the prefix/suffix preference is for a human to read grammatical descriptions (948 languages), which is time-consuming and involves discretization judgments. In this paper we explore two machine-driven approaches for prefix and suffix statistics which are crude approximations, but have advantages in terms of time and replicability. The first simply searches a large collection of grammatical descriptions for occurrences of the terms ‘prefix’ and ‘suffix’ (4 287 languages). The second counts substrings from raw text data in a way indirectly reflecting prefixation and suffixation (1 030 languages, using New Testament translations). The three approaches largely agree in their measurements but there are important theoretical and practical differences. In all measurements, there is an overall preference for suffixation, albeit only slightly, at ratios ranging between 0.51 and 0.68.</abstract>
      <url hash="d467a867">2021.sigtyp-1.8</url>
    </paper>
    <paper id="9">
      <title>Predicting and Explaining <fixed-case>F</fixed-case>rench Grammatical Gender</title>
      <author><first>Saumya</first><last>Sahai</last></author>
      <author><first>Dravyansh</first><last>Sharma</last></author>
      <pages>89–95</pages>
      <abstract>Grammatical gender may be determined by semantics, orthography, phonology, or could even be arbitrary. Identifying patterns in the factors that govern noun genders can be useful for language learners, and for understanding innate linguistic sources of gender bias. Traditional manual rule-based approaches may be substituted by more accurate and scalable but harder-to-interpret computational approaches for predicting gender from typological information. In this work, we propose interpretable gender classification models for French, which obtain the best of both worlds. We present high accuracy neural approaches which are augmented by a novel global surrogate based approach for explaining predictions. We introduce ‘auxiliary attributes’ to provide tunable explanation complexity.</abstract>
      <url hash="4b90bb0b">2021.sigtyp-1.9</url>
    </paper>
    <paper id="10">
      <title>Morph Call: Probing Morphosyntactic Content of Multilingual Transformers</title>
      <author><first>Vladislav</first><last>Mikhailov</last></author>
      <author><first>Oleg</first><last>Serikov</last></author>
      <author><first>Ekaterina</first><last>Artemova</last></author>
      <pages>96–120</pages>
      <abstract>The outstanding performance of transformer-based language models on a great variety of NLP and NLU tasks has stimulated interest in exploration of their inner workings. Recent research has been primarily focused on higher-level and complex linguistic phenomena such as syntax, semantics, world knowledge and common-sense. The majority of the studies is anglocentric, and little remains known regarding other languages, specifically their morphosyntactic properties. To this end, our work presents Morph Call, a suite of 46 probing tasks for four Indo-European languages of different morphology: Russian, French, English and German. We propose a new type of probing tasks based on detection of guided sentence perturbations. We use a combination of neuron-, layer- and representation-level introspection techniques to analyze the morphosyntactic content of four multilingual transformers, including their understudied distilled versions. Besides, we examine how fine-tuning on POS-tagging task affects the probing performance.</abstract>
      <url hash="f4025f45">2021.sigtyp-1.10</url>
    </paper>
    <paper id="11">
      <title>Language <fixed-case>ID</fixed-case> Prediction from Speech Using Self-Attentive Pooling</title>
      <author><first>Roman</first><last>Bedyakin</last></author>
      <author><first>Nikolay</first><last>Mikhaylovskiy</last></author>
      <pages>121–126</pages>
      <abstract>This memo describes NTR-TSU submission for SIGTYP 2021 Shared Task on predicting language IDs from speech. Spoken Language Identification (LID) is an important step in a multilingual Automated Speech Recognition (ASR) system pipeline. For many low-resource and endangered languages, only single-speaker recordings may be available, demanding a need for domain and speaker-invariant language ID systems. In this memo, we show that a convolutional neural network with a Self-Attentive Pooling layer shows promising results for the language identification task.</abstract>
      <url hash="09e05d81">2021.sigtyp-1.11</url>
    </paper>
    <paper id="12">
      <title>A <fixed-case>R</fixed-case>es<fixed-case>N</fixed-case>et-50-Based Convolutional Neural Network Model for Language <fixed-case>ID</fixed-case> Identification from Speech Recordings</title>
      <author><first>Celano</first><last>Giuseppe</last></author>
      <pages>127–135</pages>
      <abstract>This paper describes the model built for the SIGTYP 2021 Shared Task aimed at identifying 18 typologically different languages from speech recordings. Mel-frequency cepstral coefficients derived from audio files are transformed into spectrograms, which are then fed into a ResNet-50-based CNN architecture. The final model achieved validation and test accuracies of 0.73 and 0.53, respectively.</abstract>
      <url hash="06e5626a">2021.sigtyp-1.12</url>
    </paper>
    <paper id="13">
      <title><fixed-case>SIGTYP</fixed-case> 2021 Shared Task: Robust Spoken Language Identification</title>
      <author><first>Elizabeth</first><last>Salesky</last></author>
      <author><first>Badr M.</first><last>Abdullah</last></author>
      <author><first>Sabrina</first><last>Mielke</last></author>
      <author><first>Elena</first><last>Klyachko</last></author>
      <author><first>Oleg</first><last>Serikov</last></author>
      <author><first>Edoardo Maria</first><last>Ponti</last></author>
      <author><first>Ritesh</first><last>Kumar</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Ekaterina</first><last>Vylomova</last></author>
      <pages>136–142</pages>
      <abstract>While language identification is a fundamental speech and language processing task, for many languages and language families it remains a challenging task. For many low-resource and endangered languages this is in part due to resource availability: where larger datasets exist, they may be single-speaker or have different domains than desired application scenarios, demanding a need for domain and speaker-invariant language identification systems. This year’s shared task on robust spoken language identification sought to investigate just this scenario: systems were to be trained on largely single-speaker speech from one domain, but evaluated on data in other domains recorded from speakers under different recording circumstances, mimicking realistic low-resource scenarios. We see that domain and speaker mismatch proves very challenging for current methods which can perform above 95% accuracy in-domain, which domain adaptation can address to some degree, but that these conditions merit further investigation to make spoken language identification accessible in many scenarios.</abstract>
      <url hash="01269bdd">2021.sigtyp-1.13</url>
    </paper>
  </volume>
</collection>
