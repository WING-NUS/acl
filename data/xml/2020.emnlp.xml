<?xml version='1.0' encoding='UTF-8'?>
<collection id="2020.emnlp">
  <volume id="main" ingest-date="2020-11-05">
    <meta>
      <booktitle>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</booktitle>
      <editor><first>Trevor</first><last>Cohn</last></editor>
      <editor><first>Yulan</first><last>He</last></editor>
      <editor id="yang-liu-icsi"><first>Yang</first><last>Liu</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="42722bc7">2020.emnlp-main.0</url>
    </frontmatter>
    <paper id="1">
      <title>Detecting Attackable Sentences in Arguments</title>
      <author><first>Yohan</first><last>Jo</last></author>
      <author><first>Seojin</first><last>Bang</last></author>
      <author><first>Emaad</first><last>Manzoor</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <author><first>Chris</first><last>Reed</last></author>
      <pages>1–23</pages>
      <url hash="56ee711d">2020.emnlp-main.1</url>
    </paper>
    <paper id="2">
      <title>Extracting Implicitly Asserted Propositions in Argumentation</title>
      <author><first>Yohan</first><last>Jo</last></author>
      <author><first>Jacky</first><last>Visser</last></author>
      <author><first>Chris</first><last>Reed</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>24–38</pages>
      <url hash="78e06e63">2020.emnlp-main.2</url>
    </paper>
    <paper id="3">
      <title>Quantitative Argument Summarization and beyond: Cross-Domain Key Point Analysis</title>
      <author><first>Roy</first><last>Bar-Haim</last></author>
      <author><first>Yoav</first><last>Kantor</last></author>
      <author><first>Lilach</first><last>Eden</last></author>
      <author><first>Roni</first><last>Friedman</last></author>
      <author><first>Dan</first><last>Lahav</last></author>
      <author><first>Noam</first><last>Slonim</last></author>
      <pages>39–49</pages>
      <url hash="a2277112">2020.emnlp-main.3</url>
    </paper>
    <paper id="4">
      <title>Unsupervised Stance Detection for Arguments from Consequences</title>
      <author><first>Jonathan</first><last>Kobbe</last></author>
      <author><first>Ioana</first><last>Hulpuș</last></author>
      <author><first>Heiner</first><last>Stuckenschmidt</last></author>
      <pages>50–60</pages>
      <url hash="b982b14e">2020.emnlp-main.4</url>
    </paper>
    <paper id="5">
      <title><fixed-case>BLEU</fixed-case> Might Be Guilty but References Are Not Innocent</title>
      <author><first>Markus</first><last>Freitag</last></author>
      <author><first>David</first><last>Grangier</last></author>
      <author><first>Isaac</first><last>Caswell</last></author>
      <pages>61–71</pages>
      <url hash="e3d4ce36">2020.emnlp-main.5</url>
    </paper>
    <paper id="6">
      <title>Translationese in Machine Translation Evaluation</title>
      <author><first>Yvette</first><last>Graham</last></author>
      <author><first>Barry</first><last>Haddow</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <pages>72–81</pages>
      <url hash="161257e0">2020.emnlp-main.6</url>
    </paper>
    <paper id="7">
      <title>Simulated Multiple Reference Training Improves Low-Resource Machine Translation</title>
      <author><first>Huda</first><last>Khayrallah</last></author>
      <author><first>Brian</first><last>Thompson</last></author>
      <author><first>Matt</first><last>Post</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <pages>82–89</pages>
      <url hash="36931069">2020.emnlp-main.7</url>
    </paper>
    <paper id="8">
      <title>Automatic Machine Translation Evaluation in Many Languages via Zero-Shot Paraphrasing</title>
      <author><first>Brian</first><last>Thompson</last></author>
      <author><first>Matt</first><last>Post</last></author>
      <pages>90–121</pages>
      <url hash="be078170">2020.emnlp-main.8</url>
    </paper>
    <paper id="9">
      <title><fixed-case>PR</fixed-case>over: Proof Generation for Interpretable Reasoning over Rules</title>
      <author><first>Swarnadeep</first><last>Saha</last></author>
      <author><first>Sayan</first><last>Ghosh</last></author>
      <author><first>Shashank</first><last>Srivastava</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>122–136</pages>
      <url hash="212ed5fc">2020.emnlp-main.9</url>
    </paper>
    <paper id="10">
      <title>Learning to Explain: Datasets and Models for Identifying Valid Reasoning Chains in Multihop Question-Answering</title>
      <author><first>Harsh</first><last>Jhamtani</last></author>
      <author><first>Peter</first><last>Clark</last></author>
      <pages>137–150</pages>
      <url hash="c99468b7">2020.emnlp-main.10</url>
    </paper>
    <paper id="11">
      <title>Self-Supervised Knowledge Triplet Learning for Zero-shot Question Answering</title>
      <author><first>Pratyay</first><last>Banerjee</last></author>
      <author><first>Chitta</first><last>Baral</last></author>
      <pages>151–162</pages>
      <url hash="f583b64a">2020.emnlp-main.11</url>
      <attachment type="OptionalSupplementaryMaterial" hash="7679c305">2020.emnlp-main.11.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="12">
      <title>More Bang for Your Buck: Natural Perturbation for Robust Question Answering</title>
      <author><first>Daniel</first><last>Khashabi</last></author>
      <author><first>Tushar</first><last>Khot</last></author>
      <author><first>Ashish</first><last>Sabharwal</last></author>
      <pages>163–170</pages>
      <url hash="7f37ba04">2020.emnlp-main.12</url>
    </paper>
    <paper id="13">
      <title>A Matter of Framing: The Impact of Linguistic Formalism on Probing Results</title>
      <author><first>Ilia</first><last>Kuznetsov</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>171–182</pages>
      <url hash="4cb9ef26">2020.emnlp-main.13</url>
    </paper>
    <paper id="14">
      <title>Information-Theoretic Probing with Minimum Description Length</title>
      <author><first>Elena</first><last>Voita</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <pages>183–196</pages>
      <url hash="81f67996">2020.emnlp-main.14</url>
    </paper>
    <paper id="15">
      <title>Intrinsic Probing through Dimension Selection</title>
      <author><first>Lucas</first><last>Torroba Hennigen</last></author>
      <author><first>Adina</first><last>Williams</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <pages>197–216</pages>
      <url hash="28aa84f1">2020.emnlp-main.15</url>
    </paper>
    <paper id="16">
      <title>Learning Helpful Inductive Biases from Self-Supervised Pretraining</title>
      <author><first>Alex</first><last>Warstadt</last></author>
      <author><first>Yian</first><last>Zhang</last></author>
      <author><first>Xiaocheng</first><last>Li</last></author>
      <author><first>Haokun</first><last>Liu</last></author>
      <author><first>Samuel R.</first><last>Bowman</last></author>
      <pages>217–235</pages>
      <url hash="a43bc489">2020.emnlp-main.16</url>
    </paper>
    <paper id="17">
      <title>Repulsive Attention: Rethinking Multi-head Attention as <fixed-case>B</fixed-case>ayesian Inference</title>
      <author><first>Bang</first><last>An</last></author>
      <author><first>Jie</first><last>Lyu</last></author>
      <author><first>Zhenyi</first><last>Wang</last></author>
      <author><first>Chunyuan</first><last>Li</last></author>
      <author><first>Changwei</first><last>Hu</last></author>
      <author><first>Fei</first><last>Tan</last></author>
      <author><first>Ruiyi</first><last>Zhang</last></author>
      <author><first>Yifan</first><last>Hu</last></author>
      <author><first>Changyou</first><last>Chen</last></author>
      <pages>236–255</pages>
      <url hash="ef465fb0">2020.emnlp-main.17</url>
    </paper>
    <paper id="18">
      <title><fixed-case>KERMIT</fixed-case>: Complementing Transformer Architectures with Encoders of Explicit Syntactic Interpretations</title>
      <author><first>Fabio Massimo</first><last>Zanzotto</last></author>
      <author><first>Andrea</first><last>Santilli</last></author>
      <author><first>Leonardo</first><last>Ranaldi</last></author>
      <author><first>Dario</first><last>Onorati</last></author>
      <author><first>Pierfrancesco</first><last>Tommasino</last></author>
      <author><first>Francesca</first><last>Fallucchi</last></author>
      <pages>256–267</pages>
      <url hash="04f9f607">2020.emnlp-main.18</url>
    </paper>
    <paper id="19">
      <title><fixed-case>ETC</fixed-case>: Encoding Long and Structured Inputs in Transformers</title>
      <author><first>Joshua</first><last>Ainslie</last></author>
      <author><first>Santiago</first><last>Ontanon</last></author>
      <author><first>Chris</first><last>Alberti</last></author>
      <author><first>Vaclav</first><last>Cvicek</last></author>
      <author><first>Zachary</first><last>Fisher</last></author>
      <author><first>Philip</first><last>Pham</last></author>
      <author><first>Anirudh</first><last>Ravula</last></author>
      <author><first>Sumit</first><last>Sanghai</last></author>
      <author><first>Qifan</first><last>Wang</last></author>
      <author><first>Li</first><last>Yang</last></author>
      <pages>268–284</pages>
      <url hash="55fd0e08">2020.emnlp-main.19</url>
    </paper>
    <paper id="20">
      <title>Pre-Training Transformers as Energy-Based Cloze Models</title>
      <author><first>Kevin</first><last>Clark</last></author>
      <author><first>Minh-Thang</first><last>Luong</last></author>
      <author><first>Quoc</first><last>Le</last></author>
      <author><first>Christopher D.</first><last>Manning</last></author>
      <pages>285–294</pages>
      <url hash="5ca72728">2020.emnlp-main.20</url>
    </paper>
    <paper id="21">
      <title>Calibration of Pre-trained Transformers</title>
      <author><first>Shrey</first><last>Desai</last></author>
      <author><first>Greg</first><last>Durrett</last></author>
      <pages>295–302</pages>
      <url hash="71284959">2020.emnlp-main.21</url>
    </paper>
    <paper id="22">
      <title>Near-imperceptible Neural Linguistic Steganography via Self-Adjusting Arithmetic Coding</title>
      <author><first>Jiaming</first><last>Shen</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <pages>303–313</pages>
      <url hash="8b2e85a9">2020.emnlp-main.22</url>
    </paper>
    <paper id="23">
      <title>Multi-Dimensional Gender Bias Classification</title>
      <author><first>Emily</first><last>Dinan</last></author>
      <author><first>Angela</first><last>Fan</last></author>
      <author><first>Ledell</first><last>Wu</last></author>
      <author><first>Jason</first><last>Weston</last></author>
      <author><first>Douwe</first><last>Kiela</last></author>
      <author><first>Adina</first><last>Williams</last></author>
      <pages>314–331</pages>
      <url hash="7008b295">2020.emnlp-main.23</url>
    </paper>
    <paper id="24">
      <title>Human-in-the-loop Debugging Deep Text Classifiers</title>
      <author><first>Piyawat</first><last>Lertvittayakumjorn</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <author><first>Francesca</first><last>Toni</last></author>
      <pages>332–348</pages>
      <url hash="a48e4abe">2020.emnlp-main.24</url>
    </paper>
    <paper id="25">
      <title>Conversational Document Prediction to Assist Customer Care Agents</title>
      <author><first>Jatin</first><last>Ganhotra</last></author>
      <author><first>Haggai</first><last>Roitman</last></author>
      <author><first>Doron</first><last>Cohen</last></author>
      <author><first>Nathaniel</first><last>Mills</last></author>
      <author><first>Chulaka</first><last>Gunasekara</last></author>
      <author><first>Yosi</first><last>Mass</last></author>
      <author><first>Sachindra</first><last>Joshi</last></author>
      <author><first>Luis</first><last>Lastras</last></author>
      <author><first>David</first><last>Konopnicki</last></author>
      <pages>349–356</pages>
      <url hash="98869d7b">2020.emnlp-main.25</url>
    </paper>
    <paper id="26">
      <title>Incremental Processing in the Age of Non-Incremental Encoders: An Empirical Assessment of Bidirectional Models for Incremental <fixed-case>NLU</fixed-case></title>
      <author><first>Brielen</first><last>Madureira</last></author>
      <author><first>David</first><last>Schlangen</last></author>
      <pages>357–374</pages>
      <url hash="09d22bbc">2020.emnlp-main.26</url>
    </paper>
    <paper id="27">
      <title>Augmented Natural Language for Generative Sequence Labeling</title>
      <author><first>Ben</first><last>Athiwaratkun</last></author>
      <author><first>Cicero</first><last>Nogueira dos Santos</last></author>
      <author><first>Jason</first><last>Krone</last></author>
      <author><first>Bing</first><last>Xiang</last></author>
      <pages>375–385</pages>
      <url hash="91001c09">2020.emnlp-main.27</url>
    </paper>
    <paper id="28">
      <title>Dialogue Response Ranking Training with Large-Scale Human Feedback Data</title>
      <author><first>Xiang</first><last>Gao</last></author>
      <author><first>Yizhe</first><last>Zhang</last></author>
      <author><first>Michel</first><last>Galley</last></author>
      <author><first>Chris</first><last>Brockett</last></author>
      <author><first>Bill</first><last>Dolan</last></author>
      <pages>386–395</pages>
      <url hash="070d32a4">2020.emnlp-main.28</url>
    </paper>
    <paper id="29">
      <title>Semantic Evaluation for Text-to-<fixed-case>SQL</fixed-case> with Distilled Test Suite</title>
      <author><first>Ruiqi</first><last>Zhong</last></author>
      <author><first>Tao</first><last>Yu</last></author>
      <author><first>Dan</first><last>Klein</last></author>
      <pages>396–411</pages>
      <url hash="dfb95249">2020.emnlp-main.29</url>
    </paper>
    <paper id="30">
      <title>Cross-Thought for Sentence Encoder Pre-training</title>
      <author><first>Shuohang</first><last>Wang</last></author>
      <author><first>Yuwei</first><last>Fang</last></author>
      <author><first>Siqi</first><last>Sun</last></author>
      <author><first>Zhe</first><last>Gan</last></author>
      <author><first>Yu</first><last>Cheng</last></author>
      <author><first>Jingjing</first><last>Liu</last></author>
      <author><first>Jing</first><last>Jiang</last></author>
      <pages>412–421</pages>
      <url hash="e8ac1ccb">2020.emnlp-main.30</url>
    </paper>
    <paper id="31">
      <title><fixed-case>A</fixed-case>uto<fixed-case>QA</fixed-case>: From Databases to <fixed-case>Q</fixed-case>&amp;<fixed-case>A</fixed-case> Semantic Parsers with Only Synthetic Training Data</title>
      <author><first>Silei</first><last>Xu</last></author>
      <author><first>Sina</first><last>Semnani</last></author>
      <author><first>Giovanni</first><last>Campagna</last></author>
      <author><first>Monica</first><last>Lam</last></author>
      <pages>422–434</pages>
      <url hash="d7970de5">2020.emnlp-main.31</url>
    </paper>
    <paper id="32">
      <title>A Spectral Method for Unsupervised Multi-Document Summarization</title>
      <author><first>Kexiang</first><last>Wang</last></author>
      <author><first>Baobao</first><last>Chang</last></author>
      <author><first>Zhifang</first><last>Sui</last></author>
      <pages>435–445</pages>
      <url hash="561adbc2">2020.emnlp-main.32</url>
    </paper>
    <paper id="33">
      <title>What Have We Achieved on Text Summarization?</title>
      <author><first>Dandan</first><last>Huang</last></author>
      <author><first>Leyang</first><last>Cui</last></author>
      <author><first>Sen</first><last>Yang</last></author>
      <author><first>Guangsheng</first><last>Bao</last></author>
      <author><first>Kun</first><last>Wang</last></author>
      <author><first>Jun</first><last>Xie</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>446–469</pages>
      <url hash="391272d7">2020.emnlp-main.33</url>
    </paper>
    <paper id="34">
      <title><fixed-case>Q</fixed-case>-learning with Language Model for Edit-based Unsupervised Summarization</title>
      <author><first>Ryosuke</first><last>Kohita</last></author>
      <author><first>Akifumi</first><last>Wachi</last></author>
      <author><first>Yang</first><last>Zhao</last></author>
      <author><first>Ryuki</first><last>Tachibana</last></author>
      <pages>470–484</pages>
      <url hash="32ea6a2d">2020.emnlp-main.34</url>
    </paper>
    <paper id="35">
      <title>Friendly Topic Assistant for Transformer Based Abstractive Summarization</title>
      <author><first>Zhengjue</first><last>Wang</last></author>
      <author><first>Zhibin</first><last>Duan</last></author>
      <author><first>Hao</first><last>Zhang</last></author>
      <author><first>Chaojie</first><last>Wang</last></author>
      <author><first>Long</first><last>Tian</last></author>
      <author><first>Bo</first><last>Chen</last></author>
      <author><first>Mingyuan</first><last>Zhou</last></author>
      <pages>485–497</pages>
      <url hash="69bf5008">2020.emnlp-main.35</url>
    </paper>
    <paper id="36">
      <title>Contrastive Distillation on Intermediate Representations for Language Model Compression</title>
      <author><first>Siqi</first><last>Sun</last></author>
      <author><first>Zhe</first><last>Gan</last></author>
      <author><first>Yuwei</first><last>Fang</last></author>
      <author><first>Yu</first><last>Cheng</last></author>
      <author><first>Shuohang</first><last>Wang</last></author>
      <author><first>Jingjing</first><last>Liu</last></author>
      <pages>498–508</pages>
      <url hash="0b1aeb8d">2020.emnlp-main.36</url>
    </paper>
    <paper id="37">
      <title><fixed-case>T</fixed-case>ernary<fixed-case>BERT</fixed-case>: Distillation-aware Ultra-low Bit <fixed-case>BERT</fixed-case></title>
      <author><first>Wei</first><last>Zhang</last></author>
      <author><first>Lu</first><last>Hou</last></author>
      <author><first>Yichun</first><last>Yin</last></author>
      <author><first>Lifeng</first><last>Shang</last></author>
      <author><first>Xiao</first><last>Chen</last></author>
      <author><first>Xin</first><last>Jiang</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <pages>509–521</pages>
      <url hash="b1927905">2020.emnlp-main.37</url>
    </paper>
    <paper id="38">
      <title>Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks</title>
      <author><first>Trapit</first><last>Bansal</last></author>
      <author><first>Rishikesh</first><last>Jha</last></author>
      <author><first>Tsendsuren</first><last>Munkhdalai</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>522–534</pages>
      <url hash="7f1b3a1e">2020.emnlp-main.38</url>
    </paper>
    <paper id="39">
      <title>Efficient Meta Lifelong-Learning with Limited Memory</title>
      <author><first>Zirui</first><last>Wang</last></author>
      <author><first>Sanket Vaibhav</first><last>Mehta</last></author>
      <author><first>Barnabas</first><last>Poczos</last></author>
      <author><first>Jaime</first><last>Carbonell</last></author>
      <pages>535–548</pages>
      <url hash="23abf29b">2020.emnlp-main.39</url>
    </paper>
    <paper id="40">
      <title>On the Evaluation of Contextual Embeddings for Zero-Shot Cross-Lingual Transfer Learning</title>
      <author><first>Phillip</first><last>Keung</last></author>
      <author><first>Yichao</first><last>Lu</last></author>
      <author><first>Julian</first><last>Salazar</last></author>
      <author><first>Vikas</first><last>Bhardwaj</last></author>
      <pages>549–554</pages>
      <url hash="d8a66088">2020.emnlp-main.40</url>
    </paper>
    <paper id="41">
      <title>A Supervised Word Alignment Method Based on Cross-Language Span Prediction Using Multilingual <fixed-case>BERT</fixed-case></title>
      <author><first>Masaaki</first><last>Nagata</last></author>
      <author><first>Katsuki</first><last>Chousa</last></author>
      <author><first>Masaaki</first><last>Nishino</last></author>
      <pages>555–565</pages>
      <url hash="41c0e923">2020.emnlp-main.41</url>
    </paper>
    <paper id="42">
      <title>Accurate Word Alignment Induction from Neural Machine Translation</title>
      <author><first>Yun</first><last>Chen</last></author>
      <author id="yang-liu-ict"><first>Yang</first><last>Liu</last></author>
      <author><first>Guanhua</first><last>Chen</last></author>
      <author><first>Xin</first><last>Jiang</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <pages>566–576</pages>
      <url hash="d66661ae">2020.emnlp-main.42</url>
    </paper>
    <paper id="43">
      <title><fixed-case>C</fixed-case>hr<fixed-case>E</fixed-case>n: <fixed-case>C</fixed-case>herokee-<fixed-case>E</fixed-case>nglish Machine Translation for Endangered Language Revitalization</title>
      <author><first>Shiyue</first><last>Zhang</last></author>
      <author><first>Benjamin</first><last>Frey</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>577–595</pages>
      <url hash="ee026e0c">2020.emnlp-main.43</url>
    </paper>
    <paper id="44">
      <title>Unsupervised Discovery of Implicit Gender Bias</title>
      <author><first>Anjalie</first><last>Field</last></author>
      <author><first>Yulia</first><last>Tsvetkov</last></author>
      <pages>596–608</pages>
      <url hash="c723d291">2020.emnlp-main.44</url>
    </paper>
    <paper id="45">
      <title>Condolences and Empathy in Online Communities</title>
      <author><first>Naitian</first><last>Zhou</last></author>
      <author><first>David</first><last>Jurgens</last></author>
      <pages>609–626</pages>
      <url hash="c3e54d51">2020.emnlp-main.45</url>
    </paper>
    <paper id="46">
      <title>An Embedding Model for Estimating Legislative Preferences from the Frequency and Sentiment of Tweets</title>
      <author><first>Gregory</first><last>Spell</last></author>
      <author><first>Brian</first><last>Guay</last></author>
      <author><first>Sunshine</first><last>Hillygus</last></author>
      <author><first>Lawrence</first><last>Carin</last></author>
      <pages>627–641</pages>
      <url hash="5c2571c2">2020.emnlp-main.46</url>
    </paper>
    <paper id="47">
      <title>Measuring Information Propagation in Literary Social Networks</title>
      <author><first>Matthew</first><last>Sims</last></author>
      <author><first>David</first><last>Bamman</last></author>
      <pages>642–652</pages>
      <url hash="7f8943fb">2020.emnlp-main.47</url>
    </paper>
    <paper id="48">
      <title>Social Chemistry 101: Learning to Reason about Social and Moral Norms</title>
      <author><first>Maxwell</first><last>Forbes</last></author>
      <author><first>Jena D.</first><last>Hwang</last></author>
      <author><first>Vered</first><last>Shwartz</last></author>
      <author><first>Maarten</first><last>Sap</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>653–670</pages>
      <url hash="cf589137">2020.emnlp-main.48</url>
    </paper>
    <paper id="49">
      <title>Event Extraction by Answering (Almost) Natural Questions</title>
      <author><first>Xinya</first><last>Du</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <pages>671–683</pages>
      <url hash="a74a1776">2020.emnlp-main.49</url>
    </paper>
    <paper id="50">
      <title>Connecting the Dots: Event Graph Schema Induction with Path Language Modeling</title>
      <author><first>Manling</first><last>Li</last></author>
      <author><first>Qi</first><last>Zeng</last></author>
      <author><first>Ying</first><last>Lin</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Jonathan</first><last>May</last></author>
      <author><first>Nathanael</first><last>Chambers</last></author>
      <author><first>Clare</first><last>Voss</last></author>
      <pages>684–695</pages>
      <url hash="29d1aba4">2020.emnlp-main.50</url>
    </paper>
    <paper id="51">
      <title>Joint Constrained Learning for Event-Event Relation Extraction</title>
      <author><first>Haoyu</first><last>Wang</last></author>
      <author><first>Muhao</first><last>Chen</last></author>
      <author><first>Hongming</first><last>Zhang</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>696–706</pages>
      <url hash="be31566e">2020.emnlp-main.51</url>
    </paper>
    <paper id="52">
      <title>Incremental Event Detection via Knowledge Consolidation Networks</title>
      <author><first>Pengfei</first><last>Cao</last></author>
      <author><first>Yubo</first><last>Chen</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Taifeng</first><last>Wang</last></author>
      <pages>707–717</pages>
      <url hash="505df92b">2020.emnlp-main.52</url>
    </paper>
    <paper id="53">
      <title>Semi-supervised New Event Type Induction and Event Detection</title>
      <author><first>Lifu</first><last>Huang</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <pages>718–724</pages>
      <url hash="14d0f319">2020.emnlp-main.53</url>
    </paper>
    <paper id="54">
      <title>Language Generation with Multi-hop Reasoning on Commonsense Knowledge Graph</title>
      <author><first>Haozhe</first><last>Ji</last></author>
      <author><first>Pei</first><last>Ke</last></author>
      <author><first>Shaohan</first><last>Huang</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Xiaoyan</first><last>Zhu</last></author>
      <author><first>Minlie</first><last>Huang</last></author>
      <pages>725–736</pages>
      <url hash="9731ba81">2020.emnlp-main.54</url>
    </paper>
    <paper id="55">
      <title>Reformulating Unsupervised Style Transfer as Paraphrase Generation</title>
      <author><first>Kalpesh</first><last>Krishna</last></author>
      <author><first>John</first><last>Wieting</last></author>
      <author><first>Mohit</first><last>Iyyer</last></author>
      <pages>737–762</pages>
      <url hash="4f54696c">2020.emnlp-main.55</url>
      <attachment type="OptionalSupplementaryMaterial" hash="967f527c">2020.emnlp-main.55.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="56">
      <title>De-biased Court’s View Generation with Causality</title>
      <author><first>Yiquan</first><last>Wu</last></author>
      <author><first>Kun</first><last>Kuang</last></author>
      <author><first>Yating</first><last>Zhang</last></author>
      <author><first>Xiaozhong</first><last>Liu</last></author>
      <author><first>Changlong</first><last>Sun</last></author>
      <author><first>Jun</first><last>Xiao</last></author>
      <author><first>Yueting</first><last>Zhuang</last></author>
      <author><first>Luo</first><last>Si</last></author>
      <author><first>Fei</first><last>Wu</last></author>
      <pages>763–780</pages>
      <url hash="1f70b3c4">2020.emnlp-main.56</url>
      <attachment type="OptionalSupplementaryMaterial" hash="9fc1f3c0">2020.emnlp-main.56.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="57">
      <title><fixed-case>PAIR</fixed-case>: Planning and Iterative Refinement in Pre-trained Transformers for Long Text Generation</title>
      <author><first>Xinyu</first><last>Hua</last></author>
      <author><first>Lu</first><last>Wang</last></author>
      <pages>781–793</pages>
      <url hash="b4bd484b">2020.emnlp-main.57</url>
      <attachment type="OptionalSupplementaryMaterial" hash="f1e6e5cd">2020.emnlp-main.57.OptionalSupplementaryMaterial.pdf</attachment>
    </paper>
    <paper id="58">
      <title>Backpropagation-based Decoding for Unsupervised Counterfactual and Abductive Reasoning</title>
      <author><first>Lianhui</first><last>Qin</last></author>
      <author><first>Vered</first><last>Shwartz</last></author>
      <author><first>Peter</first><last>West</last></author>
      <author><first>Chandra</first><last>Bhagavatula</last></author>
      <author><first>Jena D.</first><last>Hwang</last></author>
      <author><first>Ronan</first><last>Le Bras</last></author>
      <author><first>Antoine</first><last>Bosselut</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>794–805</pages>
      <url hash="2a376b34">2020.emnlp-main.58</url>
      <attachment type="OptionalSupplementaryMaterial" hash="44d382a5">2020.emnlp-main.58.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="59">
      <title>Where Are You? Localization from Embodied Dialog</title>
      <author><first>Meera</first><last>Hahn</last></author>
      <author><first>Jacob</first><last>Krantz</last></author>
      <author><first>Dhruv</first><last>Batra</last></author>
      <author><first>Devi</first><last>Parikh</last></author>
      <author><first>James</first><last>Rehg</last></author>
      <author><first>Stefan</first><last>Lee</last></author>
      <author><first>Peter</first><last>Anderson</last></author>
      <pages>806–822</pages>
      <url hash="c88c1981">2020.emnlp-main.59</url>
    </paper>
    <paper id="60">
      <title>Learning to Represent Image and Text with Denotation Graphs</title>
      <author><first>Bowen</first><last>Zhang</last></author>
      <author><first>Hexiang</first><last>Hu</last></author>
      <author><first>Vihan</first><last>Jain</last></author>
      <author><first>Eugene</first><last>Ie</last></author>
      <author><first>Fei</first><last>Sha</last></author>
      <pages>823–839</pages>
      <url hash="e613342b">2020.emnlp-main.60</url>
    </paper>
    <paper id="61">
      <title><fixed-case>V</fixed-case>ideo2<fixed-case>C</fixed-case>ommonsense: Generating Commonsense Descriptions to Enrich Video Captioning</title>
      <author><first>Zhiyuan</first><last>Fang</last></author>
      <author><first>Tejas</first><last>Gokhale</last></author>
      <author><first>Pratyay</first><last>Banerjee</last></author>
      <author><first>Chitta</first><last>Baral</last></author>
      <author><first>Yezhou</first><last>Yang</last></author>
      <pages>840–860</pages>
      <url hash="31f9091b">2020.emnlp-main.61</url>
    </paper>
    <paper id="62">
      <title>Does My Multimodal Model Learn Cross-modal Interactions? It’s Harder to Tell than You Might Think!</title>
      <author><first>Jack</first><last>Hessel</last></author>
      <author><first>Lillian</first><last>Lee</last></author>
      <pages>861–877</pages>
      <url hash="b2f80cc8">2020.emnlp-main.62</url>
      <attachment type="OptionalSupplementaryMaterial" hash="6876bced">2020.emnlp-main.62.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="63">
      <title><fixed-case>MUTANT</fixed-case>: A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering</title>
      <author><first>Tejas</first><last>Gokhale</last></author>
      <author><first>Pratyay</first><last>Banerjee</last></author>
      <author><first>Chitta</first><last>Baral</last></author>
      <author><first>Yezhou</first><last>Yang</last></author>
      <pages>878–892</pages>
      <url hash="d6912735">2020.emnlp-main.63</url>
    </paper>
    <paper id="64">
      <title>Mitigating Gender Bias for Neural Dialogue Generation with Adversarial Learning</title>
      <author><first>Haochen</first><last>Liu</last></author>
      <author><first>Wentao</first><last>Wang</last></author>
      <author><first>Yiqi</first><last>Wang</last></author>
      <author><first>Hui</first><last>Liu</last></author>
      <author><first>Zitao</first><last>Liu</last></author>
      <author><first>Jiliang</first><last>Tang</last></author>
      <pages>893–903</pages>
      <url hash="71964d1d">2020.emnlp-main.64</url>
    </paper>
    <paper id="65">
      <title>Will <fixed-case>I</fixed-case> Sound like Me? Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness</title>
      <author><first>Hyunwoo</first><last>Kim</last></author>
      <author><first>Byeongchang</first><last>Kim</last></author>
      <author><first>Gunhee</first><last>Kim</last></author>
      <pages>904–916</pages>
      <url hash="22a0adcc">2020.emnlp-main.65</url>
    </paper>
    <paper id="66">
      <title><fixed-case>TOD</fixed-case>-<fixed-case>BERT</fixed-case>: Pre-trained Natural Language Understanding for Task-Oriented Dialogue</title>
      <author><first>Chien-Sheng</first><last>Wu</last></author>
      <author><first>Steven C.H.</first><last>Hoi</last></author>
      <author><first>Richard</first><last>Socher</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <pages>917–929</pages>
      <url hash="7147fe0a">2020.emnlp-main.66</url>
    </paper>
    <paper id="67">
      <title><fixed-case>R</fixed-case>i<fixed-case>SAWOZ</fixed-case>: A Large-Scale Multi-Domain <fixed-case>W</fixed-case>izard-of-<fixed-case>O</fixed-case>z Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling</title>
      <author><first>Jun</first><last>Quan</last></author>
      <author><first>Shian</first><last>Zhang</last></author>
      <author><first>Qian</first><last>Cao</last></author>
      <author><first>Zizhong</first><last>Li</last></author>
      <author><first>Deyi</first><last>Xiong</last></author>
      <pages>930–940</pages>
      <url hash="aac30b8d">2020.emnlp-main.67</url>
    </paper>
    <paper id="68">
      <title>Filtering Noisy Dialogue Corpora by Connectivity and Content Relatedness</title>
      <author><first>Reina</first><last>Akama</last></author>
      <author><first>Sho</first><last>Yokoi</last></author>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>941–958</pages>
      <url hash="3c4475a7">2020.emnlp-main.68</url>
    </paper>
    <paper id="69">
      <title>Latent Geographical Factors for Analyzing the Evolution of Dialects in Contact</title>
      <author><first>Yugo</first><last>Murawaki</last></author>
      <pages>959–976</pages>
      <url hash="d479758d">2020.emnlp-main.69</url>
    </paper>
    <paper id="70">
      <title>Predicting Reference: What Do Language Models Learn about Discourse Models?</title>
      <author><first>Shiva</first><last>Upadhye</last></author>
      <author><first>Leon</first><last>Bergen</last></author>
      <author><first>Andrew</first><last>Kehler</last></author>
      <pages>977–982</pages>
      <url hash="4128f0ea">2020.emnlp-main.70</url>
    </paper>
    <paper id="71">
      <title>Word Class Flexibility: A Deep Contextualized Approach</title>
      <author><first>Bai</first><last>Li</last></author>
      <author><first>Guillaume</first><last>Thomas</last></author>
      <author><first>Yang</first><last>Xu</last></author>
      <author><first>Frank</first><last>Rudzicz</last></author>
      <pages>983–994</pages>
      <url hash="17861e64">2020.emnlp-main.71</url>
    </paper>
    <paper id="72">
      <title>Shallow-to-Deep Training for Neural Machine Translation</title>
      <author><first>Bei</first><last>Li</last></author>
      <author><first>Ziyang</first><last>Wang</last></author>
      <author><first>Hui</first><last>Liu</last></author>
      <author><first>Yufan</first><last>Jiang</last></author>
      <author><first>Quan</first><last>Du</last></author>
      <author><first>Tong</first><last>Xiao</last></author>
      <author><first>Huizhen</first><last>Wang</last></author>
      <author><first>Jingbo</first><last>Zhu</last></author>
      <pages>995–1005</pages>
      <url hash="d7c2e63b">2020.emnlp-main.72</url>
    </paper>
    <paper id="73">
      <title>Iterative Refinement in the Continuous Space for Non-Autoregressive Neural Machine Translation</title>
      <author><first>Jason</first><last>Lee</last></author>
      <author><first>Raphael</first><last>Shu</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <pages>1006–1015</pages>
      <url hash="388e5082">2020.emnlp-main.73</url>
      <attachment type="OptionalSupplementaryMaterial" hash="644e174b">2020.emnlp-main.73.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="74">
      <title>Why Skip If You Can Combine: A Simple Knowledge Distillation Technique for Intermediate Layers</title>
      <author><first>Yimeng</first><last>Wu</last></author>
      <author><first>Peyman</first><last>Passban</last></author>
      <author><first>Mehdi</first><last>Rezagholizadeh</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <pages>1016–1021</pages>
      <url hash="88af6da2">2020.emnlp-main.74</url>
    </paper>
    <paper id="75">
      <title>Multi-task Learning for Multilingual Neural Machine Translation</title>
      <author><first>Yiren</first><last>Wang</last></author>
      <author><first>ChengXiang</first><last>Zhai</last></author>
      <author><first>Hany</first><last>Hassan</last></author>
      <pages>1022–1034</pages>
      <url hash="c6fd6694">2020.emnlp-main.75</url>
    </paper>
    <paper id="76">
      <title>Token-level Adaptive Training for Neural Machine Translation</title>
      <author><first>Shuhao</first><last>Gu</last></author>
      <author><first>Jinchao</first><last>Zhang</last></author>
      <author><first>Fandong</first><last>Meng</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <author><first>Wanying</first><last>Xie</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <author><first>Dong</first><last>Yu</last></author>
      <pages>1035–1046</pages>
      <url hash="3986c73c">2020.emnlp-main.76</url>
    </paper>
    <paper id="77">
      <title>Multi-Unit Transformers for Neural Machine Translation</title>
      <author><first>Jianhao</first><last>Yan</last></author>
      <author><first>Fandong</first><last>Meng</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>1047–1059</pages>
      <url hash="3cfd6562">2020.emnlp-main.77</url>
    </paper>
    <paper id="78">
      <title>On the Sparsity of Neural Machine Translation Models</title>
      <author><first>Yong</first><last>Wang</last></author>
      <author><first>Longyue</first><last>Wang</last></author>
      <author><first>Victor</first><last>Li</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <pages>1060–1066</pages>
      <url hash="924cd68c">2020.emnlp-main.78</url>
    </paper>
    <paper id="79">
      <title>Incorporating a Local Translation Mechanism into Non-autoregressive Translation</title>
      <author><first>Xiang</first><last>Kong</last></author>
      <author><first>Zhisong</first><last>Zhang</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>1067–1073</pages>
      <url hash="387b7896">2020.emnlp-main.79</url>
    </paper>
    <paper id="80">
      <title>Self-Paced Learning for Neural Machine Translation</title>
      <author><first>Yu</first><last>Wan</last></author>
      <author><first>Baosong</first><last>Yang</last></author>
      <author><first>Derek F.</first><last>Wong</last></author>
      <author><first>Yikai</first><last>Zhou</last></author>
      <author><first>Lidia S.</first><last>Chao</last></author>
      <author><first>Haibo</first><last>Zhang</last></author>
      <author><first>Boxing</first><last>Chen</last></author>
      <pages>1074–1080</pages>
      <url hash="12c09e6d">2020.emnlp-main.80</url>
    </paper>
    <paper id="81">
      <title>Long-Short Term Masking Transformer: A Simple but Effective Baseline for Document-level Neural Machine Translation</title>
      <author><first>Pei</first><last>Zhang</last></author>
      <author><first>Boxing</first><last>Chen</last></author>
      <author><first>Niyu</first><last>Ge</last></author>
      <author><first>Kai</first><last>Fan</last></author>
      <pages>1081–1087</pages>
      <url hash="4b5418b7">2020.emnlp-main.81</url>
      <attachment type="OptionalSupplementaryMaterial" hash="a52fdfe5">2020.emnlp-main.81.OptionalSupplementaryMaterial.pdf</attachment>
    </paper>
    <paper id="82">
      <title>Generating Diverse Translation from Model Distribution with Dropout</title>
      <author><first>Xuanfu</first><last>Wu</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <author><first>Chenze</first><last>Shao</last></author>
      <pages>1088–1097</pages>
      <url hash="dab3a4ff">2020.emnlp-main.82</url>
    </paper>
    <paper id="83">
      <title>Non-Autoregressive Machine Translation with Latent Alignments</title>
      <author><first>Chitwan</first><last>Saharia</last></author>
      <author><first>William</first><last>Chan</last></author>
      <author><first>Saurabh</first><last>Saxena</last></author>
      <author><first>Mohammad</first><last>Norouzi</last></author>
      <pages>1098–1108</pages>
      <url hash="b3dd4408">2020.emnlp-main.83</url>
    </paper>
    <paper id="84">
      <title>Look at the First Sentence: Position Bias in Question Answering</title>
      <author><first>Miyoung</first><last>Ko</last></author>
      <author><first>Jinhyuk</first><last>Lee</last></author>
      <author><first>Hyunjae</first><last>Kim</last></author>
      <author><first>Gangwoo</first><last>Kim</last></author>
      <author><first>Jaewoo</first><last>Kang</last></author>
      <pages>1109–1121</pages>
      <url hash="a72e5c03">2020.emnlp-main.84</url>
    </paper>
    <paper id="85">
      <title><fixed-case>P</fixed-case>roto<fixed-case>QA</fixed-case>: A Question Answering Dataset for Prototypical Common-Sense Reasoning</title>
      <author><first>Michael</first><last>Boratko</last></author>
      <author><first>Xiang</first><last>Li</last></author>
      <author><first>Tim</first><last>O’Gorman</last></author>
      <author><first>Rajarshi</first><last>Das</last></author>
      <author><first>Dan</first><last>Le</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>1122–1136</pages>
      <url hash="e9d189b9">2020.emnlp-main.85</url>
      <attachment type="OptionalSupplementaryMaterial" hash="a5238d6e">2020.emnlp-main.85.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="86">
      <title><fixed-case>IIRC</fixed-case>: A Dataset of Incomplete Information Reading Comprehension Questions</title>
      <author><first>James</first><last>Ferguson</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last></author>
      <author><first>Tushar</first><last>Khot</last></author>
      <author><first>Pradeep</first><last>Dasigi</last></author>
      <pages>1137–1147</pages>
      <url hash="c9e426b2">2020.emnlp-main.86</url>
    </paper>
    <paper id="87">
      <title>Unsupervised Adaptation of Question Answering Systems via Generative Self-training</title>
      <author><first>Steven</first><last>Rennie</last></author>
      <author><first>Etienne</first><last>Marcheret</last></author>
      <author><first>Neil</first><last>Mallinar</last></author>
      <author><first>David</first><last>Nahamoo</last></author>
      <author><first>Vaibhava</first><last>Goel</last></author>
      <pages>1148–1157</pages>
      <url hash="a9557fcb">2020.emnlp-main.87</url>
    </paper>
    <paper id="88">
      <title><fixed-case>TORQUE</fixed-case>: A Reading Comprehension Dataset of Temporal Ordering Questions</title>
      <author><first>Qiang</first><last>Ning</last></author>
      <author><first>Hao</first><last>Wu</last></author>
      <author><first>Rujun</first><last>Han</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>1158–1172</pages>
      <url hash="2bf1ce46">2020.emnlp-main.88</url>
    </paper>
    <paper id="89">
      <title><fixed-case>T</fixed-case>o<fixed-case>TT</fixed-case>o: A Controlled Table-To-Text Generation Dataset</title>
      <author><first>Ankur</first><last>Parikh</last></author>
      <author><first>Xuezhi</first><last>Wang</last></author>
      <author><first>Sebastian</first><last>Gehrmann</last></author>
      <author><first>Manaal</first><last>Faruqui</last></author>
      <author><first>Bhuwan</first><last>Dhingra</last></author>
      <author><first>Diyi</first><last>Yang</last></author>
      <author><first>Dipanjan</first><last>Das</last></author>
      <pages>1173–1186</pages>
      <url hash="c75753a8">2020.emnlp-main.89</url>
      <attachment type="OptionalSupplementaryMaterial" hash="88a69b87">2020.emnlp-main.89.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="90">
      <title>Knowledge Graph Empowered Entity Description Generation</title>
      <author><first>Liying</first><last>Cheng</last></author>
      <author><first>Dekun</first><last>Wu</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <author><first>Yan</first><last>Zhang</last></author>
      <author><first>Zhanming</first><last>Jie</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Luo</first><last>Si</last></author>
      <pages>1187–1197</pages>
      <url hash="5edb5a09">2020.emnlp-main.90</url>
    </paper>
    <paper id="91">
      <title>Small but Mighty: New Benchmarks for Split and Rephrase</title>
      <author><first>Li</first><last>Zhang</last></author>
      <author><first>Huaiyu</first><last>Zhu</last></author>
      <author><first>Siddhartha</first><last>Brahma</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <pages>1198–1205</pages>
      <url hash="02849073">2020.emnlp-main.91</url>
    </paper>
    <paper id="92">
      <title>Online Back-Parsing for <fixed-case>AMR</fixed-case>-to-Text Generation</title>
      <author><first>Xuefeng</first><last>Bai</last></author>
      <author><first>Linfeng</first><last>Song</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>1206–1219</pages>
      <url hash="4409a5e4">2020.emnlp-main.92</url>
    </paper>
    <paper id="93">
      <title>Reading between the Lines: Exploring Infilling in Visual Narratives</title>
      <author><first>Khyathi Raghavi</first><last>Chandu</last></author>
      <author><first>Ruo-Ping</first><last>Dong</last></author>
      <author><first>Alan W</first><last>Black</last></author>
      <pages>1220–1229</pages>
      <url hash="0775c9f1">2020.emnlp-main.93</url>
    </paper>
    <paper id="94">
      <title>Acrostic Poem Generation</title>
      <author><first>Rajat</first><last>Agarwal</last></author>
      <author><first>Katharina</first><last>Kann</last></author>
      <pages>1230–1240</pages>
      <url hash="9644e4b6">2020.emnlp-main.94</url>
    </paper>
    <paper id="95">
      <title>Local Additivity Based Data Augmentation for Semi-supervised <fixed-case>NER</fixed-case></title>
      <author><first>Jiaao</first><last>Chen</last></author>
      <author><first>Zhenghui</first><last>Wang</last></author>
      <author><first>Ran</first><last>Tian</last></author>
      <author><first>Zichao</first><last>Yang</last></author>
      <author><first>Diyi</first><last>Yang</last></author>
      <pages>1241–1251</pages>
      <url hash="56cd51f9">2020.emnlp-main.95</url>
    </paper>
    <paper id="96">
      <title>Grounded Compositional Outputs for Adaptive Language Modeling</title>
      <author><first>Nikolaos</first><last>Pappas</last></author>
      <author><first>Phoebe</first><last>Mulcaire</last></author>
      <author><first>Noah A.</first><last>Smith</last></author>
      <pages>1252–1267</pages>
      <url hash="e277894f">2020.emnlp-main.96</url>
    </paper>
    <paper id="97">
      <title><fixed-case>SSMBA</fixed-case>: Self-Supervised Manifold Based Data Augmentation for Improving Out-of-Domain Robustness</title>
      <author><first>Nathan</first><last>Ng</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <author><first>Marzyeh</first><last>Ghassemi</last></author>
      <pages>1268–1283</pages>
      <url hash="cb10a610">2020.emnlp-main.97</url>
    </paper>
    <paper id="98">
      <title><fixed-case>S</fixed-case>et<fixed-case>C</fixed-case>onv: A New Approach for Learning from Imbalanced Data</title>
      <author><first>Yang</first><last>Gao</last></author>
      <author><first>Yi-Fan</first><last>Li</last></author>
      <author><first>Yu</first><last>Lin</last></author>
      <author><first>Charu</first><last>Aggarwal</last></author>
      <author><first>Latifur</first><last>Khan</last></author>
      <pages>1284–1294</pages>
      <url hash="6314322e">2020.emnlp-main.98</url>
    </paper>
    <paper id="99">
      <title>Scalable Multi-Hop Relational Reasoning for Knowledge-Aware Question Answering</title>
      <author><first>Yanlin</first><last>Feng</last></author>
      <author><first>Xinyue</first><last>Chen</last></author>
      <author><first>Bill Yuchen</first><last>Lin</last></author>
      <author><first>Peifeng</first><last>Wang</last></author>
      <author><first>Jun</first><last>Yan</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <pages>1295–1309</pages>
      <url hash="6ed82a15">2020.emnlp-main.99</url>
      <attachment type="OptionalSupplementaryMaterial" hash="505ff218">2020.emnlp-main.99.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="100">
      <title>Improving Bilingual Lexicon Induction for Low Frequency Words</title>
      <author><first>Jiaji</first><last>Huang</last></author>
      <author><first>Xingyu</first><last>Cai</last></author>
      <author><first>Kenneth</first><last>Church</last></author>
      <pages>1310–1314</pages>
      <url hash="7b31022a">2020.emnlp-main.100</url>
    </paper>
    <paper id="101">
      <title>Learning <fixed-case>VAE</fixed-case>-<fixed-case>LDA</fixed-case> Models with Rounded Reparameterization Trick</title>
      <author><first>Runzhi</first><last>Tian</last></author>
      <author><first>Yongyi</first><last>Mao</last></author>
      <author><first>Richong</first><last>Zhang</last></author>
      <pages>1315–1325</pages>
      <url hash="150cd7f6">2020.emnlp-main.101</url>
    </paper>
    <paper id="102">
      <title>Calibrated Fine-Tuning for Pre-trained Language Models via Manifold Smoothing</title>
      <author><first>Lingkai</first><last>Kong</last></author>
      <author><first>Haoming</first><last>Jiang</last></author>
      <author><first>Yuchen</first><last>Zhuang</last></author>
      <author><first>Jie</first><last>Lyu</last></author>
      <author><first>Tuo</first><last>Zhao</last></author>
      <author><first>Chao</first><last>Zhang</last></author>
      <pages>1326–1340</pages>
      <url hash="d4d53a7c">2020.emnlp-main.102</url>
    </paper>
    <paper id="103">
      <title>Scaling Hidden <fixed-case>M</fixed-case>arkov Language Models</title>
      <author><first>Justin</first><last>Chiu</last></author>
      <author><first>Alexander</first><last>Rush</last></author>
      <pages>1341–1349</pages>
      <url hash="66a4f5ab">2020.emnlp-main.103</url>
    </paper>
    <paper id="104">
      <title>Coding Textual Inputs Boosts the Accuracy of Neural Networks</title>
      <author><first>Abdul Rafae</first><last>Khan</last></author>
      <author><first>Jia</first><last>Xu</last></author>
      <author><first>Weiwei</first><last>Sun</last></author>
      <pages>1350–1360</pages>
      <url hash="53b5562f">2020.emnlp-main.104</url>
    </paper>
    <paper id="105">
      <title>Learning from Task Descriptions</title>
      <author><first>Orion</first><last>Weller</last></author>
      <author><first>Nicholas</first><last>Lourie</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <author><first>Matthew</first><last>Peters</last></author>
      <pages>1361–1375</pages>
      <url hash="271873fc">2020.emnlp-main.105</url>
    </paper>
    <paper id="106">
      <title>Hashtags, Emotions, and Comments: A Large-Scale Dataset to Understand Fine-Grained Social Emotions to Online Topics</title>
      <author><first>Keyang</first><last>Ding</last></author>
      <author><first>Jing</first><last>Li</last></author>
      <author><first>Yuji</first><last>Zhang</last></author>
      <pages>1376–1382</pages>
      <url hash="4a2b9a27">2020.emnlp-main.106</url>
    </paper>
    <paper id="107">
      <title>Named Entity Recognition for Social Media Texts with Semantic Augmentation</title>
      <author><first>Yuyang</first><last>Nie</last></author>
      <author><first>Yuanhe</first><last>Tian</last></author>
      <author><first>Xiang</first><last>Wan</last></author>
      <author><first>Yan</first><last>Song</last></author>
      <author><first>Bo</first><last>Dai</last></author>
      <pages>1383–1391</pages>
      <url hash="fc108d62">2020.emnlp-main.107</url>
    </paper>
    <paper id="108">
      <title>Predicting Stance and Rumor Veracity via Dual Hierarchical Transformer with Pretrained Encoders</title>
      <author><first>Jianfei</first><last>Yu</last></author>
      <author><first>Jing</first><last>Jiang</last></author>
      <author><first>Ling Min Serena</first><last>Khoo</last></author>
      <author><first>Hai Leong</first><last>Chieu</last></author>
      <author><first>Rui</first><last>Xia</last></author>
      <pages>1392–1401</pages>
      <url hash="c89d8899">2020.emnlp-main.108</url>
    </paper>
    <paper id="109">
      <title>Social Media Attributions in the Context of Water Crisis</title>
      <author><first>Rupak</first><last>Sarkar</last></author>
      <author><first>Sayantan</first><last>Mahinder</last></author>
      <author><first>Hirak</first><last>Sarkar</last></author>
      <author><first>Ashiqur</first><last>KhudaBukhsh</last></author>
      <pages>1402–1412</pages>
      <url hash="6e318ab1">2020.emnlp-main.109</url>
    </paper>
    <paper id="110">
      <title>On the Reliability and Validity of Detecting Approval of Political Actors in Tweets</title>
      <author><first>Indira</first><last>Sen</last></author>
      <author><first>Fabian</first><last>Flöck</last></author>
      <author><first>Claudia</first><last>Wagner</last></author>
      <pages>1413–1426</pages>
      <url hash="31d0460b">2020.emnlp-main.110</url>
    </paper>
    <paper id="111">
      <title>Towards Medical Machine Reading Comprehension with Structural Knowledge and Plain Text</title>
      <author><first>Dongfang</first><last>Li</last></author>
      <author><first>Baotian</first><last>Hu</last></author>
      <author><first>Qingcai</first><last>Chen</last></author>
      <author><first>Weihua</first><last>Peng</last></author>
      <author><first>Anqi</first><last>Wang</last></author>
      <pages>1427–1438</pages>
      <url hash="354245f0">2020.emnlp-main.111</url>
      <attachment type="OptionalSupplementaryMaterial" hash="0146de91">2020.emnlp-main.111.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="112">
      <title>Generating Radiology Reports via Memory-driven Transformer</title>
      <author><first>Zhihong</first><last>Chen</last></author>
      <author><first>Yan</first><last>Song</last></author>
      <author><first>Tsung-Hui</first><last>Chang</last></author>
      <author><first>Xiang</first><last>Wan</last></author>
      <pages>1439–1449</pages>
      <url hash="40540d26">2020.emnlp-main.112</url>
    </paper>
    <paper id="113">
      <title>Planning and Generating Natural and Diverse Disfluent Texts as Augmentation for Disfluency Detection</title>
      <author><first>Jingfeng</first><last>Yang</last></author>
      <author><first>Diyi</first><last>Yang</last></author>
      <author><first>Zhaoran</first><last>Ma</last></author>
      <pages>1450–1460</pages>
      <url hash="a260366a">2020.emnlp-main.113</url>
    </paper>
    <paper id="114">
      <title>Predicting Clinical Trial Results by Implicit Evidence Integration</title>
      <author><first>Qiao</first><last>Jin</last></author>
      <author><first>Chuanqi</first><last>Tan</last></author>
      <author><first>Mosha</first><last>Chen</last></author>
      <author><first>Xiaozhong</first><last>Liu</last></author>
      <author><first>Songfang</first><last>Huang</last></author>
      <pages>1461–1477</pages>
      <url hash="a8d5e5e9">2020.emnlp-main.114</url>
    </paper>
    <paper id="115">
      <title>Explainable Clinical Decision Support from Text</title>
      <author><first>Jinyue</first><last>Feng</last></author>
      <author><first>Chantal</first><last>Shaib</last></author>
      <author><first>Frank</first><last>Rudzicz</last></author>
      <pages>1478–1489</pages>
      <url hash="91b238a5">2020.emnlp-main.115</url>
      <attachment type="OptionalSupplementaryMaterial" hash="2fec42a6">2020.emnlp-main.115.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="116">
      <title>A Knowledge-driven Generative Model for Multi-implication <fixed-case>C</fixed-case>hinese Medical Procedure Entity Normalization</title>
      <author><first>Jinghui</first><last>Yan</last></author>
      <author><first>Yining</first><last>Wang</last></author>
      <author><first>Lu</first><last>Xiang</last></author>
      <author><first>Yu</first><last>Zhou</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>1490–1499</pages>
      <url hash="751712ff">2020.emnlp-main.116</url>
    </paper>
    <paper id="117">
      <title><fixed-case>C</fixed-case>he<fixed-case>X</fixed-case>bert: Combining Automatic Labelers and Expert Annotations for Accurate Radiology Report Labeling Using <fixed-case>BERT</fixed-case></title>
      <author><first>Akshay</first><last>Smit</last></author>
      <author><first>Saahil</first><last>Jain</last></author>
      <author><first>Pranav</first><last>Rajpurkar</last></author>
      <author><first>Anuj</first><last>Pareek</last></author>
      <author><first>Andrew</first><last>Ng</last></author>
      <author><first>Matthew</first><last>Lungren</last></author>
      <pages>1500–1519</pages>
      <url hash="cb197b58">2020.emnlp-main.117</url>
    </paper>
    <paper id="118">
      <title>Benchmarking Meaning Representations in Neural Semantic Parsing</title>
      <author><first>Jiaqi</first><last>Guo</last></author>
      <author><first>Qian</first><last>Liu</last></author>
      <author><first>Jian-Guang</first><last>Lou</last></author>
      <author><first>Zhenwen</first><last>Li</last></author>
      <author><first>Xueqing</first><last>Liu</last></author>
      <author><first>Tao</first><last>Xie</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <pages>1520–1540</pages>
      <url hash="35a019e7">2020.emnlp-main.118</url>
    </paper>
    <paper id="119">
      <title>Analogous Process Structure Induction for Sub-event Sequence Prediction</title>
      <author><first>Hongming</first><last>Zhang</last></author>
      <author><first>Muhao</first><last>Chen</last></author>
      <author><first>Haoyu</first><last>Wang</last></author>
      <author><first>Yangqiu</first><last>Song</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>1541–1550</pages>
      <url hash="4e28b587">2020.emnlp-main.119</url>
    </paper>
    <paper id="120">
      <title><fixed-case>SLM</fixed-case>: Learning a Discourse Language Representation with Sentence Unshuffling</title>
      <author><first>Haejun</first><last>Lee</last></author>
      <author><first>Drew A.</first><last>Hudson</last></author>
      <author><first>Kangwook</first><last>Lee</last></author>
      <author><first>Christopher D.</first><last>Manning</last></author>
      <pages>1551–1562</pages>
      <url hash="71f951ce">2020.emnlp-main.120</url>
    </paper>
    <paper id="121">
      <title>Detecting Fine-Grained Cross-Lingual Semantic Divergences without Supervision by Learning to Rank</title>
      <author><first>Eleftheria</first><last>Briakou</last></author>
      <author><first>Marine</first><last>Carpuat</last></author>
      <pages>1563–1580</pages>
      <url hash="f63ed2a0">2020.emnlp-main.121</url>
    </paper>
    <paper id="122">
      <title>A Bilingual Generative Transformer for Semantic Sentence Embedding</title>
      <author><first>John</first><last>Wieting</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Taylor</first><last>Berg-Kirkpatrick</last></author>
      <pages>1581–1594</pages>
      <url hash="89a1f9ac">2020.emnlp-main.122</url>
    </paper>
    <paper id="123">
      <title>Semantically Inspired <fixed-case>AMR</fixed-case> Alignment for the <fixed-case>P</fixed-case>ortuguese Language</title>
      <author><first>Rafael</first><last>Anchiêta</last></author>
      <author><first>Thiago</first><last>Pardo</last></author>
      <pages>1595–1600</pages>
      <url hash="6faa3525">2020.emnlp-main.123</url>
    </paper>
    <paper id="124">
      <title>An Unsupervised Sentence Embedding Method by Mutual Information Maximization</title>
      <author><first>Yan</first><last>Zhang</last></author>
      <author><first>Ruidan</first><last>He</last></author>
      <author><first>Zuozhu</first><last>Liu</last></author>
      <author><first>Kwan Hui</first><last>Lim</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <pages>1601–1610</pages>
      <url hash="7604ae77">2020.emnlp-main.124</url>
    </paper>
    <paper id="125">
      <title>Compositional Phrase Alignment and beyond</title>
      <author><first>Yuki</first><last>Arase</last></author>
      <author><first>Jun’ichi</first><last>Tsujii</last></author>
      <pages>1611–1623</pages>
      <url hash="9e25d54f">2020.emnlp-main.125</url>
    </paper>
    <paper id="126">
      <title>Table Fact Verification with Structure-Aware Transformer</title>
      <author><first>Hongzhi</first><last>Zhang</last></author>
      <author><first>Yingyao</first><last>Wang</last></author>
      <author><first>Sirui</first><last>Wang</last></author>
      <author><first>Xuezhi</first><last>Cao</last></author>
      <author><first>Fuzheng</first><last>Zhang</last></author>
      <author><first>Zhongyuan</first><last>Wang</last></author>
      <pages>1624–1629</pages>
      <url hash="387ff85e">2020.emnlp-main.126</url>
    </paper>
    <paper id="127">
      <title>Double Graph Based Reasoning for Document-level Relation Extraction</title>
      <author><first>Shuang</first><last>Zeng</last></author>
      <author><first>Runxin</first><last>Xu</last></author>
      <author><first>Baobao</first><last>Chang</last></author>
      <author><first>Lei</first><last>Li</last></author>
      <pages>1630–1640</pages>
      <url hash="f205ef83">2020.emnlp-main.127</url>
    </paper>
    <paper id="128">
      <title>Event Extraction as Machine Reading Comprehension</title>
      <author><first>Jian</first><last>Liu</last></author>
      <author><first>Yubo</first><last>Chen</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Wei</first><last>Bi</last></author>
      <author><first>Xiaojiang</first><last>Liu</last></author>
      <pages>1641–1651</pages>
      <url hash="12be5030">2020.emnlp-main.128</url>
    </paper>
    <paper id="129">
      <title><fixed-case>MAVEN</fixed-case>: A Massive General Domain Event Detection Dataset</title>
      <author><first>Xiaozhi</first><last>Wang</last></author>
      <author><first>Ziqi</first><last>Wang</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Wangyi</first><last>Jiang</last></author>
      <author><first>Rong</first><last>Han</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Juanzi</first><last>Li</last></author>
      <author><first>Peng</first><last>Li</last></author>
      <author><first>Yankai</first><last>Lin</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>1652–1671</pages>
      <url hash="6c7a5d01">2020.emnlp-main.129</url>
      <attachment type="OptionalSupplementaryMaterial" hash="ba254e53">2020.emnlp-main.129.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="130">
      <title>Knowledge Graph Alignment with Entity-Pair Embedding</title>
      <author><first>Zhichun</first><last>Wang</last></author>
      <author><first>Jinjian</first><last>Yang</last></author>
      <author><first>Xiaoju</first><last>Ye</last></author>
      <pages>1672–1680</pages>
      <url hash="b4c8783f">2020.emnlp-main.130</url>
    </paper>
    <paper id="131">
      <title>Adaptive Attentional Network for Few-Shot Knowledge Graph Completion</title>
      <author><first>Jiawei</first><last>Sheng</last></author>
      <author><first>Shu</first><last>Guo</last></author>
      <author><first>Zhenyu</first><last>Chen</last></author>
      <author><first>Juwei</first><last>Yue</last></author>
      <author><first>Lihong</first><last>Wang</last></author>
      <author><first>Tingwen</first><last>Liu</last></author>
      <author><first>Hongbo</first><last>Xu</last></author>
      <pages>1681–1691</pages>
      <url hash="016913e2">2020.emnlp-main.131</url>
    </paper>
    <paper id="132">
      <title>Pre-training Entity Relation Encoder with Intra-span and Inter-span Information</title>
      <author><first>Yijun</first><last>Wang</last></author>
      <author><first>Changzhi</first><last>Sun</last></author>
      <author><first>Yuanbin</first><last>Wu</last></author>
      <author><first>Junchi</first><last>Yan</last></author>
      <author><first>Peng</first><last>Gao</last></author>
      <author><first>Guotong</first><last>Xie</last></author>
      <pages>1692–1705</pages>
      <url hash="b04d4804">2020.emnlp-main.132</url>
    </paper>
    <paper id="133">
      <title>Two Are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders</title>
      <author><first>Jue</first><last>Wang</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <pages>1706–1721</pages>
      <url hash="19aabbc5">2020.emnlp-main.133</url>
    </paper>
    <paper id="134">
      <title>Beyond [<fixed-case>CLS</fixed-case>] through Ranking by Generation</title>
      <author><first>Cicero</first><last>Nogueira dos Santos</last></author>
      <author><first>Xiaofei</first><last>Ma</last></author>
      <author><first>Ramesh</first><last>Nallapati</last></author>
      <author><first>Zhiheng</first><last>Huang</last></author>
      <author><first>Bing</first><last>Xiang</last></author>
      <pages>1722–1727</pages>
      <url hash="eaf9f6f3">2020.emnlp-main.134</url>
    </paper>
    <paper id="135">
      <title>Tired of Topic Models? Clusters of Pretrained Word Embeddings Make for Fast and Good Topics Too!</title>
      <author><first>Suzanna</first><last>Sia</last></author>
      <author><first>Ayush</first><last>Dalmia</last></author>
      <author><first>Sabrina J.</first><last>Mielke</last></author>
      <pages>1728–1736</pages>
      <url hash="8dbdef45">2020.emnlp-main.135</url>
      <attachment type="OptionalSupplementaryMaterial" hash="86332bd5">2020.emnlp-main.135.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="136">
      <title>Multi-document Summarization with Maximal Marginal Relevance-guided Reinforcement Learning</title>
      <author><first>Yuning</first><last>Mao</last></author>
      <author><first>Yanru</first><last>Qu</last></author>
      <author><first>Yiqing</first><last>Xie</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <pages>1737–1751</pages>
      <url hash="270e0d04">2020.emnlp-main.136</url>
    </paper>
    <paper id="137">
      <title>Improving Neural Topic Models Using Knowledge Distillation</title>
      <author><first>Alexander Miserlis</first><last>Hoyle</last></author>
      <author><first>Pranav</first><last>Goel</last></author>
      <author><first>Philip</first><last>Resnik</last></author>
      <pages>1752–1771</pages>
      <url hash="268b7642">2020.emnlp-main.137</url>
    </paper>
    <paper id="138">
      <title>Short Text Topic Modeling with Topic Distribution Quantization and Negative Sampling Decoder</title>
      <author><first>Xiaobao</first><last>Wu</last></author>
      <author><first>Chunping</first><last>Li</last></author>
      <author><first>Yan</first><last>Zhu</last></author>
      <author><first>Yishu</first><last>Miao</last></author>
      <pages>1772–1782</pages>
      <url hash="1c7d53fa">2020.emnlp-main.138</url>
    </paper>
    <paper id="139">
      <title>Querying across Genres to Retrieve Research That Supports Medical Claims Made in News</title>
      <author><first>Chaoyuan</first><last>Zuo</last></author>
      <author><first>Narayan</first><last>Acharya</last></author>
      <author><first>Ritwik</first><last>Banerjee</last></author>
      <pages>1783–1789</pages>
      <url hash="dcb96e4a">2020.emnlp-main.139</url>
    </paper>
    <paper id="140">
      <title>Incorporating Multimodal Information in Open-Domain Web Keyphrase Extraction</title>
      <author><first>Yansen</first><last>Wang</last></author>
      <author><first>Zhen</first><last>Fan</last></author>
      <author><first>Carolyn</first><last>Rose</last></author>
      <pages>1790–1800</pages>
      <url hash="b7ec773b">2020.emnlp-main.140</url>
      <attachment type="OptionalSupplementaryMaterial" hash="c21a9081">2020.emnlp-main.140.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="141">
      <title><fixed-case>MOSEAS</fixed-case>: A Multimodal Language Dataset for <fixed-case>S</fixed-case>panish, <fixed-case>P</fixed-case>ortuguese, <fixed-case>G</fixed-case>erman and <fixed-case>F</fixed-case>rench</title>
      <author><first>AmirAli</first><last>Bagher Zadeh</last></author>
      <author><first>Yansheng</first><last>Cao</last></author>
      <author><first>Simon</first><last>Hessner</last></author>
      <author><first>Paul Pu</first><last>Liang</last></author>
      <author><first>Soujanya</first><last>Poria</last></author>
      <author><first>Louis-Philippe</first><last>Morency</last></author>
      <pages>1801–1812</pages>
      <url hash="3b32d7ca">2020.emnlp-main.141</url>
    </paper>
    <paper id="142">
      <title>Combining Self-Training and Self-Supervised Learning for Unsupervised Disfluency Detection</title>
      <author><first>Shaolei</first><last>Wang</last></author>
      <author><first>Zhongyuan</first><last>Wang</last></author>
      <author><first>Wanxiang</first><last>Che</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <pages>1813–1822</pages>
      <url hash="c53e4afc">2020.emnlp-main.142</url>
    </paper>
    <paper id="143">
      <title>Multimodal Routing: Improving Local and Global Interpretability of Multimodal Language Analysis</title>
      <author><first>Yao-Hung Hubert</first><last>Tsai</last></author>
      <author><first>Martin</first><last>Ma</last></author>
      <author><first>Muqiao</first><last>Yang</last></author>
      <author><first>Ruslan</first><last>Salakhutdinov</last></author>
      <author><first>Louis-Philippe</first><last>Morency</last></author>
      <pages>1823–1833</pages>
      <url hash="aa965690">2020.emnlp-main.143</url>
      <attachment type="OptionalSupplementaryMaterial" hash="60c3805e">2020.emnlp-main.143.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="144">
      <title>Multistage Fusion with Forget Gate for Multimodal Summarization in Open-Domain Videos</title>
      <author><first>Nayu</first><last>Liu</last></author>
      <author><first>Xian</first><last>Sun</last></author>
      <author><first>Hongfeng</first><last>Yu</last></author>
      <author><first>Wenkai</first><last>Zhang</last></author>
      <author><first>Guangluan</first><last>Xu</last></author>
      <pages>1834–1845</pages>
      <url hash="c0825562">2020.emnlp-main.144</url>
    </paper>
    <paper id="145">
      <title><fixed-case>B</fixed-case>i<fixed-case>ST</fixed-case>: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues</title>
      <author><first>Hung</first><last>Le</last></author>
      <author><first>Doyen</first><last>Sahoo</last></author>
      <author><first>Nancy</first><last>Chen</last></author>
      <author><first>Steven C.H.</first><last>Hoi</last></author>
      <pages>1846–1859</pages>
      <url hash="3028407e">2020.emnlp-main.145</url>
    </paper>
    <paper id="146">
      <title><fixed-case>U</fixed-case>ni<fixed-case>C</fixed-case>onv: A Unified Conversational Neural Architecture for Multi-domain Task-oriented Dialogues</title>
      <author><first>Hung</first><last>Le</last></author>
      <author><first>Doyen</first><last>Sahoo</last></author>
      <author><first>Chenghao</first><last>Liu</last></author>
      <author><first>Nancy</first><last>Chen</last></author>
      <author><first>Steven C.H.</first><last>Hoi</last></author>
      <pages>1860–1877</pages>
      <url hash="704aff0d">2020.emnlp-main.146</url>
    </paper>
    <paper id="147">
      <title><fixed-case>G</fixed-case>raph<fixed-case>D</fixed-case>ialog: Integrating Graph Knowledge into End-to-End Task-Oriented Dialogue Systems</title>
      <author><first>Shiquan</first><last>Yang</last></author>
      <author><first>Rui</first><last>Zhang</last></author>
      <author><first>Sarah</first><last>Erfani</last></author>
      <pages>1878–1888</pages>
      <url hash="6595e8f8">2020.emnlp-main.147</url>
    </paper>
    <paper id="148">
      <title>Structured Attention for Unsupervised Dialogue Structure Induction</title>
      <author><first>Liang</first><last>Qiu</last></author>
      <author><first>Yizhou</first><last>Zhao</last></author>
      <author><first>Weiyan</first><last>Shi</last></author>
      <author><first>Yuan</first><last>Liang</last></author>
      <author><first>Feng</first><last>Shi</last></author>
      <author><first>Tao</first><last>Yuan</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <author><first>Song-Chun</first><last>Zhu</last></author>
      <pages>1889–1899</pages>
      <url hash="cce58ed1">2020.emnlp-main.148</url>
      <attachment type="OptionalSupplementaryMaterial" hash="6b2c622d">2020.emnlp-main.148.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="149">
      <title>Cross Copy Network for Dialogue Generation</title>
      <author><first>Changzhen</first><last>Ji</last></author>
      <author><first>Xin</first><last>Zhou</last></author>
      <author><first>Yating</first><last>Zhang</last></author>
      <author><first>Xiaozhong</first><last>Liu</last></author>
      <author><first>Changlong</first><last>Sun</last></author>
      <author><first>Conghui</first><last>Zhu</last></author>
      <author><first>Tiejun</first><last>Zhao</last></author>
      <pages>1900–1910</pages>
      <url hash="408fb65e">2020.emnlp-main.149</url>
      <attachment type="OptionalSupplementaryMaterial" hash="3020954e">2020.emnlp-main.149.OptionalSupplementaryMaterial.rar</attachment>
    </paper>
    <paper id="150">
      <title>Multi-turn Response Selection Using Dialogue Dependency Relations</title>
      <author><first>Qi</first><last>Jia</last></author>
      <author><first>Yizhu</first><last>Liu</last></author>
      <author><first>Siyu</first><last>Ren</last></author>
      <author><first>Kenny</first><last>Zhu</last></author>
      <author><first>Haifeng</first><last>Tang</last></author>
      <pages>1911–1920</pages>
      <url hash="4f8b2fd1">2020.emnlp-main.150</url>
    </paper>
    <paper id="151">
      <title>Parallel Interactive Networks for Multi-Domain Dialogue State Generation</title>
      <author><first>Junfan</first><last>Chen</last></author>
      <author><first>Richong</first><last>Zhang</last></author>
      <author><first>Yongyi</first><last>Mao</last></author>
      <author><first>Jie</first><last>Xu</last></author>
      <pages>1921–1931</pages>
      <url hash="9ae88dd5">2020.emnlp-main.151</url>
    </paper>
    <paper id="152">
      <title><fixed-case>S</fixed-case>lot<fixed-case>R</fixed-case>efine: A Fast Non-Autoregressive Model for Joint Intent Detection and Slot Filling</title>
      <author><first>Di</first><last>Wu</last></author>
      <author><first>Liang</first><last>Ding</last></author>
      <author><first>Fan</first><last>Lu</last></author>
      <author><first>Jian</first><last>Xie</last></author>
      <pages>1932–1937</pages>
      <url hash="46175883">2020.emnlp-main.152</url>
    </paper>
    <paper id="153">
      <title>An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction</title>
      <author><first>Bhargavi</first><last>Paranjape</last></author>
      <author><first>Mandar</first><last>Joshi</last></author>
      <author><first>John</first><last>Thickstun</last></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>1938–1952</pages>
      <url hash="7ca4716f">2020.emnlp-main.153</url>
    </paper>
    <paper id="154">
      <title><fixed-case>C</fixed-case>row<fixed-case>S</fixed-case>-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models</title>
      <author><first>Nikita</first><last>Nangia</last></author>
      <author><first>Clara</first><last>Vania</last></author>
      <author><first>Rasika</first><last>Bhalerao</last></author>
      <author><first>Samuel R.</first><last>Bowman</last></author>
      <pages>1953–1967</pages>
      <url hash="58544784">2020.emnlp-main.154</url>
      <attachment type="OptionalSupplementaryMaterial" hash="2d5ce472">2020.emnlp-main.154.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="155">
      <title><fixed-case>LOGAN</fixed-case>: Local Group Bias Detection by Clustering</title>
      <author><first>Jieyu</first><last>Zhao</last></author>
      <author><first>Kai-Wei</first><last>Chang</last></author>
      <pages>1968–1977</pages>
      <url hash="a658f80f">2020.emnlp-main.155</url>
    </paper>
    <paper id="156">
      <title><fixed-case>RNN</fixed-case>s Can Generate Bounded Hierarchical Languages with Optimal Memory</title>
      <author><first>John</first><last>Hewitt</last></author>
      <author><first>Michael</first><last>Hahn</last></author>
      <author><first>Surya</first><last>Ganguli</last></author>
      <author><first>Percy</first><last>Liang</last></author>
      <author><first>Christopher D.</first><last>Manning</last></author>
      <pages>1978–2010</pages>
      <url hash="c069310e">2020.emnlp-main.156</url>
      <attachment type="OptionalSupplementaryMaterial" hash="3c008a27">2020.emnlp-main.156.OptionalSupplementaryMaterial.tgz</attachment>
    </paper>
    <paper id="157">
      <title>Detecting Independent Pronoun Bias with Partially-Synthetic Data Generation</title>
      <author><first>Robert</first><last>Munro</last></author>
      <author><first>Alex (Carmen)</first><last>Morrison</last></author>
      <pages>2011–2017</pages>
      <url hash="2d7f3e06">2020.emnlp-main.157</url>
    </paper>
    <paper id="158">
      <title>Visually Grounded Continual Learning of Compositional Phrases</title>
      <author><first>Xisen</first><last>Jin</last></author>
      <author><first>Junyi</first><last>Du</last></author>
      <author><first>Arka</first><last>Sadhu</last></author>
      <author><first>Ram</first><last>Nevatia</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <pages>2018–2029</pages>
      <url hash="cdcc42a7">2020.emnlp-main.158</url>
    </paper>
    <paper id="159">
      <title>An Effective Framework for Weakly-Supervised Phrase Grounding</title>
      <author><first>Qinxin</first><last>Wang</last></author>
      <author><first>Hao</first><last>Tan</last></author>
      <author><first>Sheng</first><last>Shen</last></author>
      <author><first>Michael</first><last>Mahoney</last></author>
      <author><first>Zhewei</first><last>Yao</last></author>
      <pages>2030–2038</pages>
      <url hash="930e1ecf">2020.emnlp-main.159</url>
      <attachment type="OptionalSupplementaryMaterial" hash="96649bed">2020.emnlp-main.159.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="160">
      <title>Finding Domain-Specific Grounding in Noisy Visual-Textual Documents</title>
      <author><first>Gregory</first><last>Yauney</last></author>
      <author><first>Jack</first><last>Hessel</last></author>
      <author><first>David</first><last>Mimno</last></author>
      <pages>2039–2045</pages>
      <url hash="1f7216f3">2020.emnlp-main.160</url>
    </paper>
    <paper id="161">
      <title>Hero: Hierarchical Encoder for <fixed-case>V</fixed-case>ideo+<fixed-case>L</fixed-case>anguage Omni-representation Pre-training</title>
      <author><first>Linjie</first><last>Li</last></author>
      <author><first>Yen-Chun</first><last>Chen</last></author>
      <author><first>Yu</first><last>Cheng</last></author>
      <author><first>Zhe</first><last>Gan</last></author>
      <author><first>Licheng</first><last>Yu</last></author>
      <author><first>Jingjing</first><last>Liu</last></author>
      <pages>2046–2065</pages>
      <url hash="97c44837">2020.emnlp-main.161</url>
    </paper>
    <paper id="162">
      <title>Vokenization: Improving Language Understanding via Contextualized, Visually-Grounded Supervision</title>
      <author><first>Hao</first><last>Tan</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>2066–2080</pages>
      <url hash="aa50e3ec">2020.emnlp-main.162</url>
    </paper>
    <paper id="163">
      <title>Detecting Cross-Modal Inconsistency to Defend against Neural Fake News</title>
      <author><first>Reuben</first><last>Tan</last></author>
      <author><first>Bryan</first><last>Plummer</last></author>
      <author><first>Kate</first><last>Saenko</last></author>
      <pages>2081–2106</pages>
      <url hash="9f3fb51a">2020.emnlp-main.163</url>
    </paper>
    <paper id="164">
      <title>Enhancing Aspect Term Extraction with Soft Prototypes</title>
      <author><first>Zhuang</first><last>Chen</last></author>
      <author><first>Tieyun</first><last>Qian</last></author>
      <pages>2107–2117</pages>
      <url hash="41be63e0">2020.emnlp-main.164</url>
    </paper>
    <paper id="165">
      <title><fixed-case>F</fixed-case>ed<fixed-case>ED</fixed-case>: Federated Learning via Ensemble Distillation for Medical Relation Extraction</title>
      <author><first>Dianbo</first><last>Sui</last></author>
      <author><first>Yubo</first><last>Chen</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Yantao</first><last>Jia</last></author>
      <author><first>Yuantao</first><last>Xie</last></author>
      <author><first>Weijian</first><last>Sun</last></author>
      <pages>2118–2128</pages>
      <url hash="eae3bec0">2020.emnlp-main.165</url>
    </paper>
    <paper id="166">
      <title>Multimodal Joint Attribute Prediction and Value Extraction for <fixed-case>E</fixed-case>-commerce Product</title>
      <author><first>Tiangang</first><last>Zhu</last></author>
      <author><first>Yue</first><last>Wang</last></author>
      <author><first>Haoran</first><last>Li</last></author>
      <author><first>Youzheng</first><last>Wu</last></author>
      <author><first>Xiaodong</first><last>He</last></author>
      <author><first>Bowen</first><last>Zhou</last></author>
      <pages>2129–2139</pages>
      <url hash="991f36d1">2020.emnlp-main.166</url>
    </paper>
    <paper id="167">
      <title>A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information Expression</title>
      <author><first>Mingming</first><last>Sun</last></author>
      <author><first>Wenyue</first><last>Hua</last></author>
      <author><first>Zoey</first><last>Liu</last></author>
      <author><first>Xin</first><last>Wang</last></author>
      <author><first>Kangjie</first><last>Zheng</last></author>
      <author><first>Ping</first><last>Li</last></author>
      <pages>2140–2150</pages>
      <url hash="5fbbbffa">2020.emnlp-main.167</url>
    </paper>
    <paper id="168">
      <title>Retrofitting Structure-aware Transformer Language Model for End Tasks</title>
      <author><first>Hao</first><last>Fei</last></author>
      <author><first>Yafeng</first><last>Ren</last></author>
      <author><first>Donghong</first><last>Ji</last></author>
      <pages>2151–2161</pages>
      <url hash="bb986069">2020.emnlp-main.168</url>
    </paper>
    <paper id="169">
      <title>Lightweight, Dynamic Graph Convolutional Networks for <fixed-case>AMR</fixed-case>-to-Text Generation</title>
      <author><first>Yan</first><last>Zhang</last></author>
      <author><first>Zhijiang</first><last>Guo</last></author>
      <author><first>Zhiyang</first><last>Teng</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Shay B.</first><last>Cohen</last></author>
      <author><first>Zuozhu</first><last>Liu</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <pages>2162–2172</pages>
      <url hash="0820a40a">2020.emnlp-main.169</url>
    </paper>
    <paper id="170">
      <title>If Beam Search Is the Answer, What Was the Question?</title>
      <author><first>Clara</first><last>Meister</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Tim</first><last>Vieira</last></author>
      <pages>2173–2185</pages>
      <url hash="45ea24ef">2020.emnlp-main.170</url>
    </paper>
    <paper id="171">
      <title>Understanding the Mechanics of <fixed-case>SPIGOT</fixed-case>: Surrogate Gradients for Latent Structure Learning</title>
      <author><first>Tsvetomila</first><last>Mihaylova</last></author>
      <author><first>Vlad</first><last>Niculae</last></author>
      <author><first>André F. T.</first><last>Martins</last></author>
      <pages>2186–2202</pages>
      <url hash="be4f9c2e">2020.emnlp-main.171</url>
    </paper>
    <paper id="172">
      <title>Is the Best Better? <fixed-case>B</fixed-case>ayesian Statistical Model Comparison for Natural Language Processing</title>
      <author><first>Piotr</first><last>Szymański</last></author>
      <author><first>Kyle</first><last>Gorman</last></author>
      <pages>2203–2212</pages>
      <url hash="2a1166dd">2020.emnlp-main.172</url>
      <attachment type="OptionalSupplementaryMaterial" hash="5d74ee71">2020.emnlp-main.172.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="173">
      <title>Multi-Task Learning for Logically Dependent Tasks from the Perspective of Causal Inference</title>
      <author><first>Wenqing</first><last>Chen</last></author>
      <author><first>Jidong</first><last>Tian</last></author>
      <author><first>Liqiang</first><last>Xiao</last></author>
      <author><first>Hao</first><last>He</last></author>
      <author><first>Yaohui</first><last>Jin</last></author>
      <pages>2213–2225</pages>
      <url hash="2a2aec14">2020.emnlp-main.173</url>
    </paper>
    <paper id="174">
      <title>Masking as an Efficient Alternative to Finetuning for Pretrained Language Models</title>
      <author><first>Mengjie</first><last>Zhao</last></author>
      <author><first>Tao</first><last>Lin</last></author>
      <author><first>Fei</first><last>Mi</last></author>
      <author><first>Martin</first><last>Jaggi</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>2226–2241</pages>
      <url hash="15c53fc4">2020.emnlp-main.174</url>
    </paper>
    <paper id="175">
      <title>Dynamic Context Selection for Document-level Neural Machine Translation via Reinforcement Learning</title>
      <author><first>Xiaomian</first><last>Kang</last></author>
      <author><first>Yang</first><last>Zhao</last></author>
      <author><first>Jiajun</first><last>Zhang</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>2242–2254</pages>
      <url hash="071deca8">2020.emnlp-main.175</url>
    </paper>
    <paper id="176">
      <title>Data Rejuvenation: Exploiting Inactive Training Examples for Neural Machine Translation</title>
      <author><first>Wenxiang</first><last>Jiao</last></author>
      <author><first>Xing</first><last>Wang</last></author>
      <author><first>Shilin</first><last>He</last></author>
      <author><first>Irwin</first><last>King</last></author>
      <author><first>Michael</first><last>Lyu</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <pages>2255–2266</pages>
      <url hash="a9462dc5">2020.emnlp-main.176</url>
    </paper>
    <paper id="177">
      <title>Targeted Finetuning for <fixed-case>NMT</fixed-case> with Conditional Generative-Discriminative Loss</title>
      <author><first>Prathyusha</first><last>Jwalapuram</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <author><first>Youlin</first><last>Shen</last></author>
      <pages>2267–2279</pages>
      <url hash="ddd03e36">2020.emnlp-main.177</url>
    </paper>
    <paper id="178">
      <title>Learning Adaptive Segmentation Policy for Simultaneous Translation</title>
      <author><first>Ruiqing</first><last>Zhang</last></author>
      <author><first>Chuanqiang</first><last>Zhang</last></author>
      <author><first>Zhongjun</first><last>He</last></author>
      <author><first>Hua</first><last>Wu</last></author>
      <author><first>Haifeng</first><last>Wang</last></author>
      <pages>2280–2289</pages>
      <url hash="d7fe112e">2020.emnlp-main.178</url>
    </paper>
    <paper id="179">
      <title>Learn to Cross-lingual Transfer with Meta Graph Learning across Heterogeneous Languages</title>
      <author><first>Zheng</first><last>Li</last></author>
      <author><first>Mukul</first><last>Kumar</last></author>
      <author><first>William</first><last>Headden</last></author>
      <author><first>Bing</first><last>Yin</last></author>
      <author><first>Ying</first><last>Wei</last></author>
      <author><first>Yu</first><last>Zhang</last></author>
      <author><first>Qiang</first><last>Yang</last></author>
      <pages>2290–2301</pages>
      <url hash="385bffca">2020.emnlp-main.179</url>
      <attachment type="OptionalSupplementaryMaterial" hash="9367a2ea">2020.emnlp-main.179.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="180">
      <title><fixed-case>UD</fixed-case>apter: Language Adaptation for Truly <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependency Parsing</title>
      <author><first>Ahmet</first><last>Üstün</last></author>
      <author><first>Arianna</first><last>Bisazza</last></author>
      <author><first>Gosse</first><last>Bouma</last></author>
      <author><first>Gertjan</first><last>van Noord</last></author>
      <pages>2302–2315</pages>
      <url hash="27e0a31d">2020.emnlp-main.180</url>
    </paper>
    <paper id="181">
      <title>Uncertainty-Aware Label Refinement for Sequence Labeling</title>
      <author><first>Tao</first><last>Gui</last></author>
      <author><first>Jiacheng</first><last>Ye</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Zhengyan</first><last>Li</last></author>
      <author><first>Zichu</first><last>Fei</last></author>
      <author><first>Yeyun</first><last>Gong</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>2316–2326</pages>
      <url hash="1f05e790">2020.emnlp-main.181</url>
    </paper>
    <paper id="182">
      <title>Adversarial Attack and Defense of Structured Prediction Models</title>
      <author><first>Wenjuan</first><last>Han</last></author>
      <author><first>Liwen</first><last>Zhang</last></author>
      <author><first>Yong</first><last>Jiang</last></author>
      <author><first>Kewei</first><last>Tu</last></author>
      <pages>2327–2338</pages>
      <url hash="39442d52">2020.emnlp-main.182</url>
    </paper>
    <paper id="183">
      <title>Position-Aware Tagging for Aspect Sentiment Triplet Extraction</title>
      <author><first>Lu</first><last>Xu</last></author>
      <author><first>Hao</first><last>Li</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <pages>2339–2349</pages>
      <url hash="afb6dfe3">2020.emnlp-main.183</url>
      <attachment type="OptionalSupplementaryMaterial" hash="aa271b80">2020.emnlp-main.183.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="184">
      <title>Simultaneous Machine Translation with Visual Context</title>
      <author><first>Ozan</first><last>Caglayan</last></author>
      <author><first>Julia</first><last>Ive</last></author>
      <author><first>Veneta</first><last>Haralampieva</last></author>
      <author><first>Pranava</first><last>Madhyastha</last></author>
      <author><first>Loïc</first><last>Barrault</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <pages>2350–2361</pages>
      <url hash="7bc2d1ec">2020.emnlp-main.184</url>
    </paper>
    <paper id="185">
      <title><fixed-case>XCOPA</fixed-case>: A Multilingual Dataset for Causal Commonsense Reasoning</title>
      <author><first>Edoardo Maria</first><last>Ponti</last></author>
      <author><first>Goran</first><last>Glavaš</last></author>
      <author><first>Olga</first><last>Majewska</last></author>
      <author><first>Qianchu</first><last>Liu</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>2362–2376</pages>
      <url hash="ec142a85">2020.emnlp-main.185</url>
    </paper>
    <paper id="186">
      <title>The Secret Is in the Spectra: Predicting Cross-lingual Task Performance with Spectral Similarity Measures</title>
      <author><first>Haim</first><last>Dubossarsky</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Roi</first><last>Reichart</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>2377–2390</pages>
      <url hash="49304001">2020.emnlp-main.186</url>
      <attachment type="OptionalSupplementaryMaterial" hash="86ec5f15">2020.emnlp-main.186.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="187">
      <title>Bridging Linguistic Typology and Multilingual Machine Translation with Multi-view Language Representations</title>
      <author><first>Arturo</first><last>Oncevay</last></author>
      <author><first>Barry</first><last>Haddow</last></author>
      <author><first>Alexandra</first><last>Birch</last></author>
      <pages>2391–2406</pages>
      <url hash="625b980a">2020.emnlp-main.187</url>
    </paper>
    <paper id="188">
      <title><fixed-case>A</fixed-case>nswer<fixed-case>F</fixed-case>act: Fact Checking in Product Question Answering</title>
      <author><first>Wenxuan</first><last>Zhang</last></author>
      <author><first>Yang</first><last>Deng</last></author>
      <author><first>Jing</first><last>Ma</last></author>
      <author><first>Wai</first><last>Lam</last></author>
      <pages>2407–2417</pages>
      <url hash="115b1ce1">2020.emnlp-main.188</url>
    </paper>
    <paper id="189">
      <title>Context-Aware Answer Extraction in Question Answering</title>
      <author><first>Yeon</first><last>Seonwoo</last></author>
      <author><first>Ji-Hoon</first><last>Kim</last></author>
      <author><first>Jung-Woo</first><last>Ha</last></author>
      <author><first>Alice</first><last>Oh</last></author>
      <pages>2418–2428</pages>
      <url hash="143e33f2">2020.emnlp-main.189</url>
    </paper>
    <paper id="190">
      <title>What Do Models Learn from Question Answering Datasets?</title>
      <author><first>Priyanka</first><last>Sen</last></author>
      <author><first>Amir</first><last>Saffari</last></author>
      <pages>2429–2438</pages>
      <url hash="2ba14f96">2020.emnlp-main.190</url>
    </paper>
    <paper id="191">
      <title>Discern: Discourse-Aware Entailment Reasoning Network for Conversational Machine Reading</title>
      <author><first>Yifan</first><last>Gao</last></author>
      <author><first>Chien-Sheng</first><last>Wu</last></author>
      <author><first>Jingjing</first><last>Li</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <author><first>Steven C.H.</first><last>Hoi</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <author><first>Irwin</first><last>King</last></author>
      <author><first>Michael</first><last>Lyu</last></author>
      <pages>2439–2449</pages>
      <url hash="849f066c">2020.emnlp-main.191</url>
    </paper>
    <paper id="192">
      <title>A Method for Building a Commonsense Inference Dataset Based on Basic Events</title>
      <author><first>Kazumasa</first><last>Omura</last></author>
      <author><first>Daisuke</first><last>Kawahara</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>2450–2460</pages>
      <url hash="82805939">2020.emnlp-main.192</url>
    </paper>
    <paper id="193">
      <title>Neural Deepfake Detection with Factual Structure of Text</title>
      <author><first>Wanjun</first><last>Zhong</last></author>
      <author><first>Duyu</first><last>Tang</last></author>
      <author><first>Zenan</first><last>Xu</last></author>
      <author><first>Ruize</first><last>Wang</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <author><first>Jiahai</first><last>Wang</last></author>
      <author><first>Jian</first><last>Yin</last></author>
      <pages>2461–2470</pages>
      <url hash="206a57bd">2020.emnlp-main.193</url>
    </paper>
    <paper id="194">
      <title><fixed-case>M</fixed-case>ulti<fixed-case>CQA</fixed-case>: Zero-Shot Transfer of Self-Supervised Text Matching Models on a Massive Scale</title>
      <author><first>Andreas</first><last>Rücklé</last></author>
      <author><first>Jonas</first><last>Pfeiffer</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>2471–2486</pages>
      <url hash="5fa7d92b">2020.emnlp-main.194</url>
    </paper>
    <paper id="195">
      <title>Enabling Cross-Lingual <fixed-case>AMR</fixed-case> Parsing with Transfer Learning Techniques</title>
      <author><first>Rexhina</first><last>Blloshmi</last></author>
      <author><first>Rocco</first><last>Tripodi</last></author>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>2487–2500</pages>
      <url hash="c3642070">2020.emnlp-main.195</url>
    </paper>
    <paper id="196">
      <title>Improving <fixed-case>AMR</fixed-case> Parsing with Sequence-to-Sequence Pre-training</title>
      <author><first>Dongqin</first><last>Xu</last></author>
      <author><first>Junhui</first><last>Li</last></author>
      <author><first>Muhua</first><last>Zhu</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Guodong</first><last>Zhou</last></author>
      <pages>2501–2511</pages>
      <url hash="f9c8204a">2020.emnlp-main.196</url>
    </paper>
    <paper id="197">
      <title>Hate-Speech and Offensive Language Detection in <fixed-case>R</fixed-case>oman <fixed-case>U</fixed-case>rdu</title>
      <author><first>Hammad</first><last>Rizwan</last></author>
      <author><first>Muhammad Haroon</first><last>Shakeel</last></author>
      <author><first>Asim</first><last>Karim</last></author>
      <pages>2512–2522</pages>
      <url hash="156c30c1">2020.emnlp-main.197</url>
    </paper>
    <paper id="198">
      <title>Suicidal Risk Detection for Military Personnel</title>
      <author><first>Sungjoon</first><last>Park</last></author>
      <author><first>Kiwoong</first><last>Park</last></author>
      <author><first>Jaimeen</first><last>Ahn</last></author>
      <author><first>Alice</first><last>Oh</last></author>
      <pages>2523–2531</pages>
      <url hash="9aaed6c1">2020.emnlp-main.198</url>
    </paper>
    <paper id="199">
      <title>Comparative Evaluation of Label Agnostic Selection Bias in Multilingual Hate Speech Datasets</title>
      <author><first>Nedjma</first><last>Ousidhoum</last></author>
      <author><first>Yangqiu</first><last>Song</last></author>
      <author><first>Dit-Yan</first><last>Yeung</last></author>
      <pages>2532–2542</pages>
      <url hash="34fae7c1">2020.emnlp-main.199</url>
    </paper>
    <paper id="200">
      <title><fixed-case>HENIN</fixed-case>: Learning Heterogeneous Neural Interaction Networks for Explainable Cyberbullying Detection on Social Media</title>
      <author><first>Hsin-Yu</first><last>Chen</last></author>
      <author><first>Cheng-Te</first><last>Li</last></author>
      <pages>2543–2552</pages>
      <url hash="3406e5ea">2020.emnlp-main.200</url>
    </paper>
    <paper id="201">
      <title><fixed-case>I</fixed-case> Was Just Being Sarcastic! Reactive Supervision: A New Method for Collecting Sarcasm Data</title>
      <author><first>Boaz</first><last>Shmueli</last></author>
      <author><first>Lun-Wei</first><last>Ku</last></author>
      <author><first>Soumya</first><last>Ray</last></author>
      <pages>2553–2559</pages>
      <url hash="b1b55354">2020.emnlp-main.201</url>
    </paper>
    <paper id="202">
      <title>Self-Induced Curriculum Learning in Self-Supervised Neural Machine Translation</title>
      <author><first>Dana</first><last>Ruiter</last></author>
      <author><first>Josef</first><last>van Genabith</last></author>
      <author><first>Cristina</first><last>España-Bonet</last></author>
      <pages>2560–2571</pages>
      <url hash="fb830132">2020.emnlp-main.202</url>
    </paper>
    <paper id="203">
      <title>Towards Reasonably-Sized Character-Level Transformer <fixed-case>NMT</fixed-case> by Finetuning Subword Systems</title>
      <author><first>Jindřich</first><last>Libovický</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <pages>2572–2579</pages>
      <url hash="f0722a0c">2020.emnlp-main.203</url>
      <attachment type="OptionalSupplementaryMaterial" hash="5ce69b68">2020.emnlp-main.203.OptionalSupplementaryMaterial.tgz</attachment>
    </paper>
    <paper id="204">
      <title>Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on <fixed-case>A</fixed-case>frican Languages</title>
      <author><first>Michael A.</first><last>Hedderich</last></author>
      <author><first>David</first><last>Adelani</last></author>
      <author><first>Dawei</first><last>Zhu</last></author>
      <author><first>Jesujoba</first><last>Alabi</last></author>
      <author><first>Udia</first><last>Markus</last></author>
      <author><first>Dietrich</first><last>Klakow</last></author>
      <pages>2580–2591</pages>
      <url hash="d1f2a324">2020.emnlp-main.204</url>
      <attachment type="OptionalSupplementaryMaterial" hash="886e16a8">2020.emnlp-main.204.OptionalSupplementaryMaterial.pdf</attachment>
    </paper>
    <paper id="205">
      <title>Translation Quality Estimation by Jointly Learning to Score and Rank</title>
      <author><first>Jingyi</first><last>Zhang</last></author>
      <author><first>Josef</first><last>van Genabith</last></author>
      <pages>2592–2598</pages>
      <url hash="3b065fad">2020.emnlp-main.205</url>
    </paper>
    <paper id="206">
      <title>Direct Segmentation Models for Streaming Speech Translation</title>
      <author><first>Javier</first><last>Iranzo-Sánchez</last></author>
      <author><first>Adrià</first><last>Giménez Pastor</last></author>
      <author><first>Joan Albert</first><last>Silvestre-Cerdà</last></author>
      <author><first>Pau</first><last>Baquero-Arnal</last></author>
      <author><first>Jorge</first><last>Civera Saiz</last></author>
      <author><first>Alfons</first><last>Juan</last></author>
      <pages>2599–2611</pages>
      <url hash="6f6a5d91">2020.emnlp-main.206</url>
      <attachment type="OptionalSupplementaryMaterial" hash="990c2187">2020.emnlp-main.206.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="207">
      <title>Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for <fixed-case>B</fixed-case>engali-<fixed-case>E</fixed-case>nglish Machine Translation</title>
      <author><first>Tahmid</first><last>Hasan</last></author>
      <author><first>Abhik</first><last>Bhattacharjee</last></author>
      <author><first>Kazi</first><last>Samin</last></author>
      <author><first>Masum</first><last>Hasan</last></author>
      <author><first>Madhusudan</first><last>Basak</last></author>
      <author><first>M. Sohel</first><last>Rahman</last></author>
      <author><first>Rifat</first><last>Shahriyar</last></author>
      <pages>2612–2623</pages>
      <url hash="a0921235">2020.emnlp-main.207</url>
    </paper>
    <paper id="208">
      <title><fixed-case>CSP</fixed-case>: Code-Switching Pre-training for Neural Machine Translation</title>
      <author><first>Zhen</first><last>Yang</last></author>
      <author><first>Bojie</first><last>Hu</last></author>
      <author><first>Ambyera</first><last>Han</last></author>
      <author><first>Shen</first><last>Huang</last></author>
      <author><first>Qi</first><last>Ju</last></author>
      <pages>2624–2636</pages>
      <url hash="5cb99c8a">2020.emnlp-main.208</url>
    </paper>
    <paper id="209">
      <title>Type <fixed-case>B</fixed-case> Reflexivization as an Unambiguous Testbed for Multilingual Multi-Task Gender Bias</title>
      <author><first>Ana Valeria</first><last>González</last></author>
      <author><first>Maria</first><last>Barrett</last></author>
      <author><first>Rasmus</first><last>Hvingelby</last></author>
      <author><first>Kellie</first><last>Webster</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>2637–2648</pages>
      <url hash="69926c37">2020.emnlp-main.209</url>
    </paper>
    <paper id="210">
      <title>Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information</title>
      <author><first>Zehui</first><last>Lin</last></author>
      <author><first>Xiao</first><last>Pan</last></author>
      <author><first>Mingxuan</first><last>Wang</last></author>
      <author><first>Xipeng</first><last>Qiu</last></author>
      <author><first>Jiangtao</first><last>Feng</last></author>
      <author><first>Hao</first><last>Zhou</last></author>
      <author><first>Lei</first><last>Li</last></author>
      <pages>2649–2663</pages>
      <url hash="a0f25581">2020.emnlp-main.210</url>
    </paper>
    <paper id="211">
      <title>Losing Heads in the Lottery: Pruning Transformer Attention in Neural Machine Translation</title>
      <author><first>Maximiliana</first><last>Behnke</last></author>
      <author><first>Kenneth</first><last>Heafield</last></author>
      <pages>2664–2674</pages>
      <url hash="a86a9658">2020.emnlp-main.211</url>
    </paper>
    <paper id="212">
      <title>Towards Enhancing Faithfulness for Neural Machine Translation</title>
      <author><first>Rongxiang</first><last>Weng</last></author>
      <author><first>Heng</first><last>Yu</last></author>
      <author><first>Xiangpeng</first><last>Wei</last></author>
      <author><first>Weihua</first><last>Luo</last></author>
      <pages>2675–2684</pages>
      <url hash="aba554e7">2020.emnlp-main.212</url>
    </paper>
    <paper id="213">
      <title><fixed-case>COMET</fixed-case>: A Neural Framework for <fixed-case>MT</fixed-case> Evaluation</title>
      <author><first>Ricardo</first><last>Rei</last></author>
      <author><first>Craig</first><last>Stewart</last></author>
      <author><first>Ana C</first><last>Farinha</last></author>
      <author><first>Alon</first><last>Lavie</last></author>
      <pages>2685–2702</pages>
      <url hash="63c66bdb">2020.emnlp-main.213</url>
    </paper>
    <paper id="214">
      <title>Reusing a Pretrained Language Model on Languages with Limited Corpora for Unsupervised <fixed-case>NMT</fixed-case></title>
      <author><first>Alexandra</first><last>Chronopoulou</last></author>
      <author><first>Dario</first><last>Stojanovski</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <pages>2703–2711</pages>
      <url hash="4aecdee7">2020.emnlp-main.214</url>
      <attachment type="OptionalSupplementaryMaterial" hash="8820fbcc">2020.emnlp-main.214.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="215">
      <title><fixed-case>LNM</fixed-case>ap: Departures from Isomorphic Assumption in Bilingual Lexicon Induction through Non-Linear Mapping in Latent Space</title>
      <author><first>Tasnim</first><last>Mohiuddin</last></author>
      <author><first>M Saiful</first><last>Bari</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <pages>2712–2723</pages>
      <url hash="4602ab16">2020.emnlp-main.215</url>
    </paper>
    <paper id="216">
      <title>Uncertainty-Aware Semantic Augmentation for Neural Machine Translation</title>
      <author><first>Xiangpeng</first><last>Wei</last></author>
      <author><first>Heng</first><last>Yu</last></author>
      <author><first>Yue</first><last>Hu</last></author>
      <author><first>Rongxiang</first><last>Weng</last></author>
      <author><first>Luxi</first><last>Xing</last></author>
      <author><first>Weihua</first><last>Luo</last></author>
      <pages>2724–2735</pages>
      <url hash="ee95a39d">2020.emnlp-main.216</url>
      <attachment type="OptionalSupplementaryMaterial" hash="cae056de">2020.emnlp-main.216.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="217">
      <title>Can Automatic Post-Editing Improve <fixed-case>NMT</fixed-case>?</title>
      <author><first>Shamil</first><last>Chollampatt</last></author>
      <author><first>Raymond Hendy</first><last>Susanto</last></author>
      <author><first>Liling</first><last>Tan</last></author>
      <author><first>Ewa</first><last>Szymanska</last></author>
      <pages>2736–2746</pages>
      <url hash="6af71e80">2020.emnlp-main.217</url>
    </paper>
    <paper id="218">
      <title>Parsing Gapping Constructions Based on Grammatical and Semantic Roles</title>
      <author><first>Yoshihide</first><last>Kato</last></author>
      <author><first>Shigeki</first><last>Matsubara</last></author>
      <pages>2747–2752</pages>
      <url hash="f07ffaf1">2020.emnlp-main.218</url>
    </paper>
    <paper id="219">
      <title>Span-based Discontinuous Constituency Parsing: A Family of Exact Chart-based Algorithms with Time Complexities from <fixed-case>O</fixed-case>(nˆ6) Down to <fixed-case>O</fixed-case>(nˆ3)</title>
      <author><first>Caio</first><last>Corro</last></author>
      <pages>2753–2764</pages>
      <url hash="2c0f4d7f">2020.emnlp-main.219</url>
      <attachment type="OptionalSupplementaryMaterial" hash="c63fdefa">2020.emnlp-main.219.OptionalSupplementaryMaterial.pdf</attachment>
    </paper>
    <paper id="220">
      <title>Some Languages Seem Easier to Parse Because Their Treebanks Leak</title>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>2765–2770</pages>
      <url hash="fd0bc433">2020.emnlp-main.220</url>
      <attachment type="OptionalSupplementaryMaterial" hash="8f016362">2020.emnlp-main.220.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="221">
      <title>Discontinuous Constituent Parsing as Sequence Labeling</title>
      <author><first>David</first><last>Vilares</last></author>
      <author><first>Carlos</first><last>Gómez-Rodríguez</last></author>
      <pages>2771–2785</pages>
      <url hash="59623267">2020.emnlp-main.221</url>
    </paper>
    <paper id="222">
      <title>Modularized Syntactic Neural Networks for Sentence Classification</title>
      <author><first>Haiyan</first><last>Wu</last></author>
      <author><first>Ying</first><last>Liu</last></author>
      <author><first>Shaoyun</first><last>Shi</last></author>
      <pages>2786–2792</pages>
      <url hash="0abda388">2020.emnlp-main.222</url>
    </paper>
    <paper id="223">
      <title><fixed-case>TED</fixed-case>-<fixed-case>CDB</fixed-case>: A Large-Scale <fixed-case>C</fixed-case>hinese Discourse Relation Dataset on <fixed-case>TED</fixed-case> Talks</title>
      <author><first>Wanqiu</first><last>Long</last></author>
      <author><first>Bonnie</first><last>Webber</last></author>
      <author><first>Deyi</first><last>Xiong</last></author>
      <pages>2793–2803</pages>
      <url hash="a943489e">2020.emnlp-main.223</url>
    </paper>
    <paper id="224">
      <title><fixed-case>QAD</fixed-case>iscourse - Discourse Relations as <fixed-case>QA</fixed-case> Pairs: Representation, Crowdsourcing and Baselines</title>
      <author><first>Valentina</first><last>Pyatkin</last></author>
      <author><first>Ayal</first><last>Klein</last></author>
      <author><first>Reut</first><last>Tsarfaty</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>2804–2819</pages>
      <url hash="6bdbd076">2020.emnlp-main.224</url>
    </paper>
    <paper id="225">
      <title>Discourse Self-Attention for Discourse Element Identification in Argumentative Student Essays</title>
      <author><first>Wei</first><last>Song</last></author>
      <author><first>Ziyao</first><last>Song</last></author>
      <author><first>Ruiji</first><last>Fu</last></author>
      <author><first>Lizhen</first><last>Liu</last></author>
      <author><first>Miaomiao</first><last>Cheng</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <pages>2820–2830</pages>
      <url hash="a45099e8">2020.emnlp-main.225</url>
      <attachment type="OptionalSupplementaryMaterial" hash="2895acf3">2020.emnlp-main.225.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="226">
      <title>Controllable Story Generation with External Knowledge Using Large-Scale Language Models</title>
      <author><first>Peng</first><last>Xu</last></author>
      <author><first>Mostofa</first><last>Patwary</last></author>
      <author><first>Mohammad</first><last>Shoeybi</last></author>
      <author><first>Raul</first><last>Puri</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <author><first>Anima</first><last>Anandkumar</last></author>
      <author><first>Bryan</first><last>Catanzaro</last></author>
      <pages>2831–2845</pages>
      <url hash="86506504">2020.emnlp-main.226</url>
    </paper>
    <paper id="227">
      <title>Incomplete Utterance Rewriting as Semantic Segmentation</title>
      <author><first>Qian</first><last>Liu</last></author>
      <author><first>Bei</first><last>Chen</last></author>
      <author><first>Jian-Guang</first><last>Lou</last></author>
      <author><first>Bin</first><last>Zhou</last></author>
      <author><first>Dongmei</first><last>Zhang</last></author>
      <pages>2846–2857</pages>
      <url hash="1ca2171a">2020.emnlp-main.227</url>
    </paper>
    <paper id="228">
      <title>Improving Grammatical Error Correction Models with Purpose-Built Adversarial Examples</title>
      <author><first>Lihao</first><last>Wang</last></author>
      <author><first>Xiaoqing</first><last>Zheng</last></author>
      <pages>2858–2869</pages>
      <url hash="eaab2617">2020.emnlp-main.228</url>
    </paper>
    <paper id="229">
      <title>Homophonic Pun Generation with Lexically Constrained Rewriting</title>
      <author><first>Zhiwei</first><last>Yu</last></author>
      <author><first>Hongyu</first><last>Zang</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <pages>2870–2876</pages>
      <url hash="c1df1a87">2020.emnlp-main.229</url>
    </paper>
    <paper id="230">
      <title>How to Make Neural Natural Language Generation as Reliable as Templates in Task-Oriented Dialogue</title>
      <author><first>Henry</first><last>Elder</last></author>
      <author><first>Alexander</first><last>O’Connor</last></author>
      <author><first>Jennifer</first><last>Foster</last></author>
      <pages>2877–2888</pages>
      <url hash="85f28f27">2020.emnlp-main.230</url>
    </paper>
    <paper id="231">
      <title>Multilingual <fixed-case>AMR</fixed-case>-to-Text Generation</title>
      <author><first>Angela</first><last>Fan</last></author>
      <author><first>Claire</first><last>Gardent</last></author>
      <pages>2889–2901</pages>
      <url hash="86ee8e88">2020.emnlp-main.231</url>
    </paper>
    <paper id="232">
      <title>Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation</title>
      <author><first>Francisco</first><last>Vargas</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <pages>2902–2913</pages>
      <url hash="f8bfabaa">2020.emnlp-main.232</url>
      <attachment type="OptionalSupplementaryMaterial" hash="a8b366a4">2020.emnlp-main.232.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="233">
      <title>Lifelong Language Knowledge Distillation</title>
      <author><first>Yung-Sung</first><last>Chuang</last></author>
      <author><first>Shang-Yu</first><last>Su</last></author>
      <author><first>Yun-Nung</first><last>Chen</last></author>
      <pages>2914–2924</pages>
      <url hash="1cdfbe01">2020.emnlp-main.233</url>
    </paper>
    <paper id="234">
      <title>Sparse Parallel Training for Hierarchical <fixed-case>D</fixed-case>irichlet Process Topic Models</title>
      <author><first>Alexander</first><last>Terenin</last></author>
      <author><first>Måns</first><last>Magnusson</last></author>
      <author><first>Leif</first><last>Jonsson</last></author>
      <pages>2925–2934</pages>
      <url hash="52b339d4">2020.emnlp-main.234</url>
      <attachment type="OptionalSupplementaryMaterial" hash="4f5f3c7d">2020.emnlp-main.234.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="235">
      <title>Multi-label Few/Zero-shot Learning with Knowledge Aggregated from Multiple Label Graphs</title>
      <author><first>Jueqing</first><last>Lu</last></author>
      <author><first>Lan</first><last>Du</last></author>
      <author><first>Ming</first><last>Liu</last></author>
      <author><first>Joanna</first><last>Dipnall</last></author>
      <pages>2935–2943</pages>
      <url hash="c2a38f37">2020.emnlp-main.235</url>
    </paper>
    <paper id="236">
      <title>Word Rotator’s Distance</title>
      <author><first>Sho</first><last>Yokoi</last></author>
      <author><first>Ryo</first><last>Takahashi</last></author>
      <author><first>Reina</first><last>Akama</last></author>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>2944–2960</pages>
      <url hash="d8cfbd9f">2020.emnlp-main.236</url>
    </paper>
    <paper id="237">
      <title>Disentangle-based Continual Graph Representation Learning</title>
      <author><first>Xiaoyu</first><last>Kou</last></author>
      <author><first>Yankai</first><last>Lin</last></author>
      <author><first>Shaobo</first><last>Liu</last></author>
      <author><first>Peng</first><last>Li</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <author><first>Yan</first><last>Zhang</last></author>
      <pages>2961–2972</pages>
      <url hash="cfebc155">2020.emnlp-main.237</url>
    </paper>
    <paper id="238">
      <title>Semi-Supervised Bilingual Lexicon Induction with Two-way Interaction</title>
      <author><first>Xu</first><last>Zhao</last></author>
      <author><first>Zihao</first><last>Wang</last></author>
      <author><first>Hao</first><last>Wu</last></author>
      <author><first>Yong</first><last>Zhang</last></author>
      <pages>2973–2984</pages>
      <url hash="4c69eab2">2020.emnlp-main.238</url>
      <attachment type="OptionalSupplementaryMaterial" hash="659d06b6">2020.emnlp-main.238.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="239">
      <title><fixed-case>W</fixed-case>asserstein Distance Regularized Sequence Representation for Text Matching in Asymmetrical Domains</title>
      <author><first>Weijie</first><last>Yu</last></author>
      <author><first>Chen</first><last>Xu</last></author>
      <author><first>Jun</first><last>Xu</last></author>
      <author><first>Liang</first><last>Pang</last></author>
      <author><first>Xiaopeng</first><last>Gao</last></author>
      <author><first>Xiaozhao</first><last>Wang</last></author>
      <author><first>Ji-Rong</first><last>Wen</last></author>
      <pages>2985–2994</pages>
      <url hash="e05ee78d">2020.emnlp-main.239</url>
    </paper>
    <paper id="240">
      <title>A Simple Approach to Learning Unsupervised Multilingual Embeddings</title>
      <author><first>Pratik</first><last>Jawanpuria</last></author>
      <author><first>Mayank</first><last>Meghwanshi</last></author>
      <author><first>Bamdev</first><last>Mishra</last></author>
      <pages>2995–3001</pages>
      <url hash="657c0971">2020.emnlp-main.240</url>
    </paper>
    <paper id="241">
      <title>Bootstrapped <fixed-case>Q</fixed-case>-learning with Context Relevant Observation Pruning to Generalize in Text-based Games</title>
      <author><first>Subhajit</first><last>Chaudhury</last></author>
      <author><first>Daiki</first><last>Kimura</last></author>
      <author><first>Kartik</first><last>Talamadupula</last></author>
      <author><first>Michiaki</first><last>Tatsubori</last></author>
      <author><first>Asim</first><last>Munawar</last></author>
      <author><first>Ryuki</first><last>Tachibana</last></author>
      <pages>3002–3008</pages>
      <url hash="c3d3fa4f">2020.emnlp-main.241</url>
    </paper>
    <paper id="242">
      <title><fixed-case>BERT</fixed-case>-<fixed-case>EMD</fixed-case>: Many-to-Many Layer Mapping for <fixed-case>BERT</fixed-case> Compression with Earth Mover’s Distance</title>
      <author><first>Jianquan</first><last>Li</last></author>
      <author><first>Xiaokang</first><last>Liu</last></author>
      <author><first>Honghong</first><last>Zhao</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <author><first>Min</first><last>Yang</last></author>
      <author><first>Yaohong</first><last>Jin</last></author>
      <pages>3009–3018</pages>
      <url hash="0cb77ffe">2020.emnlp-main.242</url>
    </paper>
    <paper id="243">
      <title>Slot Attention with Value Normalization for Multi-domain Dialogue State Tracking</title>
      <author><first>Yexiang</first><last>Wang</last></author>
      <author><first>Yi</first><last>Guo</last></author>
      <author><first>Siqi</first><last>Zhu</last></author>
      <pages>3019–3028</pages>
      <url hash="98405a40">2020.emnlp-main.243</url>
    </paper>
    <paper id="244">
      <title>Don’t Read Too Much into It: Adaptive Computation for Open-Domain Question Answering</title>
      <author><first>Yuxiang</first><last>Wu</last></author>
      <author><first>Sebastian</first><last>Riedel</last></author>
      <author><first>Pasquale</first><last>Minervini</last></author>
      <author><first>Pontus</first><last>Stenetorp</last></author>
      <pages>3029–3039</pages>
      <url hash="7bb908e7">2020.emnlp-main.244</url>
    </paper>
    <paper id="245">
      <title>Multi-Step Inference for Reasoning over Paragraphs</title>
      <author><first>Jiangming</first><last>Liu</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <author><first>Shay B.</first><last>Cohen</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <pages>3040–3050</pages>
      <url hash="51ebc68f">2020.emnlp-main.245</url>
    </paper>
    <paper id="246">
      <title>Learning a Cost-Effective Annotation Policy for Question Answering</title>
      <author><first>Bernhard</first><last>Kratzwald</last></author>
      <author><first>Stefan</first><last>Feuerriegel</last></author>
      <author><first>Huan</first><last>Sun</last></author>
      <pages>3051–3062</pages>
      <url hash="6dedbff4">2020.emnlp-main.246</url>
    </paper>
    <paper id="247">
      <title>Scene Restoring for Narrative Machine Reading Comprehension</title>
      <author><first>Zhixing</first><last>Tian</last></author>
      <author><first>Yuanzhe</first><last>Zhang</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Yantao</first><last>Jia</last></author>
      <author><first>Zhicheng</first><last>Sheng</last></author>
      <pages>3063–3073</pages>
      <url hash="d2d79ea7">2020.emnlp-main.247</url>
    </paper>
    <paper id="248">
      <title>A Simple and Effective Model for Answering Multi-span Questions</title>
      <author><first>Elad</first><last>Segal</last></author>
      <author><first>Avia</first><last>Efrat</last></author>
      <author><first>Mor</first><last>Shoham</last></author>
      <author><first>Amir</first><last>Globerson</last></author>
      <author><first>Jonathan</first><last>Berant</last></author>
      <pages>3074–3080</pages>
      <url hash="9ee0bdcd">2020.emnlp-main.248</url>
    </paper>
    <paper id="249">
      <title>Top-Rank-Focused Adaptive Vote Collection for the Evaluation of Domain-Specific Semantic Models</title>
      <author><first>Pierangelo</first><last>Lombardo</last></author>
      <author><first>Alessio</first><last>Boiardi</last></author>
      <author><first>Luca</first><last>Colombo</last></author>
      <author><first>Angelo</first><last>Schiavone</last></author>
      <author><first>Nicolò</first><last>Tamagnone</last></author>
      <pages>3081–3093</pages>
      <url hash="f49bb7e4">2020.emnlp-main.249</url>
    </paper>
    <paper id="250">
      <title>Meta Fine-Tuning Neural Language Models for Multi-Domain Text Mining</title>
      <author><first>Chengyu</first><last>Wang</last></author>
      <author><first>Minghui</first><last>Qiu</last></author>
      <author><first>Jun</first><last>Huang</last></author>
      <author><first>Xiaofeng</first><last>He</last></author>
      <pages>3094–3104</pages>
      <url hash="49452d6d">2020.emnlp-main.250</url>
    </paper>
    <paper id="251">
      <title>Incorporating Context Structures for Query Generation</title>
      <author><first>Ruey-Cheng</first><last>Chen</last></author>
      <author><first>Chia-Jung</first><last>Lee</last></author>
      <pages>3105–3110</pages>
      <url hash="266cefd8">2020.emnlp-main.251</url>
    </paper>
    <paper id="252">
      <title>Conditional Causal Relationships between Emotions and Causes in Texts</title>
      <author><first>Xinhong</first><last>Chen</last></author>
      <author><first>Qing</first><last>Li</last></author>
      <author><first>Jianping</first><last>Wang</last></author>
      <pages>3111–3121</pages>
      <url hash="e0d3dd69">2020.emnlp-main.252</url>
      <attachment type="OptionalSupplementaryMaterial" hash="aba47534">2020.emnlp-main.252.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="253">
      <title><fixed-case>COMETA</fixed-case>: A Corpus for Medical Entity Linking in the Social Media</title>
      <author><first>Marco</first><last>Basaldella</last></author>
      <author><first>Fangyu</first><last>Liu</last></author>
      <author><first>Ehsan</first><last>Shareghi</last></author>
      <author><first>Nigel</first><last>Collier</last></author>
      <pages>3122–3137</pages>
      <url hash="4a263730">2020.emnlp-main.253</url>
    </paper>
    <paper id="254">
      <title><fixed-case>P</fixed-case>areto Probing: Trading-Off Accuracy and Complexity</title>
      <author><first>Tiago</first><last>Pimentel</last></author>
      <author><first>Naomi</first><last>Saphra</last></author>
      <author><first>Adina</first><last>Williams</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <pages>3138–3153</pages>
      <url hash="2ee3f796">2020.emnlp-main.254</url>
    </paper>
    <paper id="255">
      <title>Interpretation of <fixed-case>NLP</fixed-case> Models through Input Marginalization</title>
      <author><first>Siwon</first><last>Kim</last></author>
      <author><first>Jihun</first><last>Yi</last></author>
      <author><first>Eunji</first><last>Kim</last></author>
      <author><first>Sungroh</first><last>Yoon</last></author>
      <pages>3154–3167</pages>
      <url hash="e54fba57">2020.emnlp-main.255</url>
    </paper>
    <paper id="256">
      <title>Generating Label Cohesive and Well-Formed Adversarial Claims</title>
      <author><first>Pepa</first><last>Atanasova</last></author>
      <author><first>Dustin</first><last>Wright</last></author>
      <author><first>Isabelle</first><last>Augenstein</last></author>
      <pages>3168–3177</pages>
      <url hash="95d17a59">2020.emnlp-main.256</url>
    </paper>
    <paper id="257">
      <title>Are All Good Word Vector Spaces Isomorphic?</title>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>3178–3192</pages>
      <url hash="33ce5d62">2020.emnlp-main.257</url>
      <attachment type="OptionalSupplementaryMaterial" hash="90417f2f">2020.emnlp-main.257.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="258">
      <title>Cold-start and Interpretability: Turning Regular Expressions into Trainable Recurrent Neural Networks</title>
      <author><first>Chengyue</first><last>Jiang</last></author>
      <author><first>Yinggong</first><last>Zhao</last></author>
      <author><first>Shanbo</first><last>Chu</last></author>
      <author><first>Libin</first><last>Shen</last></author>
      <author><first>Kewei</first><last>Tu</last></author>
      <pages>3193–3207</pages>
      <url hash="b55f89db">2020.emnlp-main.258</url>
    </paper>
    <paper id="259">
      <title>When <fixed-case>BERT</fixed-case> Plays the Lottery, All Tickets Are Winning</title>
      <author><first>Sai</first><last>Prasanna</last></author>
      <author><first>Anna</first><last>Rogers</last></author>
      <author><first>Anna</first><last>Rumshisky</last></author>
      <pages>3208–3229</pages>
      <url hash="a8e942f6">2020.emnlp-main.259</url>
    </paper>
    <paper id="260">
      <title>On the Weak Link between Importance and Prunability of Attention Heads</title>
      <author><first>Aakriti</first><last>Budhraja</last></author>
      <author><first>Madhura</first><last>Pande</last></author>
      <author><first>Preksha</first><last>Nema</last></author>
      <author><first>Pratyush</first><last>Kumar</last></author>
      <author><first>Mitesh M.</first><last>Khapra</last></author>
      <pages>3230–3235</pages>
      <url hash="e8fb7126">2020.emnlp-main.260</url>
    </paper>
    <paper id="261">
      <title>Towards Interpreting <fixed-case>BERT</fixed-case> for Reading Comprehension Based <fixed-case>QA</fixed-case></title>
      <author><first>Sahana</first><last>Ramnath</last></author>
      <author><first>Preksha</first><last>Nema</last></author>
      <author><first>Deep</first><last>Sahni</last></author>
      <author><first>Mitesh M.</first><last>Khapra</last></author>
      <pages>3236–3242</pages>
      <url hash="3d4c397d">2020.emnlp-main.261</url>
    </paper>
    <paper id="262">
      <title>How Do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking</title>
      <author><first>Nicola</first><last>De Cao</last></author>
      <author><first>Michael Sejr</first><last>Schlichtkrull</last></author>
      <author><first>Wilker</first><last>Aziz</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <pages>3243–3255</pages>
      <url hash="00835ce4">2020.emnlp-main.262</url>
      <attachment type="OptionalSupplementaryMaterial" hash="8d545a99">2020.emnlp-main.262.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="263">
      <title>A Diagnostic Study of Explainability Techniques for Text Classification</title>
      <author><first>Pepa</first><last>Atanasova</last></author>
      <author><first>Jakob Grue</first><last>Simonsen</last></author>
      <author><first>Christina</first><last>Lioma</last></author>
      <author><first>Isabelle</first><last>Augenstein</last></author>
      <pages>3256–3274</pages>
      <url hash="f3716cb1">2020.emnlp-main.263</url>
    </paper>
    <paper id="264">
      <title><fixed-case>STL</fixed-case>-<fixed-case>CQA</fixed-case>: Structure-based Transformers with Localization and Encoding for Chart Question Answering</title>
      <author><first>Hrituraj</first><last>Singh</last></author>
      <author><first>Sumit</first><last>Shekhar</last></author>
      <pages>3275–3284</pages>
      <url hash="8a94584e">2020.emnlp-main.264</url>
      <attachment type="OptionalSupplementaryMaterial" hash="711a7710">2020.emnlp-main.264.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="265">
      <title>Learning to Contrast the Counterfactual Samples for Robust Visual Question Answering</title>
      <author><first>Zujie</first><last>Liang</last></author>
      <author><first>Weitao</first><last>Jiang</last></author>
      <author><first>Haifeng</first><last>Hu</last></author>
      <author><first>Jiaying</first><last>Zhu</last></author>
      <pages>3285–3292</pages>
      <url hash="0bb940e2">2020.emnlp-main.265</url>
    </paper>
    <paper id="266">
      <title>Learning Physical Common Sense as Knowledge Graph Completion via <fixed-case>BERT</fixed-case> Data Augmentation and Constrained Tucker Factorization</title>
      <author><first>Zhenjie</first><last>Zhao</last></author>
      <author><first>Evangelos</first><last>Papalexakis</last></author>
      <author><first>Xiaojuan</first><last>Ma</last></author>
      <pages>3293–3298</pages>
      <url hash="7bd77f5f">2020.emnlp-main.266</url>
    </paper>
    <paper id="267">
      <title>A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses</title>
      <author><first>Hisashi</first><last>Kamezawa</last></author>
      <author><first>Noriki</first><last>Nishida</last></author>
      <author><first>Nobuyuki</first><last>Shimizu</last></author>
      <author><first>Takashi</first><last>Miyazaki</last></author>
      <author><first>Hideki</first><last>Nakayama</last></author>
      <pages>3299–3310</pages>
      <url hash="21333207">2020.emnlp-main.267</url>
    </paper>
    <paper id="268">
      <title>Cross-Media Keyphrase Prediction: A Unified Framework with Multi-Modality Multi-Head Attention and Image Wordings</title>
      <author><first>Yue</first><last>Wang</last></author>
      <author><first>Jing</first><last>Li</last></author>
      <author><first>Michael</first><last>Lyu</last></author>
      <author><first>Irwin</first><last>King</last></author>
      <pages>3311–3324</pages>
      <url hash="ed19b520">2020.emnlp-main.268</url>
    </paper>
    <paper id="269">
      <title><fixed-case>VD</fixed-case>-<fixed-case>BERT</fixed-case>: A Unified Vision and Dialog Transformer with <fixed-case>BERT</fixed-case></title>
      <author><first>Yue</first><last>Wang</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <author><first>Michael</first><last>Lyu</last></author>
      <author><first>Irwin</first><last>King</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <author><first>Steven C.H.</first><last>Hoi</last></author>
      <pages>3325–3338</pages>
      <url hash="6b3f969f">2020.emnlp-main.269</url>
    </paper>
    <paper id="270">
      <title>The Grammar of Emergent Languages</title>
      <author><first>Oskar</first><last>van der Wal</last></author>
      <author><first>Silvan</first><last>de Boer</last></author>
      <author><first>Elia</first><last>Bruni</last></author>
      <author><first>Dieuwke</first><last>Hupkes</last></author>
      <pages>3339–3359</pages>
      <url hash="a2347550">2020.emnlp-main.270</url>
    </paper>
    <paper id="271">
      <title>Sub-Instruction Aware Vision-and-Language Navigation</title>
      <author><first>Yicong</first><last>Hong</last></author>
      <author><first>Cristian</first><last>Rodriguez</last></author>
      <author><first>Qi</first><last>Wu</last></author>
      <author><first>Stephen</first><last>Gould</last></author>
      <pages>3360–3376</pages>
      <url hash="836e30b5">2020.emnlp-main.271</url>
    </paper>
    <paper id="272">
      <title>Knowledge-Grounded Dialogue Generation with Pre-trained Language Models</title>
      <author><first>Xueliang</first><last>Zhao</last></author>
      <author><first>Wei</first><last>Wu</last></author>
      <author><first>Can</first><last>Xu</last></author>
      <author><first>Chongyang</first><last>Tao</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <pages>3377–3390</pages>
      <url hash="b450cd4e">2020.emnlp-main.272</url>
    </paper>
    <paper id="273">
      <title><fixed-case>M</fixed-case>in<fixed-case>TL</fixed-case>: Minimalist Transfer Learning for Task-Oriented Dialogue Systems</title>
      <author><first>Zhaojiang</first><last>Lin</last></author>
      <author><first>Andrea</first><last>Madotto</last></author>
      <author><first>Genta Indra</first><last>Winata</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <pages>3391–3405</pages>
      <url hash="c06a902c">2020.emnlp-main.273</url>
    </paper>
    <paper id="274">
      <title>Variational Hierarchical Dialog Autoencoder for Dialog State Tracking Data Augmentation</title>
      <author><first>Kang Min</first><last>Yoo</last></author>
      <author><first>Hanbit</first><last>Lee</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Trung</first><last>Bui</last></author>
      <author><first>Walter</first><last>Chang</last></author>
      <author><first>Sang-goo</first><last>Lee</last></author>
      <pages>3406–3425</pages>
      <url hash="8611d499">2020.emnlp-main.274</url>
    </paper>
    <paper id="275">
      <title>Bridging the Gap between Prior and Posterior Knowledge Selection for Knowledge-Grounded Dialogue Generation</title>
      <author><first>Xiuyi</first><last>Chen</last></author>
      <author><first>Fandong</first><last>Meng</last></author>
      <author><first>Peng</first><last>Li</last></author>
      <author><first>Feilong</first><last>Chen</last></author>
      <author><first>Shuang</first><last>Xu</last></author>
      <author><first>Bo</first><last>Xu</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>3426–3437</pages>
      <url hash="5b1c9c71">2020.emnlp-main.275</url>
    </paper>
    <paper id="276">
      <title>Counterfactual Off-Policy Training for Neural Dialogue Generation</title>
      <author><first>Qingfu</first><last>Zhu</last></author>
      <author><first>Wei-Nan</first><last>Zhang</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>3438–3448</pages>
      <url hash="f6df1f20">2020.emnlp-main.276</url>
    </paper>
    <paper id="277">
      <title>Dialogue Distillation: Open-domain Dialogue Augmentation Using Unpaired Data</title>
      <author><first>Rongsheng</first><last>Zhang</last></author>
      <author><first>Yinhe</first><last>Zheng</last></author>
      <author><first>Jianzhi</first><last>Shao</last></author>
      <author><first>Xiaoxi</first><last>Mao</last></author>
      <author><first>Yadong</first><last>Xi</last></author>
      <author><first>Minlie</first><last>Huang</last></author>
      <pages>3449–3460</pages>
      <url hash="0a8aa831">2020.emnlp-main.277</url>
    </paper>
    <paper id="278">
      <title>Task-Completion Dialogue Policy Learning via <fixed-case>M</fixed-case>onte <fixed-case>C</fixed-case>arlo Tree Search with Dueling Network</title>
      <author><first>Sihan</first><last>Wang</last></author>
      <author><first>Kaijie</first><last>Zhou</last></author>
      <author><first>Kunfeng</first><last>Lai</last></author>
      <author><first>Jianping</first><last>Shen</last></author>
      <pages>3461–3471</pages>
      <url hash="c22d92b4">2020.emnlp-main.278</url>
    </paper>
    <paper id="279">
      <title>Learning a Simple and Effective Model for Multi-turn Response Generation with Auxiliary Tasks</title>
      <author><first>Yufan</first><last>Zhao</last></author>
      <author><first>Can</first><last>Xu</last></author>
      <author><first>Wei</first><last>Wu</last></author>
      <pages>3472–3483</pages>
      <url hash="4c6e31d4">2020.emnlp-main.279</url>
    </paper>
    <paper id="280">
      <title><fixed-case>A</fixed-case>ttn<fixed-case>IO</fixed-case>: Knowledge Graph Exploration with In-and-Out Attention Flow for Knowledge-Grounded Dialogue</title>
      <author><first>Jaehun</first><last>Jung</last></author>
      <author><first>Bokyung</first><last>Son</last></author>
      <author><first>Sungwon</first><last>Lyu</last></author>
      <pages>3484–3497</pages>
      <url hash="7da4d56c">2020.emnlp-main.280</url>
      <attachment type="OptionalSupplementaryMaterial" hash="ebaaf58a">2020.emnlp-main.280.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="281">
      <title>Amalgamating Knowledge from Two Teachers for Task-oriented Dialogue System with Adversarial Training</title>
      <author><first>Wanwei</first><last>He</last></author>
      <author><first>Min</first><last>Yang</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <author><first>Chengming</first><last>Li</last></author>
      <author><first>Ying</first><last>Shen</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <pages>3498–3507</pages>
      <url hash="d916d101">2020.emnlp-main.281</url>
    </paper>
    <paper id="282">
      <title>Task-oriented Domain-specific Meta-Embedding for Text Classification</title>
      <author><first>Xin</first><last>Wu</last></author>
      <author><first>Yi</first><last>Cai</last></author>
      <author><first>Yang</first><last>Kai</last></author>
      <author><first>Tao</first><last>Wang</last></author>
      <author><first>Qing</first><last>Li</last></author>
      <pages>3508–3513</pages>
      <url hash="aa20313f">2020.emnlp-main.282</url>
    </paper>
    <paper id="283">
      <title>Don’t Neglect the Obvious: On the Role of Unambiguous Words in Word Sense Disambiguation</title>
      <author><first>Daniel</first><last>Loureiro</last></author>
      <author><first>Jose</first><last>Camacho-Collados</last></author>
      <pages>3514–3520</pages>
      <url hash="862d5343">2020.emnlp-main.283</url>
    </paper>
    <paper id="284">
      <title>Within-Between Lexical Relation Classification Using Path-based and Distributional Data</title>
      <author><first>Oren</first><last>Barkan</last></author>
      <author><first>Avi</first><last>Caciularu</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>3521–3527</pages>
      <url hash="80d92882">2020.emnlp-main.284</url>
    </paper>
    <paper id="285">
      <title>With More Contexts Comes Better Performance: Contextualized Sense Embeddings for All-Round Word Sense Disambiguation</title>
      <author><first>Bianca</first><last>Scarlini</last></author>
      <author><first>Tommaso</first><last>Pasini</last></author>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>3528–3539</pages>
      <url hash="ac60f8d3">2020.emnlp-main.285</url>
    </paper>
    <paper id="286">
      <title>Convolution over Hierarchical Syntactic and Lexical Graphs for Aspect Level Sentiment Analysis</title>
      <author><first>Mi</first><last>Zhang</last></author>
      <author><first>Tieyun</first><last>Qian</last></author>
      <pages>3540–3549</pages>
      <url hash="a65cf1fd">2020.emnlp-main.286</url>
    </paper>
    <paper id="287">
      <title>Multi-Instance Multi-Label Learning Networks for Aspect-Category Sentiment Analysis</title>
      <author><first>Yuncong</first><last>Li</last></author>
      <author><first>Cunxiang</first><last>Yin</last></author>
      <author><first>Sheng-hua</first><last>Zhong</last></author>
      <author><first>Xu</first><last>Pan</last></author>
      <pages>3550–3560</pages>
      <url hash="0d8854c4">2020.emnlp-main.287</url>
    </paper>
    <paper id="288">
      <title>Aspect Based Sentiment Analysis with Aspect-Specific Opinion Spans</title>
      <author><first>Lu</first><last>Xu</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Fei</first><last>Huang</last></author>
      <pages>3561–3567</pages>
      <url hash="199dfb1b">2020.emnlp-main.288</url>
    </paper>
    <paper id="289">
      <title>Emotion-Cause Pair Extraction as Sequence Labeling Based on a Novel Tagging Scheme</title>
      <author><first>Chaofa</first><last>Yuan</last></author>
      <author><first>Chuang</first><last>Fan</last></author>
      <author><first>Jianzhu</first><last>Bao</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <pages>3568–3573</pages>
      <url hash="6295cdb8">2020.emnlp-main.289</url>
    </paper>
    <paper id="290">
      <title>End-to-End Emotion-Cause Pair Extraction Based on Sliding Window Multi-Label Learning</title>
      <author><first>Zixiang</first><last>Ding</last></author>
      <author><first>Rui</first><last>Xia</last></author>
      <author><first>Jianfei</first><last>Yu</last></author>
      <pages>3574–3583</pages>
      <url hash="ba32e81f">2020.emnlp-main.290</url>
    </paper>
    <paper id="291">
      <title>Multi-modal Multi-label Emotion Detection with Modality and Label Dependence</title>
      <author><first>Dong</first><last>Zhang</last></author>
      <author><first>Xincheng</first><last>Ju</last></author>
      <author><first>Junhui</first><last>Li</last></author>
      <author><first>Shoushan</first><last>Li</last></author>
      <author><first>Qiaoming</first><last>Zhu</last></author>
      <author><first>Guodong</first><last>Zhou</last></author>
      <pages>3584–3593</pages>
      <url hash="53127218">2020.emnlp-main.291</url>
    </paper>
    <paper id="292">
      <title>Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based Sentiment Analysis</title>
      <author><first>Xiaoyu</first><last>Xing</last></author>
      <author><first>Zhijing</first><last>Jin</last></author>
      <author><first>Di</first><last>Jin</last></author>
      <author><first>Bingning</first><last>Wang</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>3594–3605</pages>
      <url hash="0d66a963">2020.emnlp-main.292</url>
    </paper>
    <paper id="293">
      <title>Modeling Content Importance for Summarization with Pre-trained Language Models</title>
      <author><first>Liqiang</first><last>Xiao</last></author>
      <author><first>Lu</first><last>Wang</last></author>
      <author><first>Hao</first><last>He</last></author>
      <author><first>Yaohui</first><last>Jin</last></author>
      <pages>3606–3611</pages>
      <url hash="ffc68a28">2020.emnlp-main.293</url>
    </paper>
    <paper id="294">
      <title>Unsupervised Reference-Free Summary Quality Evaluation via Contrastive Learning</title>
      <author><first>Hanlu</first><last>Wu</last></author>
      <author><first>Tengfei</first><last>Ma</last></author>
      <author><first>Lingfei</first><last>Wu</last></author>
      <author><first>Tariro</first><last>Manyumwa</last></author>
      <author><first>Shouling</first><last>Ji</last></author>
      <pages>3612–3621</pages>
      <url hash="48eb48bb">2020.emnlp-main.294</url>
    </paper>
    <paper id="295">
      <title>Neural Extractive Summarization with Hierarchical Attentive Heterogeneous Graph Network</title>
      <author><first>Ruipeng</first><last>Jia</last></author>
      <author><first>Yanan</first><last>Cao</last></author>
      <author><first>Hengzhu</first><last>Tang</last></author>
      <author><first>Fang</first><last>Fang</last></author>
      <author><first>Cong</first><last>Cao</last></author>
      <author><first>Shi</first><last>Wang</last></author>
      <pages>3622–3631</pages>
      <url hash="2959bde5">2020.emnlp-main.295</url>
    </paper>
    <paper id="296">
      <title>Coarse-to-Fine Query Focused Multi-Document Summarization</title>
      <author><first>Yumo</first><last>Xu</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <pages>3632–3645</pages>
      <url hash="e6be82b7">2020.emnlp-main.296</url>
    </paper>
    <paper id="297">
      <title>Pre-training for Abstractive Document Summarization by Reinstating Source Text</title>
      <author><first>Yanyan</first><last>Zou</last></author>
      <author><first>Xingxing</first><last>Zhang</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>3646–3660</pages>
      <url hash="747b0f77">2020.emnlp-main.297</url>
    </paper>
    <paper id="298">
      <title>Learning from Context or Names? An Empirical Study on Neural Relation Extraction</title>
      <author><first>Hao</first><last>Peng</last></author>
      <author><first>Tianyu</first><last>Gao</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Yankai</first><last>Lin</last></author>
      <author><first>Peng</first><last>Li</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>3661–3672</pages>
      <url hash="ef654c50">2020.emnlp-main.298</url>
      <attachment type="OptionalSupplementaryMaterial" hash="231646fc">2020.emnlp-main.298.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="299">
      <title><fixed-case>S</fixed-case>elf<fixed-case>ORE</fixed-case>: Self-supervised Relational Feature Learning for Open Relation Extraction</title>
      <author><first>Xuming</first><last>Hu</last></author>
      <author><first>Lijie</first><last>Wen</last></author>
      <author><first>Yusong</first><last>Xu</last></author>
      <author><first>Chenwei</first><last>Zhang</last></author>
      <author><first>Philip</first><last>Yu</last></author>
      <pages>3673–3682</pages>
      <url hash="d3d08b77">2020.emnlp-main.299</url>
    </paper>
    <paper id="300">
      <title>Denoising Relation Extraction from Document-level Distant Supervision</title>
      <author><first>Chaojun</first><last>Xiao</last></author>
      <author><first>Yuan</first><last>Yao</last></author>
      <author><first>Ruobing</first><last>Xie</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <author><first>Fen</first><last>Lin</last></author>
      <author><first>Leyu</first><last>Lin</last></author>
      <pages>3683–3688</pages>
      <url hash="dea325ca">2020.emnlp-main.300</url>
    </paper>
    <paper id="301">
      <title>Let’s Stop Error Propagation in the End-to-End Relation Extraction Literature!</title>
      <author><first>Bruno</first><last>Taillé</last></author>
      <author><first>Vincent</first><last>Guigue</last></author>
      <author><first>Geoffrey</first><last>Scoutheeten</last></author>
      <author><first>Patrick</first><last>Gallinari</last></author>
      <pages>3689–3701</pages>
      <url hash="7e85f4f1">2020.emnlp-main.301</url>
      <attachment type="OptionalSupplementaryMaterial" hash="b0c1945e">2020.emnlp-main.301.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="302">
      <title>Exposing Shallow Heuristics of Relation Extraction Models with Challenge Data</title>
      <author><first>Shachar</first><last>Rosenman</last></author>
      <author><first>Alon</first><last>Jacovi</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>3702–3710</pages>
      <url hash="ccd35a4e">2020.emnlp-main.302</url>
    </paper>
    <paper id="303">
      <title>Global-to-Local Neural Networks for Document-Level Relation Extraction</title>
      <author><first>Difeng</first><last>Wang</last></author>
      <author><first>Wei</first><last>Hu</last></author>
      <author><first>Ermei</first><last>Cao</last></author>
      <author><first>Weijian</first><last>Sun</last></author>
      <pages>3711–3721</pages>
      <url hash="63b716cb">2020.emnlp-main.303</url>
      <attachment type="OptionalSupplementaryMaterial" hash="8e0ad976">2020.emnlp-main.303.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="304">
      <title>Recurrent Interaction Network for Jointly Extracting Entities and Classifying Relations</title>
      <author><first>Kai</first><last>Sun</last></author>
      <author><first>Richong</first><last>Zhang</last></author>
      <author><first>Samuel</first><last>Mensah</last></author>
      <author><first>Yongyi</first><last>Mao</last></author>
      <author><first>Xudong</first><last>Liu</last></author>
      <pages>3722–3732</pages>
      <url hash="d479f54c">2020.emnlp-main.304</url>
    </paper>
    <paper id="305">
      <title>Temporal Knowledge Base Completion: New Algorithms and Evaluation Protocols</title>
      <author><first>Prachi</first><last>Jain</last></author>
      <author><first>Sushant</first><last>Rathi</last></author>
      <author><first></first><last>Mausam</last></author>
      <author><first>Soumen</first><last>Chakrabarti</last></author>
      <pages>3733–3747</pages>
      <url hash="e1e463ef">2020.emnlp-main.305</url>
    </paper>
    <paper id="306">
      <title>Constrained Iterative Labeling for Open Information Extraction</title>
      <author><first>Keshav</first><last>Kolluru</last></author>
      <author><first>Vaibhav</first><last>Adlakha</last></author>
      <author><first>Samarth</first><last>Aggarwal</last></author>
      <author><first></first><last>Mausam</last></author>
      <author><first>Soumen</first><last>Chakrabarti</last></author>
      <pages>3748–3761</pages>
      <url hash="a2594c07">2020.emnlp-main.306</url>
    </paper>
    <paper id="307">
      <title>Public Sentiment Drift Analysis Based on Hierarchical Variational Auto-encoder</title>
      <author><first>Wenyue</first><last>Zhang</last></author>
      <author><first>Xiaoli</first><last>Li</last></author>
      <author><first>Yang</first><last>Li</last></author>
      <author><first>Suge</first><last>Wang</last></author>
      <author><first>Deyu</first><last>Li</last></author>
      <author><first>Jian</first><last>Liao</last></author>
      <author><first>Jianxing</first><last>Zheng</last></author>
      <pages>3762–3767</pages>
      <url hash="6401016e">2020.emnlp-main.307</url>
    </paper>
    <paper id="308">
      <title>Point to the Expression: Solving Algebraic Word Problems Using the Expression-Pointer Transformer Model</title>
      <author><first>Bugeun</first><last>Kim</last></author>
      <author><first>Kyung Seo</first><last>Ki</last></author>
      <author><first>Donggeon</first><last>Lee</last></author>
      <author><first>Gahgene</first><last>Gweon</last></author>
      <pages>3768–3779</pages>
      <url hash="c49cdefd">2020.emnlp-main.308</url>
      <attachment type="OptionalSupplementaryMaterial" hash="5040778a">2020.emnlp-main.308.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="309">
      <title>Semantically-Aligned Universal Tree-Structured Solver for Math Word Problems</title>
      <author><first>Jinghui</first><last>Qin</last></author>
      <author><first>Lihui</first><last>Lin</last></author>
      <author><first>Xiaodan</first><last>Liang</last></author>
      <author><first>Rumin</first><last>Zhang</last></author>
      <author><first>Liang</first><last>Lin</last></author>
      <pages>3780–3789</pages>
      <url hash="c613d5bd">2020.emnlp-main.309</url>
    </paper>
    <paper id="310">
      <title>Neural Topic Modeling by Incorporating Document Relationship Graph</title>
      <author><first>Deyu</first><last>Zhou</last></author>
      <author><first>Xuemeng</first><last>Hu</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <pages>3790–3796</pages>
      <url hash="261b6d09">2020.emnlp-main.310</url>
    </paper>
    <paper id="311">
      <title>Routing Enforced Generative Model for Recipe Generation</title>
      <author><first>Zhiwei</first><last>Yu</last></author>
      <author><first>Hongyu</first><last>Zang</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <pages>3797–3806</pages>
      <url hash="0a20286a">2020.emnlp-main.311</url>
    </paper>
    <paper id="312">
      <title>Assessing the Helpfulness of Learning Materials with Inference-Based Learner-Like Agent</title>
      <author><first>Yun-Hsuan</first><last>Jen</last></author>
      <author><first>Chieh-Yang</first><last>Huang</last></author>
      <author><first>MeiHua</first><last>Chen</last></author>
      <author><first>Ting-Hao</first><last>Huang</last></author>
      <author><first>Lun-Wei</first><last>Ku</last></author>
      <pages>3807–3817</pages>
      <url hash="1571845f">2020.emnlp-main.312</url>
      <attachment type="OptionalSupplementaryMaterial" hash="54f562ed">2020.emnlp-main.312.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="313">
      <title>Selection and Generation: Learning towards Multi-Product Advertisement Post Generation</title>
      <author><first>Zhangming</first><last>Chan</last></author>
      <author><first>Yuchi</first><last>Zhang</last></author>
      <author><first>Xiuying</first><last>Chen</last></author>
      <author><first>Shen</first><last>Gao</last></author>
      <author><first>Zhiqiang</first><last>Zhang</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <pages>3818–3829</pages>
      <url hash="ccb62f58">2020.emnlp-main.313</url>
    </paper>
    <paper id="314">
      <title><fixed-case>F</fixed-case>orm2<fixed-case>S</fixed-case>eq : A Framework for Higher-Order Form Structure Extraction</title>
      <author><first>Milan</first><last>Aggarwal</last></author>
      <author><first>Hiresh</first><last>Gupta</last></author>
      <author><first>Mausoom</first><last>Sarkar</last></author>
      <author><first>Balaji</first><last>Krishnamurthy</last></author>
      <pages>3830–3840</pages>
      <url hash="111c3d39">2020.emnlp-main.314</url>
      <attachment type="OptionalSupplementaryMaterial" hash="57cc032e">2020.emnlp-main.314.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="315">
      <title>Domain Adaptation of <fixed-case>T</fixed-case>hai Word Segmentation Models Using Stacked Ensemble</title>
      <author><first>Peerat</first><last>Limkonchotiwat</last></author>
      <author><first>Wannaphong</first><last>Phatthiyaphaibun</last></author>
      <author><first>Raheem</first><last>Sarwar</last></author>
      <author><first>Ekapol</first><last>Chuangsuwanich</last></author>
      <author><first>Sarana</first><last>Nutanong</last></author>
      <pages>3841–3847</pages>
      <url hash="ca09604c">2020.emnlp-main.315</url>
    </paper>
    <paper id="316">
      <title><fixed-case>D</fixed-case>ago<fixed-case>BERT</fixed-case>: Generating Derivational Morphology with a Pretrained Language Model</title>
      <author><first>Valentin</first><last>Hofmann</last></author>
      <author><first>Janet</first><last>Pierrehumbert</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>3848–3861</pages>
      <url hash="eaf41c3c">2020.emnlp-main.316</url>
    </paper>
    <paper id="317">
      <title>Attention Is All You Need for <fixed-case>C</fixed-case>hinese Word Segmentation</title>
      <author><first>Sufeng</first><last>Duan</last></author>
      <author><first>Hai</first><last>Zhao</last></author>
      <pages>3862–3872</pages>
      <url hash="eebf0950">2020.emnlp-main.317</url>
    </paper>
    <paper id="318">
      <title>A Joint Multiple Criteria Model in Transfer Learning for Cross-domain <fixed-case>C</fixed-case>hinese Word Segmentation</title>
      <author><first>Kaiyu</first><last>Huang</last></author>
      <author><first>Degen</first><last>Huang</last></author>
      <author><first>Zhuang</first><last>Liu</last></author>
      <author><first>Fengran</first><last>Mo</last></author>
      <pages>3873–3882</pages>
      <url hash="8a7695bf">2020.emnlp-main.318</url>
    </paper>
    <paper id="319">
      <title>Alignment-free Cross-lingual Semantic Role Labeling</title>
      <author><first>Rui</first><last>Cai</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <pages>3883–3894</pages>
      <url hash="456236e8">2020.emnlp-main.319</url>
    </paper>
    <paper id="320">
      <title>Leveraging Declarative Knowledge in Text and First-Order Logic for Fine-Grained Propaganda Detection</title>
      <author><first>Ruize</first><last>Wang</last></author>
      <author><first>Duyu</first><last>Tang</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <author><first>Wanjun</first><last>Zhong</last></author>
      <author><first>Zhongyu</first><last>Wei</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <author><first>Daxin</first><last>Jiang</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>3895–3903</pages>
      <url hash="df3946c3">2020.emnlp-main.320</url>
    </paper>
    <paper id="321">
      <title><fixed-case>X</fixed-case>-<fixed-case>SRL</fixed-case>: A Parallel Cross-Lingual Semantic Role Labeling Dataset</title>
      <author><first>Angel</first><last>Daza</last></author>
      <author><first>Anette</first><last>Frank</last></author>
      <pages>3904–3914</pages>
      <url hash="276d8959">2020.emnlp-main.321</url>
      <attachment type="OptionalSupplementaryMaterial" hash="88327772">2020.emnlp-main.321.OptionalSupplementaryMaterial.pdf</attachment>
    </paper>
    <paper id="322">
      <title>Graph Convolutions over Constituent Trees for Syntax-Aware Semantic Role Labeling</title>
      <author><first>Diego</first><last>Marcheggiani</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <pages>3915–3928</pages>
      <url hash="12c0b048">2020.emnlp-main.322</url>
    </paper>
    <paper id="323">
      <title>Fast Semantic Parsing with Well-typedness Guarantees</title>
      <author><first>Matthias</first><last>Lindemann</last></author>
      <author><first>Jonas</first><last>Groschwitz</last></author>
      <author><first>Alexander</first><last>Koller</last></author>
      <pages>3929–3951</pages>
      <url hash="85dfd087">2020.emnlp-main.323</url>
    </paper>
    <paper id="324">
      <title>Improving Out-of-Scope Detection in Intent Classification by Using Embeddings of the Word Graph Space of the Classes</title>
      <author><first>Paulo</first><last>Cavalin</last></author>
      <author><first>Victor Henrique</first><last>Alves Ribeiro</last></author>
      <author><first>Ana</first><last>Appel</last></author>
      <author><first>Claudio</first><last>Pinhanez</last></author>
      <pages>3952–3961</pages>
      <url hash="6b2d43fa">2020.emnlp-main.324</url>
    </paper>
    <paper id="325">
      <title>Supervised Seeded Iterated Learning for Interactive Language Learning</title>
      <author><first>Yuchen</first><last>Lu</last></author>
      <author><first>Soumye</first><last>Singhal</last></author>
      <author><first>Florian</first><last>Strub</last></author>
      <author><first>Olivier</first><last>Pietquin</last></author>
      <author><first>Aaron</first><last>Courville</last></author>
      <pages>3962–3970</pages>
      <url hash="1dfff7b2">2020.emnlp-main.325</url>
    </paper>
    <paper id="326">
      <title>Spot the Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems</title>
      <author><first>Jan</first><last>Deriu</last></author>
      <author><first>Don</first><last>Tuggener</last></author>
      <author><first>Pius</first><last>von Däniken</last></author>
      <author><first>Jon Ander</first><last>Campos</last></author>
      <author><first>Alvaro</first><last>Rodrigo</last></author>
      <author><first>Thiziri</first><last>Belkacem</last></author>
      <author><first>Aitor</first><last>Soroa</last></author>
      <author><first>Eneko</first><last>Agirre</last></author>
      <author><first>Mark</first><last>Cieliebak</last></author>
      <pages>3971–3984</pages>
      <url hash="84986792">2020.emnlp-main.326</url>
      <attachment type="OptionalSupplementaryMaterial" hash="1cd5d2a4">2020.emnlp-main.326.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="327">
      <title>Human-centric Dialog Training via Offline Reinforcement Learning</title>
      <author><first>Natasha</first><last>Jaques</last></author>
      <author><first>Judy Hanwen</first><last>Shen</last></author>
      <author><first>Asma</first><last>Ghandeharioun</last></author>
      <author><first>Craig</first><last>Ferguson</last></author>
      <author><first>Agata</first><last>Lapedriza</last></author>
      <author><first>Noah</first><last>Jones</last></author>
      <author><first>Shixiang</first><last>Gu</last></author>
      <author><first>Rosalind</first><last>Picard</last></author>
      <pages>3985–4003</pages>
      <url hash="d54fafeb">2020.emnlp-main.327</url>
    </paper>
    <paper id="328">
      <title>Speakers Fill Semantic Gaps with Context</title>
      <author><first>Tiago</first><last>Pimentel</last></author>
      <author><first>Rowan</first><last>Hall Maudslay</last></author>
      <author><first>Damian</first><last>Blasi</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <pages>4004–4015</pages>
      <url hash="34b16d37">2020.emnlp-main.328</url>
    </paper>
    <paper id="329">
      <title>Investigating Cross-Linguistic Adjective Ordering Tendencies with a Latent-Variable Model</title>
      <author><first>Jun Yen</first><last>Leung</last></author>
      <author><first>Guy</first><last>Emerson</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <pages>4016–4028</pages>
      <url hash="afe65b8a">2020.emnlp-main.329</url>
    </paper>
    <paper id="330">
      <title>Surprisal Predicts Code-Switching in <fixed-case>C</fixed-case>hinese-<fixed-case>E</fixed-case>nglish Bilingual Text</title>
      <author><first>Jesús</first><last>Calvillo</last></author>
      <author><first>Le</first><last>Fang</last></author>
      <author><first>Jeremy</first><last>Cole</last></author>
      <author><first>David</first><last>Reitter</last></author>
      <pages>4029–4039</pages>
      <url hash="cb78cf9e">2020.emnlp-main.330</url>
    </paper>
    <paper id="331">
      <title>Investigating Lexical Variability in Language Models</title>
      <author><first>Charles</first><last>Yu</last></author>
      <author><first>Ryan</first><last>Sie</last></author>
      <author><first>Nicolas</first><last>Tedeschi</last></author>
      <author><first>Leon</first><last>Bergen</last></author>
      <pages>4040–4054</pages>
      <url hash="dd0d674d">2020.emnlp-main.331</url>
    </paper>
    <paper id="332">
      <title>Improving Word Sense Disambiguation with Translations</title>
      <author><first>Yixing</first><last>Luan</last></author>
      <author><first>Bradley</first><last>Hauer</last></author>
      <author><first>Lili</first><last>Mou</last></author>
      <author><first>Grzegorz</first><last>Kondrak</last></author>
      <pages>4055–4065</pages>
      <url hash="fe4f1994">2020.emnlp-main.332</url>
    </paper>
    <paper id="333">
      <title>Towards Better Context-aware Lexical Semantics: Adjusting Contextualized Representations through Static Anchors</title>
      <author><first>Qianchu</first><last>Liu</last></author>
      <author><first>Diana</first><last>McCarthy</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>4066–4075</pages>
      <url hash="24571765">2020.emnlp-main.333</url>
    </paper>
    <paper id="334">
      <title>Compositional Demographic Word Embeddings</title>
      <author><first>Charles</first><last>Welch</last></author>
      <author><first>Jonathan K.</first><last>Kummerfeld</last></author>
      <author><first>Verónica</first><last>Pérez-Rosas</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>4076–4089</pages>
      <url hash="74c78b71">2020.emnlp-main.334</url>
    </paper>
    <paper id="335">
      <title>Do “Undocumented Immigrants” == “Illegal Aliens”? Differentiating Denotation and Connotation in Vector Space</title>
      <author><first>Albert</first><last>Webson</last></author>
      <author><first>Zhizhong</first><last>Chen</last></author>
      <author><first>Carsten</first><last>Eickhoff</last></author>
      <author><first>Ellie</first><last>Pavlick</last></author>
      <pages>4090–4105</pages>
      <url hash="c7f21190">2020.emnlp-main.335</url>
    </paper>
    <paper id="336">
      <title>Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization</title>
      <author><first>Jiaao</first><last>Chen</last></author>
      <author><first>Diyi</first><last>Yang</last></author>
      <pages>4106–4118</pages>
      <url hash="f2cb285e">2020.emnlp-main.336</url>
    </paper>
    <paper id="337">
      <title>Few-Shot Learning for Opinion Summarization</title>
      <author><first>Arthur</first><last>Bražinskas</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <pages>4119–4135</pages>
      <url hash="e74ea355">2020.emnlp-main.337</url>
    </paper>
    <paper id="338">
      <title>Learning to Fuse Sentences with Transformers for Summarization</title>
      <author><first>Logan</first><last>Lebanoff</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Doo Soon</first><last>Kim</last></author>
      <author><first>Lidan</first><last>Wang</last></author>
      <author><first>Walter</first><last>Chang</last></author>
      <author id="fei-liu-utdallas"><first>Fei</first><last>Liu</last></author>
      <pages>4136–4142</pages>
      <url hash="4a285ca4">2020.emnlp-main.338</url>
    </paper>
    <paper id="339">
      <title>Stepwise Extractive Summarization and Planning with Structured Transformers</title>
      <author><first>Shashi</first><last>Narayan</last></author>
      <author><first>Joshua</first><last>Maynez</last></author>
      <author><first>Jakub</first><last>Adamek</last></author>
      <author><first>Daniele</first><last>Pighin</last></author>
      <author><first>Blaz</first><last>Bratanic</last></author>
      <author><first>Ryan</first><last>McDonald</last></author>
      <pages>4143–4159</pages>
      <url hash="49639e16">2020.emnlp-main.339</url>
    </paper>
    <paper id="340">
      <title><fixed-case>CLIRM</fixed-case>atrix: A Massively Large Collection of Bilingual and Multilingual Datasets for Cross-Lingual Information Retrieval</title>
      <author><first>Shuo</first><last>Sun</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <pages>4160–4170</pages>
      <url hash="c5bc2212">2020.emnlp-main.340</url>
    </paper>
    <paper id="341">
      <title><fixed-case>SLEDGE</fixed-case>: A Simple Yet Effective Zero-Shot Baseline for Coronavirus Scientific Knowledge Search</title>
      <author><first>Sean</first><last>MacAvaney</last></author>
      <author><first>Arman</first><last>Cohan</last></author>
      <author><first>Nazli</first><last>Goharian</last></author>
      <pages>4171–4179</pages>
      <url hash="fd8ca82e">2020.emnlp-main.341</url>
    </paper>
    <paper id="342">
      <title>Modularized Transfomer-based Ranking Framework</title>
      <author><first>Luyu</first><last>Gao</last></author>
      <author><first>Zhuyun</first><last>Dai</last></author>
      <author><first>Jamie</first><last>Callan</last></author>
      <pages>4180–4190</pages>
      <url hash="e97c11e7">2020.emnlp-main.342</url>
    </paper>
    <paper id="343">
      <title>Ad-hoc Document Retrieval Using Weak-Supervision with <fixed-case>BERT</fixed-case> and <fixed-case>GPT</fixed-case>2</title>
      <author><first>Yosi</first><last>Mass</last></author>
      <author><first>Haggai</first><last>Roitman</last></author>
      <pages>4191–4197</pages>
      <url hash="b54d969e">2020.emnlp-main.343</url>
    </paper>
    <paper id="344">
      <title>Adversarial Semantic Collisions</title>
      <author><first>Congzheng</first><last>Song</last></author>
      <author><first>Alexander</first><last>Rush</last></author>
      <author><first>Vitaly</first><last>Shmatikov</last></author>
      <pages>4198–4210</pages>
      <url hash="815cfb60">2020.emnlp-main.344</url>
    </paper>
    <paper id="345">
      <title>Learning Explainable Linguistic Expressions with Neural Inductive Logic Programming for Sentence Classification</title>
      <author><first>Prithviraj</first><last>Sen</last></author>
      <author><first>Marina</first><last>Danilevsky</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>Siddhartha</first><last>Brahma</last></author>
      <author><first>Matthias</first><last>Boehm</last></author>
      <author><first>Laura</first><last>Chiticariu</last></author>
      <author><first>Rajasekar</first><last>Krishnamurthy</last></author>
      <pages>4211–4221</pages>
      <url hash="a78613a0">2020.emnlp-main.345</url>
    </paper>
    <paper id="346">
      <title>Eliciting Knowledge from Language Models Using Automatically Generated Prompts</title>
      <author><first>Taylor</first><last>Shin</last></author>
      <author><first>Yasaman</first><last>Razeghi</last></author>
      <author><first>Robert L.</first><last>Logan IV</last></author>
      <author><first>Eric</first><last>Wallace</last></author>
      <author><first>Sameer</first><last>Singh</last></author>
      <pages>4222–4235</pages>
      <url hash="a0afc13a">2020.emnlp-main.346</url>
    </paper>
    <paper id="347">
      <title>Learning Variational Word Masks to Improve the Interpretability of Neural Text Classifiers</title>
      <author><first>Hanjie</first><last>Chen</last></author>
      <author><first>Yangfeng</first><last>Ji</last></author>
      <pages>4236–4251</pages>
      <url hash="b9e24f4a">2020.emnlp-main.347</url>
    </paper>
    <paper id="348">
      <title>Sparse Text Generation</title>
      <author><first>Pedro Henrique</first><last>Martins</last></author>
      <author><first>Zita</first><last>Marinho</last></author>
      <author><first>André F. T.</first><last>Martins</last></author>
      <pages>4252–4273</pages>
      <url hash="7ce47f1b">2020.emnlp-main.348</url>
    </paper>
    <paper id="349">
      <title><fixed-case>P</fixed-case>lot<fixed-case>M</fixed-case>achines: Outline-Conditioned Generation with Dynamic Plot State Tracking</title>
      <author><first>Hannah</first><last>Rashkin</last></author>
      <author><first>Asli</first><last>Celikyilmaz</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <pages>4274–4295</pages>
      <url hash="a958f8ec">2020.emnlp-main.349</url>
    </paper>
    <paper id="350">
      <title>Do Sequence-to-sequence <fixed-case>VAE</fixed-case>s Learn Global Features of Sentences?</title>
      <author><first>Tom</first><last>Bosc</last></author>
      <author><first>Pascal</first><last>Vincent</last></author>
      <pages>4296–4318</pages>
      <url hash="d3d3812e">2020.emnlp-main.350</url>
    </paper>
    <paper id="351">
      <title>Content Planning for Neural Story Generation with Aristotelian Rescoring</title>
      <author><first>Seraphina</first><last>Goldfarb-Tarrant</last></author>
      <author><first>Tuhin</first><last>Chakrabarty</last></author>
      <author><first>Ralph</first><last>Weischedel</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <pages>4319–4338</pages>
      <url hash="3952a4f4">2020.emnlp-main.351</url>
    </paper>
    <paper id="352">
      <title>Generating Dialogue Responses from a Semantic Latent Space</title>
      <author><first>Wei-Jen</first><last>Ko</last></author>
      <author><first>Avik</first><last>Ray</last></author>
      <author><first>Yilin</first><last>Shen</last></author>
      <author><first>Hongxia</first><last>Jin</last></author>
      <pages>4339–4349</pages>
      <url hash="c5e15cb9">2020.emnlp-main.352</url>
    </paper>
    <paper id="353">
      <title>Refer, Reuse, Reduce: Grounding Subsequent References in Visual and Conversational Contexts</title>
      <author><first>Ece</first><last>Takmaz</last></author>
      <author><first>Mario</first><last>Giulianelli</last></author>
      <author><first>Sandro</first><last>Pezzelle</last></author>
      <author><first>Arabella</first><last>Sinclair</last></author>
      <author><first>Raquel</first><last>Fernández</last></author>
      <pages>4350–4368</pages>
      <url hash="efd942ee">2020.emnlp-main.353</url>
    </paper>
    <paper id="354">
      <title>Visually Grounded Compound <fixed-case>PCFG</fixed-case>s</title>
      <author><first>Yanpeng</first><last>Zhao</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <pages>4369–4379</pages>
      <url hash="ba14558a">2020.emnlp-main.354</url>
    </paper>
    <paper id="355">
      <title><fixed-case>ALICE</fixed-case>: Active Learning with Contrastive Natural Language Explanations</title>
      <author><first>Weixin</first><last>Liang</last></author>
      <author><first>James</first><last>Zou</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <pages>4380–4391</pages>
      <url hash="a5e4762c">2020.emnlp-main.355</url>
    </paper>
    <paper id="356">
      <title>Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense Spatiotemporal Grounding</title>
      <author><first>Alexander</first><last>Ku</last></author>
      <author><first>Peter</first><last>Anderson</last></author>
      <author><first>Roma</first><last>Patel</last></author>
      <author><first>Eugene</first><last>Ie</last></author>
      <author><first>Jason</first><last>Baldridge</last></author>
      <pages>4392–4412</pages>
      <url hash="bcf1c408">2020.emnlp-main.356</url>
    </paper>
    <paper id="357">
      <title>Iterative Language-Based Image Editing via Self-Supervised Counterfactual Reasoning</title>
      <author><first>Tsu-Jui</first><last>Fu</last></author>
      <author><first>Xin</first><last>Wang</last></author>
      <author><first>Scott</first><last>Grafton</last></author>
      <author><first>Miguel</first><last>Eckstein</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>4413–4422</pages>
      <url hash="1b0ba01d">2020.emnlp-main.357</url>
    </paper>
    <paper id="358">
      <title>Identifying Elements Essential for <fixed-case>BERT</fixed-case>’s Multilinguality</title>
      <author><first>Philipp</first><last>Dufter</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>4423–4437</pages>
      <url hash="55f43c8d">2020.emnlp-main.358</url>
    </paper>
    <paper id="359">
      <title>On Negative Interference in Multilingual Language Models</title>
      <author><first>Zirui</first><last>Wang</last></author>
      <author><first>Zachary C.</first><last>Lipton</last></author>
      <author><first>Yulia</first><last>Tsvetkov</last></author>
      <pages>4438–4450</pages>
      <url hash="0391ac68">2020.emnlp-main.359</url>
    </paper>
    <paper id="360">
      <title>Pre-tokenization of Multi-word Expressions in Cross-lingual Word Embeddings</title>
      <author><first>Naoki</first><last>Otani</last></author>
      <author><first>Satoru</first><last>Ozaki</last></author>
      <author><first>Xingyuan</first><last>Zhao</last></author>
      <author><first>Yucen</first><last>Li</last></author>
      <author><first>Micaelah</first><last>St Johns</last></author>
      <author><first>Lori</first><last>Levin</last></author>
      <pages>4451–4464</pages>
      <url hash="6ec20025">2020.emnlp-main.360</url>
    </paper>
    <paper id="361">
      <title>Language Adapters for Zero Shot Neural Machine Translation</title>
      <author><first>Jerin</first><last>Philip</last></author>
      <author><first>Alexandre</first><last>Berard</last></author>
      <author><first>Matthias</first><last>Gallé</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <pages>4465–4470</pages>
      <url hash="ac9dd113">2020.emnlp-main.361</url>
    </paper>
    <paper id="362">
      <title>Do Explicit Alignments Robustly Improve Massively Multilingual Encoders?</title>
      <author><first>Shijie</first><last>Wu</last></author>
      <author><first>Mark</first><last>Dredze</last></author>
      <pages>4471–4482</pages>
      <url hash="9e4ddabf">2020.emnlp-main.362</url>
    </paper>
    <paper id="363">
      <title>From Zero to Hero: On the Limitations of Zero-Shot Language Transfer with Multilingual Transformers</title>
      <author><first>Anne</first><last>Lauscher</last></author>
      <author><first>Vinit</first><last>Ravishankar</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Goran</first><last>Glavaš</last></author>
      <pages>4483–4499</pages>
      <url hash="88ba5755">2020.emnlp-main.363</url>
      <attachment type="OptionalSupplementaryMaterial" hash="dd79d8d8">2020.emnlp-main.363.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="364">
      <title>Distilling Multiple Domains for Neural Machine Translation</title>
      <author><first>Anna</first><last>Currey</last></author>
      <author><first>Prashant</first><last>Mathur</last></author>
      <author><first>Georgiana</first><last>Dinu</last></author>
      <pages>4500–4511</pages>
      <url hash="7fa8aa74">2020.emnlp-main.364</url>
    </paper>
    <paper id="365">
      <title>Making Monolingual Sentence Embeddings Multilingual Using Knowledge Distillation</title>
      <author><first>Nils</first><last>Reimers</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>4512–4525</pages>
      <url hash="10074da0">2020.emnlp-main.365</url>
    </paper>
    <paper id="366">
      <title>A Streaming Approach for Efficient Batched Beam Search</title>
      <author><first>Kevin</first><last>Yang</last></author>
      <author><first>Violet</first><last>Yao</last></author>
      <author><first>John</first><last>DeNero</last></author>
      <author><first>Dan</first><last>Klein</last></author>
      <pages>4526–4535</pages>
      <url hash="48f38d03">2020.emnlp-main.366</url>
    </paper>
    <paper id="367">
      <title>Improving Multilingual Models with Language-Clustered Vocabularies</title>
      <author><first>Hyung Won</first><last>Chung</last></author>
      <author><first>Dan</first><last>Garrette</last></author>
      <author><first>Kiat Chuan</first><last>Tan</last></author>
      <author><first>Jason</first><last>Riesa</last></author>
      <pages>4536–4546</pages>
      <url hash="6e589130">2020.emnlp-main.367</url>
    </paper>
    <paper id="368">
      <title>Zero-Shot Cross-Lingual Transfer with Meta Learning</title>
      <author><first>Farhad</first><last>Nooralahzadeh</last></author>
      <author><first>Giannis</first><last>Bekoulis</last></author>
      <author><first>Johannes</first><last>Bjerva</last></author>
      <author><first>Isabelle</first><last>Augenstein</last></author>
      <pages>4547–4562</pages>
      <url hash="c066806d">2020.emnlp-main.368</url>
    </paper>
    <paper id="369">
      <title>The Multilingual <fixed-case>A</fixed-case>mazon Reviews Corpus</title>
      <author><first>Phillip</first><last>Keung</last></author>
      <author><first>Yichao</first><last>Lu</last></author>
      <author><first>György</first><last>Szarvas</last></author>
      <author><first>Noah A.</first><last>Smith</last></author>
      <pages>4563–4568</pages>
      <url hash="dc216e03">2020.emnlp-main.369</url>
    </paper>
    <paper id="370">
      <title><fixed-case>GLUCOSE</fixed-case>: <fixed-case>G</fixed-case>enera<fixed-case>L</fixed-case>ized and <fixed-case>CO</fixed-case>ntextualized Story Explanations</title>
      <author><first>Nasrin</first><last>Mostafazadeh</last></author>
      <author><first>Aditya</first><last>Kalyanpur</last></author>
      <author><first>Lori</first><last>Moon</last></author>
      <author><first>David</first><last>Buchanan</last></author>
      <author><first>Lauren</first><last>Berkowitz</last></author>
      <author><first>Or</first><last>Biran</last></author>
      <author><first>Jennifer</first><last>Chu-Carroll</last></author>
      <pages>4569–4586</pages>
      <url hash="a796940c">2020.emnlp-main.370</url>
    </paper>
    <paper id="371">
      <title>Character-level Representations Still Improve Semantic Parsing in the Age of <fixed-case>BERT</fixed-case></title>
      <author><first>Rik</first><last>van Noord</last></author>
      <author><first>Antonio</first><last>Toral</last></author>
      <author><first>Johan</first><last>Bos</last></author>
      <pages>4587–4603</pages>
      <url hash="66c27261">2020.emnlp-main.371</url>
    </paper>
    <paper id="372">
      <title>Infusing Disease Knowledge into <fixed-case>BERT</fixed-case> for Health Question Answering, Medical Inference and Disease Name Recognition</title>
      <author><first>Yun</first><last>He</last></author>
      <author><first>Ziwei</first><last>Zhu</last></author>
      <author><first>Yin</first><last>Zhang</last></author>
      <author><first>Qin</first><last>Chen</last></author>
      <author><first>James</first><last>Caverlee</last></author>
      <pages>4604–4614</pages>
      <url hash="6e6c0a8f">2020.emnlp-main.372</url>
    </paper>
    <paper id="373">
      <title>Unsupervised Commonsense Question Answering with Self-Talk</title>
      <author><first>Vered</first><last>Shwartz</last></author>
      <author><first>Peter</first><last>West</last></author>
      <author><first>Ronan</first><last>Le Bras</last></author>
      <author><first>Chandra</first><last>Bhagavatula</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>4615–4629</pages>
      <url hash="a94971e3">2020.emnlp-main.373</url>
    </paper>
    <paper id="374">
      <title>Reasoning about Goals, Steps, and Temporal Ordering with <fixed-case>W</fixed-case>iki<fixed-case>H</fixed-case>ow</title>
      <author><first>Li</first><last>Zhang</last></author>
      <author><first>Qing</first><last>Lyu</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>4630–4639</pages>
      <url hash="d19de4f7">2020.emnlp-main.374</url>
      <attachment type="OptionalSupplementaryMaterial" hash="1d54a5fe">2020.emnlp-main.374.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="375">
      <title>Structural Supervision Improves Few-Shot Learning and Syntactic Generalization in Neural Language Models</title>
      <author><first>Ethan</first><last>Wilcox</last></author>
      <author><first>Peng</first><last>Qian</last></author>
      <author><first>Richard</first><last>Futrell</last></author>
      <author><first>Ryosuke</first><last>Kohita</last></author>
      <author><first>Roger</first><last>Levy</last></author>
      <author><first>Miguel</first><last>Ballesteros</last></author>
      <pages>4640–4652</pages>
      <url hash="cb5d7aca">2020.emnlp-main.375</url>
    </paper>
    <paper id="376">
      <title>Investigating Representations of Verb Bias in Neural Language Models</title>
      <author><first>Robert</first><last>Hawkins</last></author>
      <author><first>Takateru</first><last>Yamakoshi</last></author>
      <author><first>Thomas</first><last>Griffiths</last></author>
      <author><first>Adele</first><last>Goldberg</last></author>
      <pages>4653–4663</pages>
      <url hash="699476bd">2020.emnlp-main.376</url>
    </paper>
    <paper id="377">
      <title>Generating Image Descriptions via Sequential Cross-Modal Alignment Guided by Human Gaze</title>
      <author><first>Ece</first><last>Takmaz</last></author>
      <author><first>Sandro</first><last>Pezzelle</last></author>
      <author><first>Lisa</first><last>Beinborn</last></author>
      <author><first>Raquel</first><last>Fernández</last></author>
      <pages>4664–4677</pages>
      <url hash="f6cd4cb4">2020.emnlp-main.377</url>
    </paper>
    <paper id="378">
      <title>Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space</title>
      <author><first>Chunyuan</first><last>Li</last></author>
      <author><first>Xiang</first><last>Gao</last></author>
      <author><first>Yuan</first><last>Li</last></author>
      <author><first>Baolin</first><last>Peng</last></author>
      <author><first>Xiujun</first><last>Li</last></author>
      <author><first>Yizhe</first><last>Zhang</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <pages>4678–4699</pages>
      <url hash="f49a10a1">2020.emnlp-main.378</url>
    </paper>
    <paper id="379">
      <title>Bio-Megatron: Larger Biomedical Domain Language Model</title>
      <author><first>Hoo-Chang</first><last>Shin</last></author>
      <author><first>Yang</first><last>Zhang</last></author>
      <author><first>Evelina</first><last>Bakhturina</last></author>
      <author><first>Raul</first><last>Puri</last></author>
      <author><first>Mostofa</first><last>Patwary</last></author>
      <author><first>Mohammad</first><last>Shoeybi</last></author>
      <author><first>Raghav</first><last>Mani</last></author>
      <pages>4700–4706</pages>
      <url hash="f18bf705">2020.emnlp-main.379</url>
    </paper>
    <paper id="380">
      <title>Text Segmentation by Cross Segment Attention</title>
      <author><first>Michal</first><last>Lukasik</last></author>
      <author><first>Boris</first><last>Dadachev</last></author>
      <author><first>Kishore</first><last>Papineni</last></author>
      <author><first>Goncalo</first><last>Simoes</last></author>
      <pages>4707–4716</pages>
      <url hash="ff3fb0c1">2020.emnlp-main.380</url>
    </paper>
    <paper id="381">
      <title><fixed-case>R</fixed-case>ussian<fixed-case>S</fixed-case>uper<fixed-case>GLUE</fixed-case>: A <fixed-case>R</fixed-case>ussian Language Understanding Evaluation Benchmark</title>
      <author><first>Tatiana</first><last>Shavrina</last></author>
      <author><first>Alena</first><last>Fenogenova</last></author>
      <author><first>Emelyanov</first><last>Anton</last></author>
      <author><first>Denis</first><last>Shevelev</last></author>
      <author><first>Ekaterina</first><last>Artemova</last></author>
      <author><first>Valentin</first><last>Malykh</last></author>
      <author><first>Vladislav</first><last>Mikhailov</last></author>
      <author><first>Maria</first><last>Tikhonova</last></author>
      <author><first>Andrey</first><last>Chertok</last></author>
      <author><first>Andrey</first><last>Evlampiev</last></author>
      <pages>4717–4726</pages>
      <url hash="f6616264">2020.emnlp-main.381</url>
    </paper>
    <paper id="382">
      <title>An Empirical Study of Pre-trained Transformers for <fixed-case>A</fixed-case>rabic Information Extraction</title>
      <author><first>Wuwei</first><last>Lan</last></author>
      <author><first>Yang</first><last>Chen</last></author>
      <author><first>Wei</first><last>Xu</last></author>
      <author><first>Alan</first><last>Ritter</last></author>
      <pages>4727–4734</pages>
      <url hash="fb321231">2020.emnlp-main.382</url>
    </paper>
    <paper id="383">
      <title><fixed-case>TNT</fixed-case>: Text Normalization Based Pre-training of Transformers for Content Moderation</title>
      <author><first>Fei</first><last>Tan</last></author>
      <author><first>Yifan</first><last>Hu</last></author>
      <author><first>Changwei</first><last>Hu</last></author>
      <author><first>Keqian</first><last>Li</last></author>
      <author><first>Kevin</first><last>Yen</last></author>
      <pages>4735–4741</pages>
      <url hash="1cb704f9">2020.emnlp-main.383</url>
    </paper>
    <paper id="384">
      <title>Methods for Numeracy-Preserving Word Embeddings</title>
      <author><first>Dhanasekar</first><last>Sundararaman</last></author>
      <author><first>Shijing</first><last>Si</last></author>
      <author><first>Vivek</first><last>Subramanian</last></author>
      <author><first>Guoyin</first><last>Wang</last></author>
      <author><first>Devamanyu</first><last>Hazarika</last></author>
      <author><first>Lawrence</first><last>Carin</last></author>
      <pages>4742–4753</pages>
      <url hash="632811ad">2020.emnlp-main.384</url>
    </paper>
    <paper id="385">
      <title>An Empirical Investigation of Contextualized Number Prediction</title>
      <author><first>Taylor</first><last>Berg-Kirkpatrick</last></author>
      <author><first>Daniel</first><last>Spokoyny</last></author>
      <pages>4754–4764</pages>
      <url hash="aa29c7dd">2020.emnlp-main.385</url>
    </paper>
    <paper id="386">
      <title>Modeling the Music Genre Perception across Language-Bound Cultures</title>
      <author><first>Elena V.</first><last>Epure</last></author>
      <author><first>Guillaume</first><last>Salha</last></author>
      <author><first>Manuel</first><last>Moussallam</last></author>
      <author><first>Romain</first><last>Hennequin</last></author>
      <pages>4765–4779</pages>
      <url hash="5bb50e07">2020.emnlp-main.386</url>
    </paper>
    <paper id="387">
      <title>Joint Estimation and Analysis of Risk Behavior Ratings in Movie Scripts</title>
      <author><first>Victor</first><last>Martinez</last></author>
      <author><first>Krishna</first><last>Somandepalli</last></author>
      <author><first>Yalda</first><last>Tehranian-Uhls</last></author>
      <author><first>Shrikanth</first><last>Narayanan</last></author>
      <pages>4780–4790</pages>
      <url hash="7e37a4e2">2020.emnlp-main.387</url>
    </paper>
    <paper id="388">
      <title>Keep It Surprisingly Simple: A Simple First Order Graph Based Parsing Model for Joint Morphosyntactic Parsing in <fixed-case>S</fixed-case>anskrit</title>
      <author><first>Amrith</first><last>Krishna</last></author>
      <author><first>Ashim</first><last>Gupta</last></author>
      <author><first>Deepak</first><last>Garasangi</last></author>
      <author><first>Pavankumar</first><last>Satuluri</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <pages>4791–4797</pages>
      <url hash="399d7116">2020.emnlp-main.388</url>
      <attachment type="OptionalSupplementaryMaterial" hash="0676f75f">2020.emnlp-main.388.OptionalSupplementaryMaterial.pdf</attachment>
    </paper>
    <paper id="389">
      <title>Unsupervised Parsing via Constituency Tests</title>
      <author><first>Steven</first><last>Cao</last></author>
      <author><first>Nikita</first><last>Kitaev</last></author>
      <author><first>Dan</first><last>Klein</last></author>
      <pages>4798–4808</pages>
      <url hash="12cc14bd">2020.emnlp-main.389</url>
    </paper>
    <paper id="390">
      <title>Please Mind the Root: Decoding Arborescences for Dependency Parsing</title>
      <author><first>Ran</first><last>Zmigrod</last></author>
      <author><first>Tim</first><last>Vieira</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <pages>4809–4819</pages>
      <url hash="b880be25">2020.emnlp-main.390</url>
    </paper>
    <paper id="391">
      <title>Unsupervised Cross-Lingual Part-of-Speech Tagging for Truly Low-Resource Scenarios</title>
      <author><first>Ramy</first><last>Eskander</last></author>
      <author><first>Smaranda</first><last>Muresan</last></author>
      <author><first>Michael</first><last>Collins</last></author>
      <pages>4820–4831</pages>
      <url hash="3d5e5522">2020.emnlp-main.391</url>
    </paper>
    <paper id="392">
      <title>Unsupervised Parsing with <fixed-case>S</fixed-case>-<fixed-case>DIORA</fixed-case>: Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders</title>
      <author><first>Andrew</first><last>Drozdov</last></author>
      <author><first>Subendhu</first><last>Rongali</last></author>
      <author><first>Yi-Pei</first><last>Chen</last></author>
      <author><first>Tim</first><last>O’Gorman</last></author>
      <author><first>Mohit</first><last>Iyyer</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>4832–4845</pages>
      <url hash="02dc69d3">2020.emnlp-main.392</url>
    </paper>
    <paper id="393">
      <title>Utility Is in the Eye of the User: A Critique of <fixed-case>NLP</fixed-case> Leaderboard Design</title>
      <author><first>Kawin</first><last>Ethayarajh</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <pages>4846–4853</pages>
      <url hash="1d00c9e1">2020.emnlp-main.393</url>
    </paper>
    <paper id="394">
      <title>An Empirical Investigation towards Efficient Multi-Domain Language Model Pre-training</title>
      <author><first>Kristjan</first><last>Arumae</last></author>
      <author><first>Qing</first><last>Sun</last></author>
      <author><first>Parminder</first><last>Bhatia</last></author>
      <pages>4854–4864</pages>
      <url hash="d390d905">2020.emnlp-main.394</url>
    </paper>
    <paper id="395">
      <title>Analyzing Individual Neurons in Pre-trained Language Models</title>
      <author><first>Nadir</first><last>Durrani</last></author>
      <author><first>Hassan</first><last>Sajjad</last></author>
      <author><first>Fahim</first><last>Dalvi</last></author>
      <author><first>Yonatan</first><last>Belinkov</last></author>
      <pages>4865–4880</pages>
      <url hash="7f2c2933">2020.emnlp-main.395</url>
    </paper>
    <paper id="396">
      <title>Dissecting Span Identification Tasks with Performance Prediction</title>
      <author><first>Sean</first><last>Papay</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <author><first>Sebastian</first><last>Padó</last></author>
      <pages>4881–4895</pages>
      <url hash="47e5ea30">2020.emnlp-main.396</url>
    </paper>
    <paper id="397">
      <title>Assessing Phrasal Representation and Composition in Transformers</title>
      <author><first>Lang</first><last>Yu</last></author>
      <author><first>Allyson</first><last>Ettinger</last></author>
      <pages>4896–4907</pages>
      <url hash="7b384713">2020.emnlp-main.397</url>
    </paper>
    <paper id="398">
      <title>Analyzing Redundancy in Pretrained Transformer Models</title>
      <author><first>Fahim</first><last>Dalvi</last></author>
      <author><first>Hassan</first><last>Sajjad</last></author>
      <author><first>Nadir</first><last>Durrani</last></author>
      <author><first>Yonatan</first><last>Belinkov</last></author>
      <pages>4908–4926</pages>
      <url hash="432fe13e">2020.emnlp-main.398</url>
    </paper>
    <paper id="399">
      <title>Be More with Less: Hypergraph Attention Networks for Inductive Text Classification</title>
      <author><first>Kaize</first><last>Ding</last></author>
      <author><first>Jianling</first><last>Wang</last></author>
      <author><first>Jundong</first><last>Li</last></author>
      <author><first>Dingcheng</first><last>Li</last></author>
      <author><first>Huan</first><last>Liu</last></author>
      <pages>4927–4936</pages>
      <url hash="2e704c8c">2020.emnlp-main.399</url>
    </paper>
    <paper id="400">
      <title>Entities as Experts: Sparse Memory Access with Entity Supervision</title>
      <author><first>Thibault</first><last>Févry</last></author>
      <author><first>Livio</first><last>Baldini Soares</last></author>
      <author><first>Nicholas</first><last>FitzGerald</last></author>
      <author><first>Eunsol</first><last>Choi</last></author>
      <author><first>Tom</first><last>Kwiatkowski</last></author>
      <pages>4937–4951</pages>
      <url hash="697ad17c">2020.emnlp-main.400</url>
    </paper>
    <paper id="401">
      <title><fixed-case>H</fixed-case>2<fixed-case>KGAT</fixed-case>: Hierarchical Hyperbolic Knowledge Graph Attention Network</title>
      <author><first>Shen</first><last>Wang</last></author>
      <author><first>Xiaokai</first><last>Wei</last></author>
      <author><first>Cicero</first><last>Nogueira dos Santos</last></author>
      <author><first>Zhiguo</first><last>Wang</last></author>
      <author><first>Ramesh</first><last>Nallapati</last></author>
      <author><first>Andrew</first><last>Arnold</last></author>
      <author><first>Bing</first><last>Xiang</last></author>
      <author><first>Philip S.</first><last>Yu</last></author>
      <pages>4952–4962</pages>
      <url hash="d3e37f55">2020.emnlp-main.401</url>
    </paper>
    <paper id="402">
      <title>Does the Objective Matter? Comparing Training Objectives for Pronoun Resolution</title>
      <author><first>Yordan</first><last>Yordanov</last></author>
      <author><first>Oana-Maria</first><last>Camburu</last></author>
      <author><first>Vid</first><last>Kocijan</last></author>
      <author><first>Thomas</first><last>Lukasiewicz</last></author>
      <pages>4963–4969</pages>
      <url hash="c0346195">2020.emnlp-main.402</url>
    </paper>
    <paper id="403">
      <title>On Losses for Modern Language Models</title>
      <author><first>Stéphane</first><last>Aroca-Ouellette</last></author>
      <author><first>Frank</first><last>Rudzicz</last></author>
      <pages>4970–4981</pages>
      <url hash="64c38f1f">2020.emnlp-main.403</url>
    </paper>
    <paper id="404">
      <title>We Can Detect Your Bias: Predicting the Political Ideology of News Articles</title>
      <author><first>Ramy</first><last>Baly</last></author>
      <author><first>Giovanni</first><last>Da San Martino</last></author>
      <author><first>James</first><last>Glass</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>4982–4991</pages>
      <url hash="c7cbc4d4">2020.emnlp-main.404</url>
    </paper>
    <paper id="405">
      <title>Semantic Label Smoothing for Sequence to Sequence Problems</title>
      <author><first>Michal</first><last>Lukasik</last></author>
      <author><first>Himanshu</first><last>Jain</last></author>
      <author><first>Aditya</first><last>Menon</last></author>
      <author><first>Seungyeon</first><last>Kim</last></author>
      <author><first>Srinadh</first><last>Bhojanapalli</last></author>
      <author><first>Felix</first><last>Yu</last></author>
      <author><first>Sanjiv</first><last>Kumar</last></author>
      <pages>4992–4998</pages>
      <url hash="fd8496f4">2020.emnlp-main.405</url>
    </paper>
    <paper id="406">
      <title>Training for <fixed-case>G</fixed-case>ibbs Sampling on Conditional Random Fields with Neural Scoring Factors</title>
      <author><first>Sida</first><last>Gao</last></author>
      <author><first>Matthew R.</first><last>Gormley</last></author>
      <pages>4999–5011</pages>
      <url hash="e4bc187b">2020.emnlp-main.406</url>
    </paper>
    <paper id="407">
      <title>Multilevel Text Alignment with Cross-Document Attention</title>
      <author><first>Xuhui</first><last>Zhou</last></author>
      <author><first>Nikolaos</first><last>Pappas</last></author>
      <author><first>Noah A.</first><last>Smith</last></author>
      <pages>5012–5025</pages>
      <url hash="b20b6d53">2020.emnlp-main.407</url>
    </paper>
    <paper id="408">
      <title>Conversational Semantic Parsing</title>
      <author><first>Armen</first><last>Aghajanyan</last></author>
      <author><first>Jean</first><last>Maillard</last></author>
      <author><first>Akshat</first><last>Shrivastava</last></author>
      <author><first>Keith</first><last>Diedrick</last></author>
      <author><first>Michael</first><last>Haeger</last></author>
      <author><first>Haoran</first><last>Li</last></author>
      <author><first>Yashar</first><last>Mehdad</last></author>
      <author><first>Veselin</first><last>Stoyanov</last></author>
      <author><first>Anuj</first><last>Kumar</last></author>
      <author><first>Mike</first><last>Lewis</last></author>
      <author><first>Sonal</first><last>Gupta</last></author>
      <pages>5026–5035</pages>
      <url hash="96ffc899">2020.emnlp-main.408</url>
    </paper>
    <paper id="409">
      <title>Probing Task-Oriented Dialogue Representation from Language Models</title>
      <author><first>Chien-Sheng</first><last>Wu</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <pages>5036–5051</pages>
      <url hash="c9bc881b">2020.emnlp-main.409</url>
    </paper>
    <paper id="410">
      <title>End-to-End Slot Alignment and Recognition for Cross-Lingual <fixed-case>NLU</fixed-case></title>
      <author><first>Weijia</first><last>Xu</last></author>
      <author><first>Batool</first><last>Haider</last></author>
      <author><first>Saab</first><last>Mansour</last></author>
      <pages>5052–5063</pages>
      <url hash="4b421bda">2020.emnlp-main.410</url>
      <attachment type="OptionalSupplementaryMaterial" hash="2c903da3">2020.emnlp-main.410.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="411">
      <title>Discriminative Nearest Neighbor Few-Shot Intent Detection by Transferring Natural Language Inference</title>
      <author><first>Jianguo</first><last>Zhang</last></author>
      <author><first>Kazuma</first><last>Hashimoto</last></author>
      <author><first>Wenhao</first><last>Liu</last></author>
      <author><first>Chien-Sheng</first><last>Wu</last></author>
      <author><first>Yao</first><last>Wan</last></author>
      <author><first>Philip</first><last>Yu</last></author>
      <author><first>Richard</first><last>Socher</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <pages>5064–5082</pages>
      <url hash="ecc1335a">2020.emnlp-main.411</url>
    </paper>
    <paper id="412">
      <title>Simple Data Augmentation with the Mask Token Improves Domain Adaptation for Dialog Act Tagging</title>
      <author><first>Semih</first><last>Yavuz</last></author>
      <author><first>Kazuma</first><last>Hashimoto</last></author>
      <author><first>Wenhao</first><last>Liu</last></author>
      <author><first>Nitish Shirish</first><last>Keskar</last></author>
      <author><first>Richard</first><last>Socher</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <pages>5083–5089</pages>
      <url hash="830c79f0">2020.emnlp-main.412</url>
    </paper>
    <paper id="413">
      <title>Low-Resource Domain Adaptation for Compositional Task-Oriented Semantic Parsing</title>
      <author><first>Xilun</first><last>Chen</last></author>
      <author><first>Asish</first><last>Ghoshal</last></author>
      <author><first>Yashar</first><last>Mehdad</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <author><first>Sonal</first><last>Gupta</last></author>
      <pages>5090–5100</pages>
      <url hash="587c127f">2020.emnlp-main.413</url>
    </paper>
    <paper id="414">
      <title>Sound Natural: Content Rephrasing in Dialog Systems</title>
      <author><first>Arash</first><last>Einolghozati</last></author>
      <author><first>Anchit</first><last>Gupta</last></author>
      <author><first>Keith</first><last>Diedrick</last></author>
      <author><first>Sonal</first><last>Gupta</last></author>
      <pages>5101–5108</pages>
      <url hash="dfdada62">2020.emnlp-main.414</url>
    </paper>
    <paper id="415">
      <title>Zero-Shot Crosslingual Sentence Simplification</title>
      <author><first>Jonathan</first><last>Mallinson</last></author>
      <author><first>Rico</first><last>Sennrich</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <pages>5109–5126</pages>
      <url hash="2058dcec">2020.emnlp-main.415</url>
    </paper>
    <paper id="416">
      <title>Facilitating the Communication of Politeness through Fine-Grained Paraphrasing</title>
      <author><first>Liye</first><last>Fu</last></author>
      <author><first>Susan</first><last>Fussell</last></author>
      <author><first>Cristian</first><last>Danescu-Niculescu-Mizil</last></author>
      <pages>5127–5140</pages>
      <url hash="2912edfd">2020.emnlp-main.416</url>
    </paper>
    <paper id="417">
      <title><fixed-case>CAT</fixed-case>-Gen: Improving Robustness in <fixed-case>NLP</fixed-case> Models via Controlled Adversarial Text Generation</title>
      <author><first>Tianlu</first><last>Wang</last></author>
      <author><first>Xuezhi</first><last>Wang</last></author>
      <author><first>Yao</first><last>Qin</last></author>
      <author><first>Ben</first><last>Packer</last></author>
      <author><first>Kang</first><last>Li</last></author>
      <author><first>Jilin</first><last>Chen</last></author>
      <author><first>Alex</first><last>Beutel</last></author>
      <author><first>Ed</first><last>Chi</last></author>
      <pages>5141–5146</pages>
      <url hash="7dded287">2020.emnlp-main.417</url>
    </paper>
    <paper id="418">
      <title><fixed-case>S</fixed-case>eq2<fixed-case>E</fixed-case>dits: Sequence Transduction Using Span-level Edit Operations</title>
      <author><first>Felix</first><last>Stahlberg</last></author>
      <author><first>Shankar</first><last>Kumar</last></author>
      <pages>5147–5159</pages>
      <url hash="66344daa">2020.emnlp-main.418</url>
      <attachment type="OptionalSupplementaryMaterial" hash="e5eac153">2020.emnlp-main.418.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="419">
      <title>Controllable Meaning Representation to Text Generation: Linearization and Data Augmentation Strategies</title>
      <author><first>Chris</first><last>Kedzie</last></author>
      <author><first>Kathleen</first><last>McKeown</last></author>
      <pages>5160–5185</pages>
      <url hash="5d951604">2020.emnlp-main.419</url>
    </paper>
    <paper id="420">
      <title>Blank Language Models</title>
      <author><first>Tianxiao</first><last>Shen</last></author>
      <author><first>Victor</first><last>Quach</last></author>
      <author><first>Regina</first><last>Barzilay</last></author>
      <author><first>Tommi</first><last>Jaakkola</last></author>
      <pages>5186–5198</pages>
      <url hash="14d4a583">2020.emnlp-main.420</url>
    </paper>
    <paper id="421">
      <title><fixed-case>COD</fixed-case>3<fixed-case>S</fixed-case>: Diverse Generation with Discrete Semantic Signatures</title>
      <author><first>Nathaniel</first><last>Weir</last></author>
      <author><first>João</first><last>Sedoc</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>5199–5211</pages>
      <url hash="01cdf491">2020.emnlp-main.421</url>
    </paper>
    <paper id="422">
      <title>Automatic Extraction of Rules Governing Morphological Agreement</title>
      <author><first>Aditi</first><last>Chaudhary</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Adithya</first><last>Pratapa</last></author>
      <author><first>David R.</first><last>Mortensen</last></author>
      <author><first>Zaid</first><last>Sheikh</last></author>
      <author><first>Yulia</first><last>Tsvetkov</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>5212–5236</pages>
      <url hash="ddc3a4eb">2020.emnlp-main.422</url>
    </paper>
    <paper id="423">
      <title>Tackling the Low-resource Challenge for Canonical Segmentation</title>
      <author><first>Manuel</first><last>Mager</last></author>
      <author><first>Özlem</first><last>Çetinoğlu</last></author>
      <author><first>Katharina</first><last>Kann</last></author>
      <pages>5237–5250</pages>
      <url hash="c9b8a7d2">2020.emnlp-main.423</url>
    </paper>
    <paper id="424">
      <title><fixed-case>IGT</fixed-case>2<fixed-case>P</fixed-case>: From Interlinear Glossed Texts to Paradigms</title>
      <author><first>Sarah</first><last>Moeller</last></author>
      <author><first>Ling</first><last>Liu</last></author>
      <author><first>Changbing</first><last>Yang</last></author>
      <author><first>Katharina</first><last>Kann</last></author>
      <author><first>Mans</first><last>Hulden</last></author>
      <pages>5251–5262</pages>
      <url hash="b277ac02">2020.emnlp-main.424</url>
    </paper>
    <paper id="425">
      <title>A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support</title>
      <author><first>Ashish</first><last>Sharma</last></author>
      <author><first>Adam</first><last>Miner</last></author>
      <author><first>David</first><last>Atkins</last></author>
      <author><first>Tim</first><last>Althoff</last></author>
      <pages>5263–5276</pages>
      <url hash="8448b5f5">2020.emnlp-main.425</url>
    </paper>
    <paper id="426">
      <title>Modeling Protagonist Emotions for Emotion-Aware Storytelling</title>
      <author><first>Faeze</first><last>Brahman</last></author>
      <author><first>Snigdha</first><last>Chaturvedi</last></author>
      <pages>5277–5294</pages>
      <url hash="ae2894c2">2020.emnlp-main.426</url>
    </paper>
    <paper id="427">
      <title>Help! Need Advice on Identifying Advice</title>
      <author><first>Venkata Subrahmanyan</first><last>Govindarajan</last></author>
      <author><first>Benjamin</first><last>Chen</last></author>
      <author><first>Rebecca</first><last>Warholic</last></author>
      <author><first>Katrin</first><last>Erk</last></author>
      <author><first>Junyi Jessy</first><last>Li</last></author>
      <pages>5295–5306</pages>
      <url hash="51d117f3">2020.emnlp-main.427</url>
    </paper>
    <paper id="428">
      <title>Quantifying Intimacy in Language</title>
      <author><first>Jiaxin</first><last>Pei</last></author>
      <author><first>David</first><last>Jurgens</last></author>
      <pages>5307–5326</pages>
      <url hash="685274c0">2020.emnlp-main.428</url>
    </paper>
    <paper id="429">
      <title>Writing Strategies for Science Communication: Data and Computational Analysis</title>
      <author><first>Tal</first><last>August</last></author>
      <author><first>Lauren</first><last>Kim</last></author>
      <author><first>Katharina</first><last>Reinecke</last></author>
      <author><first>Noah A.</first><last>Smith</last></author>
      <pages>5327–5344</pages>
      <url hash="8b64a852">2020.emnlp-main.429</url>
      <attachment type="OptionalSupplementaryMaterial" hash="1a73269a">2020.emnlp-main.429.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="430">
      <title>Weakly Supervised Subevent Knowledge Acquisition</title>
      <author><first>Wenlin</first><last>Yao</last></author>
      <author><first>Zeyu</first><last>Dai</last></author>
      <author><first>Maitreyi</first><last>Ramaswamy</last></author>
      <author><first>Bonan</first><last>Min</last></author>
      <author><first>Ruihong</first><last>Huang</last></author>
      <pages>5345–5356</pages>
      <url hash="bd192eb7">2020.emnlp-main.430</url>
    </paper>
    <paper id="431">
      <title>Biomedical Event Extraction as Sequence Labeling</title>
      <author><first>Alan</first><last>Ramponi</last></author>
      <author><first>Rob</first><last>van der Goot</last></author>
      <author><first>Rosario</first><last>Lombardo</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <pages>5357–5367</pages>
      <url hash="27326b23">2020.emnlp-main.431</url>
    </paper>
    <paper id="432">
      <title>Annotating Temporal Dependency Graphs via Crowdsourcing</title>
      <author><first>Jiarui</first><last>Yao</last></author>
      <author><first>Haoling</first><last>Qiu</last></author>
      <author><first>Bonan</first><last>Min</last></author>
      <author><first>Nianwen</first><last>Xue</last></author>
      <pages>5368–5380</pages>
      <url hash="50c04b8b">2020.emnlp-main.432</url>
    </paper>
    <paper id="433">
      <title>Introducing a New Dataset for Event Detection in Cybersecurity Texts</title>
      <author><first>Hieu</first><last>Man Duc Trong</last></author>
      <author><first>Duc</first><last>Trong Le</last></author>
      <author><first>Amir</first><last>Pouran Ben Veyseh</last></author>
      <author><first>Thuat</first><last>Nguyen</last></author>
      <author><first>Thien Huu</first><last>Nguyen</last></author>
      <pages>5381–5390</pages>
      <url hash="b76e5982">2020.emnlp-main.433</url>
    </paper>
    <paper id="434">
      <title><fixed-case>CHARM</fixed-case>: Inferring Personal Attributes from Conversations</title>
      <author><first>Anna</first><last>Tigunova</last></author>
      <author><first>Andrew</first><last>Yates</last></author>
      <author><first>Paramita</first><last>Mirza</last></author>
      <author><first>Gerhard</first><last>Weikum</last></author>
      <pages>5391–5404</pages>
      <url hash="0f77d686">2020.emnlp-main.434</url>
      <attachment type="OptionalSupplementaryMaterial" hash="5368e472">2020.emnlp-main.434.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="435">
      <title>Event Detection: Gate Diversity and Syntactic Importance Scores for Graph Convolution Neural Networks</title>
      <author><first>Viet Dac</first><last>Lai</last></author>
      <author><first>Tuan Ngo</first><last>Nguyen</last></author>
      <author><first>Thien Huu</first><last>Nguyen</last></author>
      <pages>5405–5411</pages>
      <url hash="8877328e">2020.emnlp-main.435</url>
    </paper>
    <paper id="436">
      <title>Severing the Edge between before and after: Neural Architectures for Temporal Ordering of Events</title>
      <author><first>Miguel</first><last>Ballesteros</last></author>
      <author><first>Rishita</first><last>Anubhai</last></author>
      <author><first>Shuai</first><last>Wang</last></author>
      <author><first>Nima</first><last>Pourdamghani</last></author>
      <author><first>Yogarshi</first><last>Vyas</last></author>
      <author><first>Jie</first><last>Ma</last></author>
      <author><first>Parminder</first><last>Bhatia</last></author>
      <author><first>Kathleen</first><last>McKeown</last></author>
      <author><first>Yaser</first><last>Al-Onaizan</last></author>
      <pages>5412–5417</pages>
      <url hash="67d86a81">2020.emnlp-main.436</url>
    </paper>
    <paper id="437">
      <title>How Much Knowledge Can You Pack into the Parameters of a Language Model?</title>
      <author><first>Adam</first><last>Roberts</last></author>
      <author><first>Colin</first><last>Raffel</last></author>
      <author><first>Noam</first><last>Shazeer</last></author>
      <pages>5418–5426</pages>
      <url hash="2d7a8d27">2020.emnlp-main.437</url>
    </paper>
    <paper id="438">
      <title><fixed-case>EXAMS</fixed-case>: A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering</title>
      <author><first>Momchil</first><last>Hardalov</last></author>
      <author><first>Todor</first><last>Mihaylov</last></author>
      <author><first>Dimitrina</first><last>Zlatkova</last></author>
      <author><first>Yoan</first><last>Dinkov</last></author>
      <author><first>Ivan</first><last>Koychev</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>5427–5444</pages>
      <url hash="34ad85cd">2020.emnlp-main.438</url>
    </paper>
    <paper id="439">
      <title>End-to-End Synthetic Data Generation for Domain Adaptation of Question Answering Systems</title>
      <author><first>Siamak</first><last>Shakeri</last></author>
      <author><first>Cicero</first><last>Nogueira dos Santos</last></author>
      <author><first>Henghui</first><last>Zhu</last></author>
      <author><first>Patrick</first><last>Ng</last></author>
      <author><first>Feng</first><last>Nan</last></author>
      <author><first>Zhiguo</first><last>Wang</last></author>
      <author><first>Ramesh</first><last>Nallapati</last></author>
      <author><first>Bing</first><last>Xiang</last></author>
      <pages>5445–5460</pages>
      <url hash="ae739670">2020.emnlp-main.439</url>
    </paper>
    <paper id="440">
      <title>Multi-Stage Pretraining for Low-Resource Domain Adaptation</title>
      <author><first>Rong</first><last>Zhang</last></author>
      <author><first>Revanth</first><last>Gangi Reddy</last></author>
      <author><first>Md Arafat</first><last>Sultan</last></author>
      <author><first>Vittorio</first><last>Castelli</last></author>
      <author><first>Anthony</first><last>Ferritto</last></author>
      <author><first>Radu</first><last>Florian</last></author>
      <author><first>Efsun</first><last>Sarioglu Kayi</last></author>
      <author><first>Salim</first><last>Roukos</last></author>
      <author><first>Avi</first><last>Sil</last></author>
      <author><first>Todd</first><last>Ward</last></author>
      <pages>5461–5468</pages>
      <url hash="868aaa2b">2020.emnlp-main.440</url>
    </paper>
    <paper id="441">
      <title><fixed-case>ISAAQ</fixed-case> - Mastering Textbook Questions with Pre-trained Transformers and Bottom-Up and Top-Down Attention</title>
      <author><first>Jose Manuel</first><last>Gomez-Perez</last></author>
      <author><first>Raúl</first><last>Ortega</last></author>
      <pages>5469–5479</pages>
      <url hash="d7fd3917">2020.emnlp-main.441</url>
    </paper>
    <paper id="442">
      <title><fixed-case>S</fixed-case>ubj<fixed-case>QA</fixed-case>: A Dataset for Subjectivity and Review Comprehension</title>
      <author><first>Johannes</first><last>Bjerva</last></author>
      <author><first>Nikita</first><last>Bhutani</last></author>
      <author><first>Behzad</first><last>Golshan</last></author>
      <author><first>Wang-Chiew</first><last>Tan</last></author>
      <author><first>Isabelle</first><last>Augenstein</last></author>
      <pages>5480–5494</pages>
      <url hash="5deab832">2020.emnlp-main.442</url>
    </paper>
    <paper id="443">
      <title>Widget Captioning: Generating Natural Language Description for Mobile User Interface Elements</title>
      <author><first>Yang</first><last>Li</last></author>
      <author><first>Gang</first><last>Li</last></author>
      <author><first>Luheng</first><last>He</last></author>
      <author><first>Jingjie</first><last>Zheng</last></author>
      <author><first>Hong</first><last>Li</last></author>
      <author><first>Zhiwei</first><last>Guan</last></author>
      <pages>5495–5510</pages>
      <url hash="ce2c7535">2020.emnlp-main.443</url>
    </paper>
    <paper id="444">
      <title>Unsupervised Natural Language Inference via Decoupled Multimodal Contrastive Learning</title>
      <author><first>Wanyun</first><last>Cui</last></author>
      <author><first>Guangyu</first><last>Zheng</last></author>
      <author><first>Wei</first><last>Wang</last></author>
      <pages>5511–5520</pages>
      <url hash="317055f5">2020.emnlp-main.444</url>
    </paper>
    <paper id="445">
      <title>Digital Voicing of Silent Speech</title>
      <author><first>David</first><last>Gaddy</last></author>
      <author><first>Dan</first><last>Klein</last></author>
      <pages>5521–5530</pages>
      <url hash="373229c3">2020.emnlp-main.445</url>
      <attachment type="OptionalSupplementaryMaterial" hash="562d34d2">2020.emnlp-main.445.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="446">
      <title>Imitation Attacks and Defenses for Black-box Machine Translation Systems</title>
      <author><first>Eric</first><last>Wallace</last></author>
      <author><first>Mitchell</first><last>Stern</last></author>
      <author><first>Dawn</first><last>Song</last></author>
      <pages>5531–5546</pages>
      <url hash="5684218c">2020.emnlp-main.446</url>
    </paper>
    <paper id="447">
      <title>Sequence-level Mixed Sample Data Augmentation</title>
      <author><first>Demi</first><last>Guo</last></author>
      <author><first>Yoon</first><last>Kim</last></author>
      <author><first>Alexander</first><last>Rush</last></author>
      <pages>5547–5552</pages>
      <url hash="aef1bdd8">2020.emnlp-main.447</url>
      <attachment type="OptionalSupplementaryMaterial" hash="c92a8ae2">2020.emnlp-main.447.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="448">
      <title>Consistency of a Recurrent Language Model with Respect to Incomplete Decoding</title>
      <author><first>Sean</first><last>Welleck</last></author>
      <author><first>Ilia</first><last>Kulikov</last></author>
      <author><first>Jaedeok</first><last>Kim</last></author>
      <author><first>Richard Yuanzhe</first><last>Pang</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <pages>5553–5568</pages>
      <url hash="8186b6d0">2020.emnlp-main.448</url>
    </paper>
    <paper id="449">
      <title>An Exploration of Arbitrary-Order Sequence Labeling via Energy-Based Inference Networks</title>
      <author><first>Lifu</first><last>Tu</last></author>
      <author><first>Tianyu</first><last>Liu</last></author>
      <author><first>Kevin</first><last>Gimpel</last></author>
      <pages>5569–5582</pages>
      <url hash="789480a8">2020.emnlp-main.449</url>
    </paper>
    <paper id="450">
      <title>Ensemble Distillation for Structured Prediction: Calibrated, Accurate, <fixed-case>F</fixed-case>ast—<fixed-case>C</fixed-case>hoose Three</title>
      <author><first>Steven</first><last>Reich</last></author>
      <author><first>David</first><last>Mueller</last></author>
      <author><first>Nicholas</first><last>Andrews</last></author>
      <pages>5583–5595</pages>
      <url hash="c92ead90">2020.emnlp-main.450</url>
    </paper>
    <paper id="451">
      <title>Inducing Target-specific Latent Structures for Aspect Sentiment Classification</title>
      <author><first>Chenhua</first><last>Chen</last></author>
      <author><first>Zhiyang</first><last>Teng</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>5596–5607</pages>
      <url hash="f20569fe">2020.emnlp-main.451</url>
    </paper>
    <paper id="452">
      <title>Affective Event Classification with Discourse-enhanced Self-training</title>
      <author><first>Yuan</first><last>Zhuang</last></author>
      <author><first>Tianyu</first><last>Jiang</last></author>
      <author><first>Ellen</first><last>Riloff</last></author>
      <pages>5608–5617</pages>
      <url hash="1488f613">2020.emnlp-main.452</url>
    </paper>
    <paper id="453">
      <title>Deep Weighted <fixed-case>M</fixed-case>ax<fixed-case>SAT</fixed-case> for Aspect-based Opinion Extraction</title>
      <author><first>Meixi</first><last>Wu</last></author>
      <author><first>Wenya</first><last>Wang</last></author>
      <author><first>Sinno Jialin</first><last>Pan</last></author>
      <pages>5618–5628</pages>
      <url hash="fea2eb85">2020.emnlp-main.453</url>
    </paper>
    <paper id="454">
      <title>Multi-view Story Characterization from Movie Plot Synopses and Reviews</title>
      <author><first>Sudipta</first><last>Kar</last></author>
      <author><first>Gustavo</first><last>Aguilar</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <author><first>Thamar</first><last>Solorio</last></author>
      <pages>5629–5646</pages>
      <url hash="99d666a2">2020.emnlp-main.454</url>
    </paper>
    <paper id="455">
      <title>Mind Your Inflections! Improving <fixed-case>NLP</fixed-case> for Non-Standard Englishes with Base-Inflection Encoding</title>
      <author><first>Samson</first><last>Tan</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <author><first>Lav</first><last>Varshney</last></author>
      <author><first>Min-Yen</first><last>Kan</last></author>
      <pages>5647–5663</pages>
      <url hash="aa918fa3">2020.emnlp-main.455</url>
    </paper>
    <paper id="456">
      <title>Measuring the Similarity of Grammatical Gender Systems by Comparing Partitions</title>
      <author><first>Arya D.</first><last>McCarthy</last></author>
      <author><first>Adina</first><last>Williams</last></author>
      <author><first>Shijia</first><last>Liu</last></author>
      <author><first>David</first><last>Yarowsky</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <pages>5664–5675</pages>
      <url hash="1fdcf58c">2020.emnlp-main.456</url>
    </paper>
    <paper id="457">
      <title>Is <fixed-case>C</fixed-case>hinese Word Segmentation a Solved Task? Rethinking Neural <fixed-case>C</fixed-case>hinese Word Segmentation</title>
      <author><first>Jinlan</first><last>Fu</last></author>
      <author><first>Pengfei</first><last>Liu</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>5676–5686</pages>
      <url hash="31ec134b">2020.emnlp-main.457</url>
    </paper>
    <paper id="458">
      <title>Learning to Pronounce <fixed-case>C</fixed-case>hinese without a Pronunciation Dictionary</title>
      <author><first>Christopher</first><last>Chu</last></author>
      <author><first>Scot</first><last>Fang</last></author>
      <author><first>Kevin</first><last>Knight</last></author>
      <pages>5687–5693</pages>
      <url hash="84b63a90">2020.emnlp-main.458</url>
    </paper>
    <paper id="459">
      <title>Dynamic Anticipation and Completion for Multi-Hop Reasoning over Sparse Knowledge Graph</title>
      <author><first>Xin</first><last>Lv</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Lei</first><last>Hou</last></author>
      <author><first>Juanzi</first><last>Li</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Wei</first><last>Zhang</last></author>
      <author><first>Yichi</first><last>Zhang</last></author>
      <author><first>Hao</first><last>Kong</last></author>
      <author><first>Suhui</first><last>Wu</last></author>
      <pages>5694–5703</pages>
      <url hash="d5d29f91">2020.emnlp-main.459</url>
    </paper>
    <paper id="460">
      <title>Knowledge Association with Hyperbolic Knowledge Graph Embeddings</title>
      <author><first>Zequn</first><last>Sun</last></author>
      <author><first>Muhao</first><last>Chen</last></author>
      <author><first>Wei</first><last>Hu</last></author>
      <author><first>Chengming</first><last>Wang</last></author>
      <author><first>Jian</first><last>Dai</last></author>
      <author><first>Wei</first><last>Zhang</last></author>
      <pages>5704–5716</pages>
      <url hash="d378d54e">2020.emnlp-main.460</url>
    </paper>
    <paper id="461">
      <title>Domain Knowledge Empowered Structured Neural Net for End-to-End Event Temporal Relation Extraction</title>
      <author><first>Rujun</first><last>Han</last></author>
      <author><first>Yichao</first><last>Zhou</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <pages>5717–5729</pages>
      <url hash="9dab2a9f">2020.emnlp-main.461</url>
    </paper>
    <paper id="462">
      <title><fixed-case>T</fixed-case>e<fixed-case>MP</fixed-case>: Temporal Message Passing for Temporal Knowledge Graph Completion</title>
      <author><first>Jiapeng</first><last>Wu</last></author>
      <author><first>Meng</first><last>Cao</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <author><first>William L.</first><last>Hamilton</last></author>
      <pages>5730–5746</pages>
      <url hash="4813fb73">2020.emnlp-main.462</url>
    </paper>
    <paper id="463">
      <title>Understanding the Difficulty of Training Transformers</title>
      <author><first>Liyuan</first><last>Liu</last></author>
      <author><first>Xiaodong</first><last>Liu</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <author><first>Weizhu</first><last>Chen</last></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <pages>5747–5763</pages>
      <url hash="6b075935">2020.emnlp-main.463</url>
      <attachment type="OptionalSupplementaryMaterial" hash="091036bc">2020.emnlp-main.463.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="464">
      <title>An Empirical Study of Generation Order for Machine Translation</title>
      <author><first>William</first><last>Chan</last></author>
      <author><first>Mitchell</first><last>Stern</last></author>
      <author><first>Jamie</first><last>Kiros</last></author>
      <author><first>Jakob</first><last>Uszkoreit</last></author>
      <pages>5764–5773</pages>
      <url hash="1258d07e">2020.emnlp-main.464</url>
      <attachment type="OptionalSupplementaryMaterial" hash="ac80ec91">2020.emnlp-main.464.OptionalSupplementaryMaterial.pdf</attachment>
    </paper>
    <paper id="465">
      <title>Inference Strategies for Sequence Generation with Conditional Masking</title>
      <author><first>Julia</first><last>Kreutzer</last></author>
      <author><first>George</first><last>Foster</last></author>
      <author><first>Colin</first><last>Cherry</last></author>
      <pages>5774–5782</pages>
      <url hash="a8c87d09">2020.emnlp-main.465</url>
    </paper>
    <paper id="466">
      <title><fixed-case>A</fixed-case>mbig<fixed-case>QA</fixed-case>: Answering Ambiguous Open-domain Questions</title>
      <author><first>Sewon</first><last>Min</last></author>
      <author><first>Julian</first><last>Michael</last></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>5783–5797</pages>
      <url hash="beed3e95">2020.emnlp-main.466</url>
    </paper>
    <paper id="467">
      <title>Tell Me How to Ask Again: Question Data Augmentation with Controllable Rewriting in Continuous Space</title>
      <author><first>Dayiheng</first><last>Liu</last></author>
      <author><first>Yeyun</first><last>Gong</last></author>
      <author><first>Jie</first><last>Fu</last></author>
      <author><first>Yu</first><last>Yan</last></author>
      <author><first>Jiusheng</first><last>Chen</last></author>
      <author><first>Jiancheng</first><last>Lv</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>5798–5810</pages>
      <url hash="f51a1f7a">2020.emnlp-main.467</url>
    </paper>
    <paper id="468">
      <title>Training Question Answering Models from Synthetic Data</title>
      <author><first>Raul</first><last>Puri</last></author>
      <author><first>Ryan</first><last>Spring</last></author>
      <author><first>Mohammad</first><last>Shoeybi</last></author>
      <author><first>Mostofa</first><last>Patwary</last></author>
      <author><first>Bryan</first><last>Catanzaro</last></author>
      <pages>5811–5826</pages>
      <url hash="f36c0b9b">2020.emnlp-main.468</url>
    </paper>
    <paper id="469">
      <title>Few-shot Complex Knowledge Base Question Answering via Meta Reinforcement Learning</title>
      <author><first>Yuncheng</first><last>Hua</last></author>
      <author><first>Yuan-Fang</first><last>Li</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <author><first>Guilin</first><last>Qi</last></author>
      <author><first>Tongtong</first><last>Wu</last></author>
      <pages>5827–5837</pages>
      <url hash="cd8faf28">2020.emnlp-main.469</url>
    </paper>
    <paper id="470">
      <title>Multilingual Offensive Language Identification with Cross-lingual Embeddings</title>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>5838–5844</pages>
      <url hash="60d6896b">2020.emnlp-main.470</url>
    </paper>
    <paper id="471">
      <title>Solving Historical Dictionary Codes with a Neural Language Model</title>
      <author><first>Christopher</first><last>Chu</last></author>
      <author><first>Raphael</first><last>Valenti</last></author>
      <author><first>Kevin</first><last>Knight</last></author>
      <pages>5845–5854</pages>
      <url hash="b3300e73">2020.emnlp-main.471</url>
    </paper>
    <paper id="472">
      <title>Beyond Geolocation: Micro-Dialect Identification in Diaglossic and Code-Switched Environments</title>
      <author><first>Muhammad</first><last>Abdul-Mageed</last></author>
      <author><first>Chiyu</first><last>Zhang</last></author>
      <author><first>AbdelRahim</first><last>Elmadany</last></author>
      <author><first>Lyle</first><last>Ungar</last></author>
      <pages>5855–5876</pages>
      <url hash="949d8df6">2020.emnlp-main.472</url>
    </paper>
    <paper id="473">
      <title>Dats Wassup!!: Investigating <fixed-case>A</fixed-case>frican-<fixed-case>A</fixed-case>merican <fixed-case>V</fixed-case>ernacular <fixed-case>E</fixed-case>nglish in Transformer-Based Text Generation</title>
      <author><first>Sophie</first><last>Groenwold</last></author>
      <author><first>Lily</first><last>Ou</last></author>
      <author><first>Aesha</first><last>Parekh</last></author>
      <author><first>Samhita</first><last>Honnavalli</last></author>
      <author><first>Sharon</first><last>Levy</last></author>
      <author><first>Diba</first><last>Mirza</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>5877–5883</pages>
      <url hash="fbf70d1b">2020.emnlp-main.473</url>
      <attachment type="OptionalSupplementaryMaterial" hash="553ba961">2020.emnlp-main.473.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="474">
      <title>Iterative Domain-Repaired Back-Translation</title>
      <author><first>Hao-Ran</first><last>Wei</last></author>
      <author><first>Zhirui</first><last>Zhang</last></author>
      <author><first>Boxing</first><last>Chen</last></author>
      <author><first>Weihua</first><last>Luo</last></author>
      <pages>5884–5893</pages>
      <url hash="41818f97">2020.emnlp-main.474</url>
    </paper>
    <paper id="475">
      <title>Dynamic Data Selection and Weighting for Iterative Back-Translation</title>
      <author><first>Zi-Yi</first><last>Dou</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>5894–5904</pages>
      <url hash="bdc7ab51">2020.emnlp-main.475</url>
    </paper>
    <paper id="476">
      <title>Revisiting Modularized Multilingual <fixed-case>NMT</fixed-case> to Meet Industrial Demands</title>
      <author><first>Sungwon</first><last>Lyu</last></author>
      <author><first>Bokyung</first><last>Son</last></author>
      <author><first>Kichang</first><last>Yang</last></author>
      <author><first>Jaekyoung</first><last>Bae</last></author>
      <pages>5905–5918</pages>
      <url hash="05f6d06b">2020.emnlp-main.476</url>
    </paper>
    <paper id="477">
      <title><fixed-case>LAR</fixed-case>e<fixed-case>QA</fixed-case>: Language-agnostic Answer Retrieval from a Multilingual Pool</title>
      <author><first>Uma</first><last>Roy</last></author>
      <author><first>Noah</first><last>Constant</last></author>
      <author><first>Rami</first><last>Al-Rfou</last></author>
      <author><first>Aditya</first><last>Barua</last></author>
      <author><first>Aaron</first><last>Phillips</last></author>
      <author><first>Yinfei</first><last>Yang</last></author>
      <pages>5919–5930</pages>
      <url hash="f231f147">2020.emnlp-main.477</url>
    </paper>
    <paper id="478">
      <title><fixed-case>OCR</fixed-case> Post-Correction for Endangered Language Texts</title>
      <author><first>Shruti</first><last>Rijhwani</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>5931–5942</pages>
      <url hash="0512ff89">2020.emnlp-main.478</url>
    </paper>
    <paper id="479">
      <title><fixed-case>X</fixed-case>-<fixed-case>FACTR</fixed-case>: Multilingual Factual Knowledge Retrieval from Pretrained Language Models</title>
      <author><first>Zhengbao</first><last>Jiang</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Jun</first><last>Araki</last></author>
      <author><first>Haibo</first><last>Ding</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>5943–5959</pages>
      <url hash="08717037">2020.emnlp-main.479</url>
    </paper>
    <paper id="480">
      <title>A Massive Collection of Cross-Lingual Web-Document Pairs</title>
      <author><first>Ahmed</first><last>El-Kishky</last></author>
      <author><first>Vishrav</first><last>Chaudhary</last></author>
      <author><first>Francisco</first><last>Guzmán</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <pages>5960–5969</pages>
      <url hash="30add64b">2020.emnlp-main.480</url>
    </paper>
    <paper id="481">
      <title>Localizing <fixed-case>Q</fixed-case>&amp;<fixed-case>A</fixed-case> Semantic Parsers for Any Language in a Day</title>
      <author><first>Mehrad</first><last>Moradshahi</last></author>
      <author><first>Giovanni</first><last>Campagna</last></author>
      <author><first>Sina</first><last>Semnani</last></author>
      <author><first>Silei</first><last>Xu</last></author>
      <author><first>Monica</first><last>Lam</last></author>
      <pages>5970–5983</pages>
      <url hash="7efa9786">2020.emnlp-main.481</url>
    </paper>
    <paper id="482">
      <title>Interactive Refinement of Cross-Lingual Word Embeddings</title>
      <author><first>Michelle</first><last>Yuan</last></author>
      <author><first>Mozhi</first><last>Zhang</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <author><first>Leah</first><last>Findlater</last></author>
      <author><first>Jordan</first><last>Boyd-Graber</last></author>
      <pages>5984–5996</pages>
      <url hash="550625d8">2020.emnlp-main.482</url>
    </paper>
    <paper id="483">
      <title>Exploiting Sentence Order in Document Alignment</title>
      <author><first>Brian</first><last>Thompson</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <pages>5997–6007</pages>
      <url hash="5f0da373">2020.emnlp-main.483</url>
    </paper>
    <paper id="484">
      <title><fixed-case>XGLUE</fixed-case>: A New Benchmark Datasetfor Cross-lingual Pre-training, Understanding and Generation</title>
      <author><first>Yaobo</first><last>Liang</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <author><first>Yeyun</first><last>Gong</last></author>
      <author><first>Ning</first><last>Wu</last></author>
      <author><first>Fenfei</first><last>Guo</last></author>
      <author><first>Weizhen</first><last>Qi</last></author>
      <author><first>Ming</first><last>Gong</last></author>
      <author><first>Linjun</first><last>Shou</last></author>
      <author><first>Daxin</first><last>Jiang</last></author>
      <author><first>Guihong</first><last>Cao</last></author>
      <author><first>Xiaodong</first><last>Fan</last></author>
      <author><first>Ruofei</first><last>Zhang</last></author>
      <author><first>Rahul</first><last>Agrawal</last></author>
      <author><first>Edward</first><last>Cui</last></author>
      <author><first>Sining</first><last>Wei</last></author>
      <author><first>Taroon</first><last>Bharti</last></author>
      <author><first>Ying</first><last>Qiao</last></author>
      <author><first>Jiun-Hung</first><last>Chen</last></author>
      <author><first>Winnie</first><last>Wu</last></author>
      <author><first>Shuguang</first><last>Liu</last></author>
      <author><first>Fan</first><last>Yang</last></author>
      <author><first>Daniel</first><last>Campos</last></author>
      <author><first>Rangan</first><last>Majumder</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>6008–6018</pages>
      <url hash="a4ebbde1">2020.emnlp-main.484</url>
    </paper>
    <paper id="485">
      <title><fixed-case>AIN</fixed-case>: Fast and Accurate Sequence Labeling with Approximate Inference Network</title>
      <author><first>Xinyu</first><last>Wang</last></author>
      <author><first>Yong</first><last>Jiang</last></author>
      <author><first>Nguyen</first><last>Bach</last></author>
      <author><first>Tao</first><last>Wang</last></author>
      <author><first>Zhongqiang</first><last>Huang</last></author>
      <author><first>Fei</first><last>Huang</last></author>
      <author><first>Kewei</first><last>Tu</last></author>
      <pages>6019–6026</pages>
      <url hash="b485e320">2020.emnlp-main.485</url>
    </paper>
    <paper id="486">
      <title><fixed-case>HIT</fixed-case>: Nested Named Entity Recognition via Head-Tail Pair and Token Interaction</title>
      <author><first>Yu</first><last>Wang</last></author>
      <author><first>Yun</first><last>Li</last></author>
      <author><first>Hanghang</first><last>Tong</last></author>
      <author><first>Ziye</first><last>Zhu</last></author>
      <pages>6027–6036</pages>
      <url hash="4264e98f">2020.emnlp-main.486</url>
    </paper>
    <paper id="487">
      <title>Supertagging <fixed-case>C</fixed-case>ombinatory <fixed-case>C</fixed-case>ategorial <fixed-case>G</fixed-case>rammar with Attentive Graph Convolutional Networks</title>
      <author><first>Yuanhe</first><last>Tian</last></author>
      <author><first>Yan</first><last>Song</last></author>
      <author><first>Fei</first><last>Xia</last></author>
      <pages>6037–6044</pages>
      <url hash="219066cb">2020.emnlp-main.487</url>
      <attachment type="OptionalSupplementaryMaterial" hash="ba4e2e62">2020.emnlp-main.487.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="488">
      <title>An Effective Data Augmentation Method for Low-resource Tagging Tasks</title>
      <author><first>Bosheng</first><last>Ding</last></author>
      <author><first>Linlin</first><last>Liu</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <author><first>Canasai</first><last>Kruengkrai</last></author>
      <author><first>Thien Hai</first><last>Nguyen</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <author><first>Luo</first><last>Si</last></author>
      <author><first>Chunyan</first><last>Miao</last></author>
      <pages>6045–6057</pages>
      <url hash="568c70a9">2020.emnlp-main.488</url>
    </paper>
    <paper id="489">
      <title>Interpretable Multi-dataset Evaluation for Named Entity Recognition</title>
      <author><first>Jinlan</first><last>Fu</last></author>
      <author><first>Pengfei</first><last>Liu</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>6058–6069</pages>
      <url hash="64206b86">2020.emnlp-main.489</url>
      <attachment type="OptionalSupplementaryMaterial" hash="d2fa08d8">2020.emnlp-main.489.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="490">
      <title>Adversarial Semantic Decoupling for Recognizing Open-Vocabulary Slots</title>
      <author><first>Yuanmeng</first><last>Yan</last></author>
      <author><first>Keqing</first><last>He</last></author>
      <author><first>Hong</first><last>Xu</last></author>
      <author><first>Sihong</first><last>Liu</last></author>
      <author><first>Fanyu</first><last>Meng</last></author>
      <author><first>Min</first><last>Hu</last></author>
      <author><first>Weiran</first><last>Xu</last></author>
      <pages>6070–6075</pages>
      <url hash="0c043b9d">2020.emnlp-main.490</url>
    </paper>
    <paper id="491">
      <title>Plug and Play Autoencoders for Conditional Text Generation</title>
      <author><first>Florian</first><last>Mai</last></author>
      <author><first>Nikolaos</first><last>Pappas</last></author>
      <author><first>Ivan</first><last>Montero</last></author>
      <author><first>Noah A.</first><last>Smith</last></author>
      <author><first>James</first><last>Henderson</last></author>
      <pages>6076–6092</pages>
      <url hash="801922a1">2020.emnlp-main.491</url>
      <attachment type="OptionalSupplementaryMaterial" hash="8ec78709">2020.emnlp-main.491.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="492">
      <title>Structure Aware Negative Sampling in Knowledge Graphs</title>
      <author><first>Kian</first><last>Ahrabian</last></author>
      <author><first>Aarash</first><last>Feizi</last></author>
      <author><first>Yasmin</first><last>Salehi</last></author>
      <author><first>William L.</first><last>Hamilton</last></author>
      <author><first>Avishek Joey</first><last>Bose</last></author>
      <pages>6093–6101</pages>
      <url hash="ae979f56">2020.emnlp-main.492</url>
      <attachment type="OptionalSupplementaryMaterial" hash="93844f88">2020.emnlp-main.492.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="493">
      <title>Neural Mask Generator: Learning to Generate Adaptive Word Maskings for Language Model Adaptation</title>
      <author><first>Minki</first><last>Kang</last></author>
      <author><first>Moonsu</first><last>Han</last></author>
      <author><first>Sung Ju</first><last>Hwang</last></author>
      <pages>6102–6120</pages>
      <url hash="c5f9c476">2020.emnlp-main.493</url>
    </paper>
    <paper id="494">
      <title>Autoregressive Knowledge Distillation through Imitation Learning</title>
      <author><first>Alexander</first><last>Lin</last></author>
      <author><first>Jeremy</first><last>Wohlwend</last></author>
      <author><first>Howard</first><last>Chen</last></author>
      <author><first>Tao</first><last>Lei</last></author>
      <pages>6121–6133</pages>
      <url hash="56f936a3">2020.emnlp-main.494</url>
    </paper>
    <paper id="495">
      <title>T3: Tree-Autoencoder Regularized Adversarial Text Generation for Targeted Attack</title>
      <author><first>Boxin</first><last>Wang</last></author>
      <author><first>Hengzhi</first><last>Pei</last></author>
      <author><first>Boyuan</first><last>Pan</last></author>
      <author><first>Qian</first><last>Chen</last></author>
      <author><first>Shuohang</first><last>Wang</last></author>
      <author id="bo-li-vanderbilt"><first>Bo</first><last>Li</last></author>
      <pages>6134–6150</pages>
      <url hash="a8458fdf">2020.emnlp-main.495</url>
      <attachment type="OptionalSupplementaryMaterial" hash="bd627725">2020.emnlp-main.495.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="496">
      <title>Structured Pruning of Large Language Models</title>
      <author><first>Ziheng</first><last>Wang</last></author>
      <author><first>Jeremy</first><last>Wohlwend</last></author>
      <author><first>Tao</first><last>Lei</last></author>
      <pages>6151–6162</pages>
      <url hash="012a2daf">2020.emnlp-main.496</url>
    </paper>
    <paper id="497">
      <title>Effective Unsupervised Domain Adaptation with Adversarially Trained Language Models</title>
      <author><first>Thuy-Trang</first><last>Vu</last></author>
      <author><first>Dinh</first><last>Phung</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>6163–6173</pages>
      <url hash="e8652a8e">2020.emnlp-main.497</url>
    </paper>
    <paper id="498">
      <title><fixed-case>BAE</fixed-case>: <fixed-case>BERT</fixed-case>-based Adversarial Examples for Text Classification</title>
      <author><first>Siddhant</first><last>Garg</last></author>
      <author><first>Goutham</first><last>Ramakrishnan</last></author>
      <pages>6174–6181</pages>
      <url hash="23f7293d">2020.emnlp-main.498</url>
    </paper>
    <paper id="499">
      <title>Adversarial Self-Supervised Data Free Distillation for Text Classification</title>
      <author><first>Xinyin</first><last>Ma</last></author>
      <author><first>Yongliang</first><last>Shen</last></author>
      <author><first>Gongfan</first><last>Fang</last></author>
      <author><first>Chen</first><last>Chen</last></author>
      <author><first>Chenghao</first><last>Jia</last></author>
      <author><first>Weiming</first><last>Lu</last></author>
      <pages>6182–6192</pages>
      <url hash="f0b36f88">2020.emnlp-main.499</url>
      <attachment type="OptionalSupplementaryMaterial" hash="28f72a1c">2020.emnlp-main.499.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="500">
      <title><fixed-case>BERT</fixed-case>-<fixed-case>ATTACK</fixed-case>: Adversarial Attack against <fixed-case>BERT</fixed-case> Using <fixed-case>BERT</fixed-case></title>
      <author><first>Linyang</first><last>Li</last></author>
      <author><first>Ruotian</first><last>Ma</last></author>
      <author><first>Qipeng</first><last>Guo</last></author>
      <author><first>Xiangyang</first><last>Xue</last></author>
      <author><first>Xipeng</first><last>Qiu</last></author>
      <pages>6193–6202</pages>
      <url hash="604993f5">2020.emnlp-main.500</url>
    </paper>
    <paper id="501">
      <title>The Thieves on Sesame Street Are Polyglots — Extracting Multilingual Models from Monolingual <fixed-case>API</fixed-case>s</title>
      <author><first>Nitish Shirish</first><last>Keskar</last></author>
      <author><first>Bryan</first><last>McCann</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <author><first>Richard</first><last>Socher</last></author>
      <pages>6203–6207</pages>
      <url hash="0345c6e9">2020.emnlp-main.501</url>
    </paper>
    <paper id="502">
      <title>When Hearst Is Not Enough: Improving Hypernymy Detection from Corpus with Distributional Models</title>
      <author><first>Changlong</first><last>Yu</last></author>
      <author><first>Jialong</first><last>Han</last></author>
      <author><first>Peifeng</first><last>Wang</last></author>
      <author><first>Yangqiu</first><last>Song</last></author>
      <author><first>Hongming</first><last>Zhang</last></author>
      <author><first>Wilfred</first><last>Ng</last></author>
      <author><first>Shuming</first><last>Shi</last></author>
      <pages>6208–6217</pages>
      <url hash="f9c70757">2020.emnlp-main.502</url>
    </paper>
    <paper id="503">
      <title>Interpreting Open-Domain Modifiers: Decomposition of <fixed-case>W</fixed-case>ikipedia Categories into Disambiguated Property-Value Pairs</title>
      <author><first>Marius</first><last>Pasca</last></author>
      <pages>6218–6228</pages>
      <url hash="37d541ee">2020.emnlp-main.503</url>
    </paper>
    <paper id="504">
      <title>A Synset Relation-enhanced Framework with a Try-again Mechanism for Word Sense Disambiguation</title>
      <author><first>Ming</first><last>Wang</last></author>
      <author><first>Yinglin</first><last>Wang</last></author>
      <pages>6229–6240</pages>
      <url hash="76784b82">2020.emnlp-main.504</url>
    </paper>
    <paper id="505">
      <title>Diverse, Controllable, and Keyphrase-Aware: A Corpus and Method for News Multi-Headline Generation</title>
      <author><first>Dayiheng</first><last>Liu</last></author>
      <author><first>Yeyun</first><last>Gong</last></author>
      <author><first>Yu</first><last>Yan</last></author>
      <author><first>Jie</first><last>Fu</last></author>
      <author><first>Bo</first><last>Shao</last></author>
      <author><first>Daxin</first><last>Jiang</last></author>
      <author><first>Jiancheng</first><last>Lv</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <pages>6241–6250</pages>
      <url hash="f190761a">2020.emnlp-main.505</url>
    </paper>
    <paper id="506">
      <title>Factual Error Correction for Abstractive Summarization Models</title>
      <author><first>Meng</first><last>Cao</last></author>
      <author><first>Yue</first><last>Dong</last></author>
      <author><first>Jiapeng</first><last>Wu</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <pages>6251–6258</pages>
      <url hash="e034590c">2020.emnlp-main.506</url>
    </paper>
    <paper id="507">
      <title>Compressive Summarization with Plausibility and Salience Modeling</title>
      <author><first>Shrey</first><last>Desai</last></author>
      <author><first>Jiacheng</first><last>Xu</last></author>
      <author><first>Greg</first><last>Durrett</last></author>
      <pages>6259–6274</pages>
      <url hash="9803c989">2020.emnlp-main.507</url>
    </paper>
    <paper id="508">
      <title>Understanding Neural Abstractive Summarization Models via Uncertainty</title>
      <author><first>Jiacheng</first><last>Xu</last></author>
      <author><first>Shrey</first><last>Desai</last></author>
      <author><first>Greg</first><last>Durrett</last></author>
      <pages>6275–6281</pages>
      <url hash="5524612b">2020.emnlp-main.508</url>
    </paper>
    <paper id="509">
      <title>Better Highlighting: Creating Sub-Sentence Summary Highlights</title>
      <author><first>Sangwoo</first><last>Cho</last></author>
      <author><first>Kaiqiang</first><last>Song</last></author>
      <author><first>Chen</first><last>Li</last></author>
      <author><first>Dong</first><last>Yu</last></author>
      <author><first>Hassan</first><last>Foroosh</last></author>
      <author id="fei-liu-utdallas"><first>Fei</first><last>Liu</last></author>
      <pages>6282–6300</pages>
      <url hash="41e8238a">2020.emnlp-main.509</url>
    </paper>
    <paper id="510">
      <title>Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised Approach</title>
      <author><first>Bowen</first><last>Tan</last></author>
      <author><first>Lianhui</first><last>Qin</last></author>
      <author><first>Eric</first><last>Xing</last></author>
      <author><first>Zhiting</first><last>Hu</last></author>
      <pages>6301–6309</pages>
      <url hash="302a388a">2020.emnlp-main.510</url>
    </paper>
    <paper id="511">
      <title><fixed-case>BERT</fixed-case>-enhanced Relational Sentence Ordering Network</title>
      <author><first>Baiyun</first><last>Cui</last></author>
      <author><first>Yingming</first><last>Li</last></author>
      <author><first>Zhongfei</first><last>Zhang</last></author>
      <pages>6310–6320</pages>
      <url hash="74425abd">2020.emnlp-main.511</url>
    </paper>
    <paper id="512">
      <title>Online Conversation Disentanglement with Pointer Networks</title>
      <author><first>Tao</first><last>Yu</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <pages>6321–6330</pages>
      <url hash="c8ec18b2">2020.emnlp-main.512</url>
    </paper>
    <paper id="513">
      <title><fixed-case>VCDM</fixed-case>: Leveraging Variational Bi-encoding and Deep Contextualized Word Representations for Improved Definition Modeling</title>
      <author><first>Machel</first><last>Reid</last></author>
      <author><first>Edison</first><last>Marrese-Taylor</last></author>
      <author><first>Yutaka</first><last>Matsuo</last></author>
      <pages>6331–6344</pages>
      <url hash="cd835a58">2020.emnlp-main.513</url>
    </paper>
    <paper id="514">
      <title>Coarse-to-Fine Pre-training for Named Entity Recognition</title>
      <author><first>Xue</first><last>Mengge</last></author>
      <author><first>Bowen</first><last>Yu</last></author>
      <author><first>Zhenyu</first><last>Zhang</last></author>
      <author><first>Tingwen</first><last>Liu</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Bin</first><last>Wang</last></author>
      <pages>6345–6354</pages>
      <url hash="4a046bff">2020.emnlp-main.514</url>
    </paper>
    <paper id="515">
      <title>Exploring and Evaluating Attributes, Values, and Structure for Entity Alignment</title>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Yixin</first><last>Cao</last></author>
      <author><first>Liangming</first><last>Pan</last></author>
      <author><first>Juanzi</first><last>Li</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Tat-Seng</first><last>Chua</last></author>
      <pages>6355–6364</pages>
      <url hash="64c96f23">2020.emnlp-main.515</url>
    </paper>
    <paper id="516">
      <title>Frustratingly Simple Few-Shot Named Entity Recognition with Structured Nearest Neighbor Learning</title>
      <author><first>Yi</first><last>Yang</last></author>
      <author><first>Arzoo</first><last>Katiyar</last></author>
      <pages>6365–6375</pages>
      <url hash="662603e1">2020.emnlp-main.516</url>
    </paper>
    <paper id="517">
      <title>Learning Structured Representations of Entity Names Using Active Learning and Weak Supervision</title>
      <author><first>Kun</first><last>Qian</last></author>
      <author><first>Poornima</first><last>Chozhiyath Raman</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>Lucian</first><last>Popa</last></author>
      <pages>6376–6383</pages>
      <url hash="528ae816">2020.emnlp-main.517</url>
    </paper>
    <paper id="518">
      <title>Entity Enhanced <fixed-case>BERT</fixed-case> Pre-training for <fixed-case>C</fixed-case>hinese <fixed-case>NER</fixed-case></title>
      <author><first>Chen</first><last>Jia</last></author>
      <author><first>Yuefeng</first><last>Shi</last></author>
      <author><first>Qinrong</first><last>Yang</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>6384–6396</pages>
      <url hash="ca8991c6">2020.emnlp-main.518</url>
    </paper>
    <paper id="519">
      <title>Scalable Zero-shot Entity Linking with Dense Entity Retrieval</title>
      <author><first>Ledell</first><last>Wu</last></author>
      <author><first>Fabio</first><last>Petroni</last></author>
      <author><first>Martin</first><last>Josifoski</last></author>
      <author><first>Sebastian</first><last>Riedel</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>6397–6407</pages>
      <url hash="4ea66737">2020.emnlp-main.519</url>
    </paper>
    <paper id="520">
      <title>A Dataset for Tracking Entities in Open Domain Procedural Text</title>
      <author><first>Niket</first><last>Tandon</last></author>
      <author><first>Keisuke</first><last>Sakaguchi</last></author>
      <author><first>Bhavana</first><last>Dalvi</last></author>
      <author><first>Dheeraj</first><last>Rajagopal</last></author>
      <author><first>Peter</first><last>Clark</last></author>
      <author><first>Michal</first><last>Guerquin</last></author>
      <author><first>Kyle</first><last>Richardson</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>6408–6417</pages>
      <url hash="4f6b6193">2020.emnlp-main.520</url>
    </paper>
    <paper id="521">
      <title>Design Challenges in Low-resource Cross-lingual Entity Linking</title>
      <author><first>Xingyu</first><last>Fu</last></author>
      <author><first>Weijia</first><last>Shi</last></author>
      <author><first>Xiaodong</first><last>Yu</last></author>
      <author><first>Zian</first><last>Zhao</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>6418–6432</pages>
      <url hash="46022de2">2020.emnlp-main.521</url>
    </paper>
    <paper id="522">
      <title>Efficient One-Pass End-to-End Entity Linking for Questions</title>
      <author><first>Belinda Z.</first><last>Li</last></author>
      <author><first>Sewon</first><last>Min</last></author>
      <author><first>Srinivasan</first><last>Iyer</last></author>
      <author><first>Yashar</first><last>Mehdad</last></author>
      <author><first>Wen-tau</first><last>Yih</last></author>
      <pages>6433–6441</pages>
      <url hash="10da23da">2020.emnlp-main.522</url>
    </paper>
    <paper id="523">
      <title><fixed-case>LUKE</fixed-case>: Deep Contextualized Entity Representations with Entity-aware Self-attention</title>
      <author><first>Ikuya</first><last>Yamada</last></author>
      <author><first>Akari</first><last>Asai</last></author>
      <author><first>Hiroyuki</first><last>Shindo</last></author>
      <author><first>Hideaki</first><last>Takeda</last></author>
      <author><first>Yuji</first><last>Matsumoto</last></author>
      <pages>6442–6454</pages>
      <url hash="2226eb6f">2020.emnlp-main.523</url>
    </paper>
    <paper id="524">
      <title>Generating Similes <fixed-case>E</fixed-case>̶<fixed-case>F</fixed-case>̶<fixed-case>F</fixed-case>̶<fixed-case>O</fixed-case>̶<fixed-case>R</fixed-case>̶<fixed-case>T</fixed-case>̶<fixed-case>L</fixed-case>̶<fixed-case>E</fixed-case>̶<fixed-case>S</fixed-case>̶<fixed-case>S</fixed-case>̶<fixed-case>L</fixed-case>̶<fixed-case>Y</fixed-case>̶ 𝘭𝘪𝘬𝘦 𝘢 <fixed-case>𝘗</fixed-case>𝘳𝘰: A Style Transfer Approach for Simile Generation</title>
      <author><first>Tuhin</first><last>Chakrabarty</last></author>
      <author><first>Smaranda</first><last>Muresan</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <pages>6455–6469</pages>
      <url hash="be5acef8">2020.emnlp-main.524</url>
    </paper>
    <paper id="525">
      <title><fixed-case>HUSH</fixed-case>: A Dataset and Platform for Human-in-the-Loop Story Generation</title>
      <author><first>Nader</first><last>Akoury</last></author>
      <author><first>Shufan</first><last>Wang</last></author>
      <author><first>Josh</first><last>Whiting</last></author>
      <author><first>Stephen</first><last>Hood</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <author><first>Mohit</first><last>Iyyer</last></author>
      <pages>6470–6484</pages>
      <url hash="7900bef0">2020.emnlp-main.525</url>
    </paper>
    <paper id="526">
      <title>Substance over Style: Document-Level Targeted Content Transfer</title>
      <author><first>Allison</first><last>Hegel</last></author>
      <author><first>Sudha</first><last>Rao</last></author>
      <author><first>Asli</first><last>Celikyilmaz</last></author>
      <author><first>Bill</first><last>Dolan</last></author>
      <pages>6485–6504</pages>
      <url hash="e7405ccc">2020.emnlp-main.526</url>
    </paper>
    <paper id="527">
      <title>Template Guided Text Generation for Task Oriented Dialogue</title>
      <author><first>Mihir</first><last>Kale</last></author>
      <author><first>Abhinav</first><last>Rastogi</last></author>
      <pages>6505–6520</pages>
      <url hash="f9fab92c">2020.emnlp-main.527</url>
    </paper>
    <paper id="528">
      <title><fixed-case>MOCHA</fixed-case>: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics</title>
      <author><first>Anthony</first><last>Chen</last></author>
      <author><first>Gabriel</first><last>Stanovsky</last></author>
      <author><first>Sameer</first><last>Singh</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <pages>6521–6532</pages>
      <url hash="1c1070b2">2020.emnlp-main.528</url>
    </paper>
    <paper id="529">
      <title>Self-Supervised Text Planning for Paragraph Completion Task</title>
      <author><first>Dongyeop</first><last>Kang</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>6533–6543</pages>
      <url hash="a39044d2">2020.emnlp-main.529</url>
      <attachment type="OptionalSupplementaryMaterial" hash="c59bebe0">2020.emnlp-main.529.OptionalSupplementaryMaterial.pdf</attachment>
    </paper>
    <paper id="530">
      <title>Inquisitive Question Generation for High Level Text Comprehension</title>
      <author><first>Wei-Jen</first><last>Ko</last></author>
      <author><first>Te-yuan</first><last>Chen</last></author>
      <author><first>Yiyan</first><last>Huang</last></author>
      <author><first>Greg</first><last>Durrett</last></author>
      <author><first>Junyi Jessy</first><last>Li</last></author>
      <pages>6544–6555</pages>
      <url hash="43ecc1f6">2020.emnlp-main.530</url>
    </paper>
    <paper id="531">
      <title>Towards Persona-Based Empathetic Conversational Models</title>
      <author><first>Peixiang</first><last>Zhong</last></author>
      <author><first>Chen</first><last>Zhang</last></author>
      <author><first>Hao</first><last>Wang</last></author>
      <author><first>Yong</first><last>Liu</last></author>
      <author><first>Chunyan</first><last>Miao</last></author>
      <pages>6556–6566</pages>
      <url hash="a607581c">2020.emnlp-main.531</url>
    </paper>
    <paper id="532">
      <title>Personal Information Leakage Detection in Conversations</title>
      <author><first>Qiongkai</first><last>Xu</last></author>
      <author><first>Lizhen</first><last>Qu</last></author>
      <author><first>Zeyu</first><last>Gao</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>6567–6580</pages>
      <url hash="878db305">2020.emnlp-main.532</url>
    </paper>
    <paper id="533">
      <title>Response Selection for Multi-Party Conversations with Dynamic Topic Tracking</title>
      <author><first>Weishi</first><last>Wang</last></author>
      <author><first>Steven C.H.</first><last>Hoi</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <pages>6581–6591</pages>
      <url hash="409291ac">2020.emnlp-main.533</url>
    </paper>
    <paper id="534">
      <title>Regularizing Dialogue Generation by Imitating Implicit Scenarios</title>
      <author><first>Shaoxiong</first><last>Feng</last></author>
      <author><first>Xuancheng</first><last>Ren</last></author>
      <author><first>Hongshen</first><last>Chen</last></author>
      <author><first>Bin</first><last>Sun</last></author>
      <author><first>Kan</first><last>Li</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <pages>6592–6604</pages>
      <url hash="6aa1db34">2020.emnlp-main.534</url>
    </paper>
    <paper id="535">
      <title><fixed-case>M</fixed-case>ovie<fixed-case>C</fixed-case>hats: Chat like Humans in a Closed Domain</title>
      <author><first>Hui</first><last>Su</last></author>
      <author><first>Xiaoyu</first><last>Shen</last></author>
      <author><first>Zhou</first><last>Xiao</last></author>
      <author><first>Zheng</first><last>Zhang</last></author>
      <author><first>Ernie</first><last>Chang</last></author>
      <author><first>Cheng</first><last>Zhang</last></author>
      <author><first>Cheng</first><last>Niu</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>6605–6619</pages>
      <url hash="187edd64">2020.emnlp-main.535</url>
      <attachment type="OptionalSupplementaryMaterial" hash="83020cc4">2020.emnlp-main.535.OptionalSupplementaryMaterial.pdf</attachment>
    </paper>
    <paper id="536">
      <title>Conundrums in Entity Reference Resolution</title>
      <author><first>Jing</first><last>Lu</last></author>
      <author><first>Vincent</first><last>Ng</last></author>
      <pages>6620–6631</pages>
      <url hash="4ca385a8">2020.emnlp-main.536</url>
    </paper>
    <paper id="537">
      <title>Semantic Role Labeling Guided Multi-turn Dialogue <fixed-case>R</fixed-case>e<fixed-case>W</fixed-case>riter</title>
      <author><first>Kun</first><last>Xu</last></author>
      <author><first>Haochen</first><last>Tan</last></author>
      <author><first>Linfeng</first><last>Song</last></author>
      <author><first>Han</first><last>Wu</last></author>
      <author><first>Haisong</first><last>Zhang</last></author>
      <author><first>Linqi</first><last>Song</last></author>
      <author><first>Dong</first><last>Yu</last></author>
      <pages>6632–6639</pages>
      <url hash="34118239">2020.emnlp-main.537</url>
    </paper>
    <paper id="538">
      <title>Continuity of Topic, Interaction, and Query: Learning to Quote in Online Conversations</title>
      <author><first>Lingzhi</first><last>Wang</last></author>
      <author><first>Jing</first><last>Li</last></author>
      <author><first>Xingshan</first><last>Zeng</last></author>
      <author><first>Haisong</first><last>Zhang</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>6640–6650</pages>
      <url hash="6715f31b">2020.emnlp-main.538</url>
    </paper>
    <paper id="539">
      <title>Profile Consistency Identification for Open-domain Dialogue Agents</title>
      <author><first>Haoyu</first><last>Song</last></author>
      <author><first>Yan</first><last>Wang</last></author>
      <author><first>Wei-Nan</first><last>Zhang</last></author>
      <author><first>Zhengyu</first><last>Zhao</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>Xiaojiang</first><last>Liu</last></author>
      <pages>6651–6662</pages>
      <url hash="cf8fb3e3">2020.emnlp-main.539</url>
    </paper>
    <paper id="540">
      <title>An Element-aware Multi-representation Model for Law Article Prediction</title>
      <author><first>Huilin</first><last>Zhong</last></author>
      <author><first>Junsheng</first><last>Zhou</last></author>
      <author><first>Weiguang</first><last>Qu</last></author>
      <author><first>Yunfei</first><last>Long</last></author>
      <author><first>Yanhui</first><last>Gu</last></author>
      <pages>6663–6668</pages>
      <url hash="e2245f3b">2020.emnlp-main.540</url>
    </paper>
    <paper id="541">
      <title>Recurrent Event Network: Autoregressive Structure Inference over Temporal Knowledge Graphs</title>
      <author><first>Woojeong</first><last>Jin</last></author>
      <author><first>Meng</first><last>Qu</last></author>
      <author><first>Xisen</first><last>Jin</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <pages>6669–6683</pages>
      <url hash="3a13cb73">2020.emnlp-main.541</url>
    </paper>
    <paper id="542">
      <title>Multi-resolution Annotations for Emoji Prediction</title>
      <author><first>Weicheng</first><last>Ma</last></author>
      <author><first>Ruibo</first><last>Liu</last></author>
      <author><first>Lili</first><last>Wang</last></author>
      <author><first>Soroush</first><last>Vosoughi</last></author>
      <pages>6684–6694</pages>
      <url hash="a6853210">2020.emnlp-main.542</url>
    </paper>
    <paper id="543">
      <title>Less Is More: Attention Supervision with Counterfactuals for Text Classification</title>
      <author><first>Seungtaek</first><last>Choi</last></author>
      <author><first>Haeju</first><last>Park</last></author>
      <author><first>Jinyoung</first><last>Yeo</last></author>
      <author><first>Seung-won</first><last>Hwang</last></author>
      <pages>6695–6704</pages>
      <url hash="56622dd9">2020.emnlp-main.543</url>
    </paper>
    <paper id="544">
      <title><fixed-case>MODE</fixed-case>-<fixed-case>LSTM</fixed-case>: A Parameter-efficient Recurrent Network with Multi-Scale for Sentence Classification</title>
      <author><first>Qianli</first><last>Ma</last></author>
      <author><first>Zhenxi</first><last>Lin</last></author>
      <author><first>Jiangyue</first><last>Yan</last></author>
      <author><first>Zipeng</first><last>Chen</last></author>
      <author><first>Liuhong</first><last>Yu</last></author>
      <pages>6705–6715</pages>
      <url hash="1d26fa97">2020.emnlp-main.544</url>
    </paper>
    <paper id="545">
      <title><fixed-case>MSCNN</fixed-case>: A Monomeric-<fixed-case>S</fixed-case>iamese Convolutional Neural Network for Extremely Imbalanced Multi-label Text Classification</title>
      <author><first>Wenshuo</first><last>Yang</last></author>
      <author><first>Jiyi</first><last>Li</last></author>
      <author><first>Fumiyo</first><last>Fukumoto</last></author>
      <author><first>Yanming</first><last>Ye</last></author>
      <pages>6716–6722</pages>
      <url hash="f87b3cb1">2020.emnlp-main.545</url>
    </paper>
    <paper id="546">
      <title>Multi-Stage Pre-training for Automated <fixed-case>C</fixed-case>hinese Essay Scoring</title>
      <author><first>Wei</first><last>Song</last></author>
      <author><first>Kai</first><last>Zhang</last></author>
      <author><first>Ruiji</first><last>Fu</last></author>
      <author><first>Lizhen</first><last>Liu</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>Miaomiao</first><last>Cheng</last></author>
      <pages>6723–6733</pages>
      <url hash="584fe254">2020.emnlp-main.546</url>
    </paper>
    <paper id="547">
      <title>Multi-hop Inference for Question-driven Summarization</title>
      <author><first>Yang</first><last>Deng</last></author>
      <author><first>Wenxuan</first><last>Zhang</last></author>
      <author><first>Wai</first><last>Lam</last></author>
      <pages>6734–6744</pages>
      <url hash="6f5ac7ce">2020.emnlp-main.547</url>
    </paper>
    <paper id="548">
      <title>Towards Interpretable Reasoning over Paragraph Effects in Situation</title>
      <author><first>Mucheng</first><last>Ren</last></author>
      <author><first>Xiubo</first><last>Geng</last></author>
      <author><first>Tao</first><last>Qin</last></author>
      <author><first>Heyan</first><last>Huang</last></author>
      <author><first>Daxin</first><last>Jiang</last></author>
      <pages>6745–6758</pages>
      <url hash="acbe5612">2020.emnlp-main.548</url>
    </paper>
    <paper id="549">
      <title>Question Directed Graph Attention Network for Numerical Reasoning over Text</title>
      <author><first>Kunlong</first><last>Chen</last></author>
      <author><first>Weidi</first><last>Xu</last></author>
      <author><first>Xingyi</first><last>Cheng</last></author>
      <author><first>Zou</first><last>Xiaochuan</last></author>
      <author><first>Yuyu</first><last>Zhang</last></author>
      <author><first>Le</first><last>Song</last></author>
      <author><first>Taifeng</first><last>Wang</last></author>
      <author><first>Yuan</first><last>Qi</last></author>
      <author><first>Wei</first><last>Chu</last></author>
      <pages>6759–6768</pages>
      <url hash="2ae1ea7c">2020.emnlp-main.549</url>
    </paper>
    <paper id="550">
      <title>Dense Passage Retrieval for Open-Domain Question Answering</title>
      <author><first>Vladimir</first><last>Karpukhin</last></author>
      <author><first>Barlas</first><last>Oguz</last></author>
      <author><first>Sewon</first><last>Min</last></author>
      <author><first>Patrick</first><last>Lewis</last></author>
      <author><first>Ledell</first><last>Wu</last></author>
      <author><first>Sergey</first><last>Edunov</last></author>
      <author><first>Danqi</first><last>Chen</last></author>
      <author><first>Wen-tau</first><last>Yih</last></author>
      <pages>6769–6781</pages>
      <url hash="351ca9c5">2020.emnlp-main.550</url>
    </paper>
    <paper id="551">
      <title>Distilling Structured Knowledge for Text-Based Relational Reasoning</title>
      <author><first>Jin</first><last>Dong</last></author>
      <author><first>Marc-Antoine</first><last>Rondeau</last></author>
      <author><first>William L.</first><last>Hamilton</last></author>
      <pages>6782–6791</pages>
      <url hash="b7e0294f">2020.emnlp-main.551</url>
    </paper>
    <paper id="552">
      <title>Asking without Telling: Exploring Latent Ontologies in Contextual Representations</title>
      <author><first>Julian</first><last>Michael</last></author>
      <author><first>Jan A.</first><last>Botha</last></author>
      <author><first>Ian</first><last>Tenney</last></author>
      <pages>6792–6812</pages>
      <url hash="5c1eecd3">2020.emnlp-main.552</url>
    </paper>
    <paper id="553">
      <title>Pretrained Language Model Embryology: The Birth of <fixed-case>ALBERT</fixed-case></title>
      <author><first>Cheng-Han</first><last>Chiang</last></author>
      <author><first>Sung-Feng</first><last>Huang</last></author>
      <author><first>Hung-yi</first><last>Lee</last></author>
      <pages>6813–6828</pages>
      <url hash="148921f4">2020.emnlp-main.553</url>
      <attachment type="OptionalSupplementaryMaterial" hash="b412e810">2020.emnlp-main.553.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="554">
      <title>Learning Music Helps You Read: Using Transfer to Study Linguistic Structure in Language Models</title>
      <author><first>Isabel</first><last>Papadimitriou</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <pages>6829–6839</pages>
      <url hash="d2d67a12">2020.emnlp-main.554</url>
    </paper>
    <paper id="555">
      <title>What Do Position Embeddings Learn? An Empirical Study of Pre-Trained Language Model Positional Encoding</title>
      <author><first>Yu-An</first><last>Wang</last></author>
      <author><first>Yun-Nung</first><last>Chen</last></author>
      <pages>6840–6849</pages>
      <url hash="d05e4700">2020.emnlp-main.555</url>
    </paper>
    <paper id="556">
      <title>“You Are Grounded!”: Latent Name Artifacts in Pre-trained Language Models</title>
      <author><first>Vered</first><last>Shwartz</last></author>
      <author><first>Rachel</first><last>Rudinger</last></author>
      <author><first>Oyvind</first><last>Tafjord</last></author>
      <pages>6850–6861</pages>
      <url hash="38cfee2a">2020.emnlp-main.556</url>
    </paper>
    <paper id="557">
      <title>Birds Have Four Legs?! <fixed-case>N</fixed-case>umer<fixed-case>S</fixed-case>ense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models</title>
      <author><first>Bill Yuchen</first><last>Lin</last></author>
      <author><first>Seyeon</first><last>Lee</last></author>
      <author><first>Rahul</first><last>Khanna</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <pages>6862–6868</pages>
      <url hash="2122ff3c">2020.emnlp-main.557</url>
    </paper>
    <paper id="558">
      <title>Grounded Adaptation for Zero-shot Executable Semantic Parsing</title>
      <author><first>Victor</first><last>Zhong</last></author>
      <author><first>Mike</first><last>Lewis</last></author>
      <author><first>Sida I.</first><last>Wang</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>6869–6882</pages>
      <url hash="a66d104e">2020.emnlp-main.558</url>
      <attachment type="OptionalSupplementaryMaterial" hash="b3820443">2020.emnlp-main.558.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="559">
      <title>An Imitation Game for Learning Semantic Parsers from User Interaction</title>
      <author><first>Ziyu</first><last>Yao</last></author>
      <author><first>Yiqi</first><last>Tang</last></author>
      <author><first>Wen-tau</first><last>Yih</last></author>
      <author><first>Huan</first><last>Sun</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <pages>6883–6902</pages>
      <url hash="d35de3c4">2020.emnlp-main.559</url>
    </paper>
    <paper id="560">
      <title><fixed-case>IGSQL</fixed-case>: Database Schema Interaction Graph Based Neural Model for Context-Dependent Text-to-<fixed-case>SQL</fixed-case> Generation</title>
      <author><first>Yitao</first><last>Cai</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <pages>6903–6912</pages>
      <url hash="4ca70338">2020.emnlp-main.560</url>
    </paper>
    <paper id="561">
      <title>“What Do You Mean by That?” - a Parser-Independent Interactive Approach for Enhancing Text-to-<fixed-case>SQL</fixed-case></title>
      <author><first>Yuntao</first><last>Li</last></author>
      <author><first>Bei</first><last>Chen</last></author>
      <author><first>Qian</first><last>Liu</last></author>
      <author><first>Yan</first><last>Gao</last></author>
      <author><first>Jian-Guang</first><last>Lou</last></author>
      <author><first>Yan</first><last>Zhang</last></author>
      <author><first>Dongmei</first><last>Zhang</last></author>
      <pages>6913–6922</pages>
      <url hash="3d9d0dbc">2020.emnlp-main.561</url>
    </paper>
    <paper id="562">
      <title><fixed-case>C</fixed-case>hi<fixed-case>T</fixed-case>e<fixed-case>SQL</fixed-case>: A Large-Scale and Pragmatic <fixed-case>C</fixed-case>hinese Text-to-<fixed-case>SQL</fixed-case> Dataset</title>
      <author><first>Lijie</first><last>Wang</last></author>
      <author><first>Ao</first><last>Zhang</last></author>
      <author><first>Kun</first><last>Wu</last></author>
      <author><first>Ke</first><last>Sun</last></author>
      <author><first>Zhenghua</first><last>Li</last></author>
      <author><first>Hua</first><last>Wu</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Haifeng</first><last>Wang</last></author>
      <pages>6923–6935</pages>
      <url hash="b6dc8ff5">2020.emnlp-main.562</url>
    </paper>
    <paper id="563">
      <title>Mention Extraction and Linking for <fixed-case>SQL</fixed-case> Query Generation</title>
      <author><first>Jianqiang</first><last>Ma</last></author>
      <author><first>Zeyu</first><last>Yan</last></author>
      <author><first>Shuai</first><last>Pang</last></author>
      <author><first>Yang</first><last>Zhang</last></author>
      <author><first>Jianping</first><last>Shen</last></author>
      <pages>6936–6942</pages>
      <url hash="0428737a">2020.emnlp-main.563</url>
    </paper>
    <paper id="564">
      <title>Re-examining the Role of Schema Linking in Text-to-<fixed-case>SQL</fixed-case></title>
      <author><first>Wenqiang</first><last>Lei</last></author>
      <author><first>Weixin</first><last>Wang</last></author>
      <author><first>Zhixin</first><last>Ma</last></author>
      <author><first>Tian</first><last>Gan</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Min-Yen</first><last>Kan</last></author>
      <author><first>Tat-Seng</first><last>Chua</last></author>
      <pages>6943–6954</pages>
      <url hash="dbaff008">2020.emnlp-main.564</url>
    </paper>
    <paper id="565">
      <title>A Multi-Task Incremental Learning Framework with Category Name Embedding for Aspect-Category Sentiment Analysis</title>
      <author><first>Zehui</first><last>Dai</last></author>
      <author><first>Cheng</first><last>Peng</last></author>
      <author><first>Huajie</first><last>Chen</last></author>
      <author><first>Yadong</first><last>Ding</last></author>
      <pages>6955–6965</pages>
      <url hash="44943918">2020.emnlp-main.565</url>
      <attachment type="OptionalSupplementaryMaterial" hash="d735ee19">2020.emnlp-main.565.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="566">
      <title>Train No Evil: Selective Masking for Task-guided Pre-training</title>
      <author><first>Yuxian</first><last>Gu</last></author>
      <author><first>Zhengyan</first><last>Zhang</last></author>
      <author><first>Xiaozhi</first><last>Wang</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <pages>6966–6974</pages>
      <url hash="745b6f59">2020.emnlp-main.566</url>
    </paper>
    <paper id="567">
      <title><fixed-case>S</fixed-case>enti<fixed-case>LARE</fixed-case>: Linguistic Knowledge Enhanced Language Representation for Sentiment Analysis</title>
      <author><first>Pei</first><last>Ke</last></author>
      <author><first>Haozhe</first><last>Ji</last></author>
      <author><first>Siyang</first><last>Liu</last></author>
      <author><first>Xiaoyan</first><last>Zhu</last></author>
      <author><first>Minlie</first><last>Huang</last></author>
      <pages>6975–6988</pages>
      <url hash="4ca0d53e">2020.emnlp-main.567</url>
    </paper>
    <paper id="568">
      <title>Aspect-Based Sentiment Analysis by Aspect-Sentiment Joint Embedding</title>
      <author><first>Jiaxin</first><last>Huang</last></author>
      <author><first>Yu</first><last>Meng</last></author>
      <author><first>Fang</first><last>Guo</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <pages>6989–6999</pages>
      <url hash="6d69b787">2020.emnlp-main.568</url>
    </paper>
    <paper id="569">
      <title>Argument Pair Extraction from Peer Review and Rebuttal via Multi-task Learning</title>
      <author><first>Liying</first><last>Cheng</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <author><first>Qian</first><last>Yu</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Luo</first><last>Si</last></author>
      <pages>7000–7011</pages>
      <url hash="17b8db0f">2020.emnlp-main.569</url>
    </paper>
    <paper id="570">
      <title><fixed-case>D</fixed-case>iversifi<fixed-case>E</fixed-case>d Multiple Instance Learning for Document-Level Multi-Aspect Sentiment <fixed-case>C</fixed-case>lassifi<fixed-case>C</fixed-case>ation</title>
      <author><first>Yunjie</first><last>Ji</last></author>
      <author><first>Hao</first><last>Liu</last></author>
      <author><first>Bolei</first><last>He</last></author>
      <author><first>Xinyan</first><last>Xiao</last></author>
      <author><first>Hua</first><last>Wu</last></author>
      <author><first>Yanhua</first><last>Yu</last></author>
      <pages>7012–7023</pages>
      <url hash="0c5c3d27">2020.emnlp-main.570</url>
    </paper>
    <paper id="571">
      <title>An Empirical Study of Hyperbole</title>
      <author><first>Li</first><last>Kong</last></author>
      <author><first>Chuanyi</first><last>Li</last></author>
      <author><first>Jidong</first><last>Ge</last></author>
      <author><first>Bin</first><last>Luo</last></author>
      <author><first>Vincent</first><last>Ng</last></author>
      <pages>7024–7034</pages>
      <url hash="31f52be4">2020.emnlp-main.571</url>
    </paper>
    <paper id="572">
      <title>Unified Feature and Instance Based Domain Adaptation for End-to-End Aspect-based Sentiment Analysis</title>
      <author><first>Chenggong</first><last>Gong</last></author>
      <author><first>Jianfei</first><last>Yu</last></author>
      <author><first>Rui</first><last>Xia</last></author>
      <pages>7035–7045</pages>
      <url hash="479a7c32">2020.emnlp-main.572</url>
    </paper>
    <paper id="573">
      <title>Compositional and Lexical Semantics in <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a, <fixed-case>BERT</fixed-case> and <fixed-case>D</fixed-case>istil<fixed-case>BERT</fixed-case>: A Case Study on <fixed-case>C</fixed-case>o<fixed-case>QA</fixed-case></title>
      <author><first>Ieva</first><last>Staliūnaitė</last></author>
      <author><first>Ignacio</first><last>Iacobacci</last></author>
      <pages>7046–7056</pages>
      <url hash="e6aa54b0">2020.emnlp-main.573</url>
    </paper>
    <paper id="574">
      <title>Attention Is Not Only a Weight: Analyzing Transformers with Vector Norms</title>
      <author><first>Goro</first><last>Kobayashi</last></author>
      <author><first>Tatsuki</first><last>Kuribayashi</last></author>
      <author><first>Sho</first><last>Yokoi</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>7057–7075</pages>
      <url hash="144fbf8e">2020.emnlp-main.574</url>
    </paper>
    <paper id="575">
      <title>F1 Is Not Enough! Models and Evaluation towards User-Centered Explainable Question Answering</title>
      <author><first>Hendrik</first><last>Schuff</last></author>
      <author><first>Heike</first><last>Adel</last></author>
      <author><first>Ngoc Thang</first><last>Vu</last></author>
      <pages>7076–7095</pages>
      <url hash="a702e150">2020.emnlp-main.575</url>
    </paper>
    <paper id="576">
      <title>On the Ability of Self-Attention Networks to Recognize Counter Languages</title>
      <author><first>Satwik</first><last>Bhattamishra</last></author>
      <author><first>Kabir</first><last>Ahuja</last></author>
      <author><first>Navin</first><last>Goyal</last></author>
      <pages>7096–7116</pages>
      <url hash="e6d875ba">2020.emnlp-main.576</url>
      <attachment type="OptionalSupplementaryMaterial" hash="62a9cbcc">2020.emnlp-main.576.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="577">
      <title>An Unsupervised Joint System for Text Generation from Knowledge Graphs and Semantic Parsing</title>
      <author><first>Martin</first><last>Schmitt</last></author>
      <author><first>Sahand</first><last>Sharifzadeh</last></author>
      <author><first>Volker</first><last>Tresp</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>7117–7130</pages>
      <url hash="d993bfb7">2020.emnlp-main.577</url>
    </paper>
    <paper id="578">
      <title>A Dual-generator Network for Text Style Transfer Applications</title>
      <author><first>Xiao</first><last>Li</last></author>
      <author><first>Guanyi</first><last>Chen</last></author>
      <author><first>Chenghua</first><last>Lin</last></author>
      <author><first>Ruizhe</first><last>Li</last></author>
      <pages>7131–7136</pages>
      <url hash="6c3411cd">2020.emnlp-main.578</url>
    </paper>
    <paper id="579">
      <title>A Knowledge-Aware Sequence-to-Tree Network for Math Word Problem Solving</title>
      <author><first>Qinzhuo</first><last>Wu</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Jinlan</first><last>Fu</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>7137–7146</pages>
      <url hash="af08fb74">2020.emnlp-main.579</url>
    </paper>
    <paper id="580">
      <title>Generating Fact Checking Briefs</title>
      <author><first>Angela</first><last>Fan</last></author>
      <author><first>Aleksandra</first><last>Piktus</last></author>
      <author><first>Fabio</first><last>Petroni</last></author>
      <author><first>Guillaume</first><last>Wenzek</last></author>
      <author><first>Marzieh</first><last>Saeidi</last></author>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <author><first>Antoine</first><last>Bordes</last></author>
      <author><first>Sebastian</first><last>Riedel</last></author>
      <pages>7147–7161</pages>
      <url hash="5dfbdd8c">2020.emnlp-main.580</url>
    </paper>
    <paper id="581">
      <title>Improving the Efficiency of Grammatical Error Correction with Erroneous Span Detection and Correction</title>
      <author><first>Mengyun</first><last>Chen</last></author>
      <author><first>Tao</first><last>Ge</last></author>
      <author><first>Xingxing</first><last>Zhang</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>7162–7169</pages>
      <url hash="a77f60b7">2020.emnlp-main.581</url>
    </paper>
    <paper id="582">
      <title>Coreferential Reasoning Learning for Language Representation</title>
      <author><first>Deming</first><last>Ye</last></author>
      <author><first>Yankai</first><last>Lin</last></author>
      <author><first>Jiaju</first><last>Du</last></author>
      <author><first>Zhenghao</first><last>Liu</last></author>
      <author><first>Peng</first><last>Li</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <pages>7170–7186</pages>
      <url hash="cae6c147">2020.emnlp-main.582</url>
    </paper>
    <paper id="583">
      <title>Is Graph Structure Necessary for Multi-hop Question Answering?</title>
      <author><first>Nan</first><last>Shao</last></author>
      <author><first>Yiming</first><last>Cui</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>Shijin</first><last>Wang</last></author>
      <author><first>Guoping</first><last>Hu</last></author>
      <pages>7187–7192</pages>
      <url hash="c04cd6a2">2020.emnlp-main.583</url>
    </paper>
    <paper id="584">
      <title><fixed-case>XL</fixed-case>-<fixed-case>W</fixed-case>i<fixed-case>C</fixed-case>: A Multilingual Benchmark for Evaluating Semantic Contextualization</title>
      <author><first>Alessandro</first><last>Raganato</last></author>
      <author><first>Tommaso</first><last>Pasini</last></author>
      <author><first>Jose</first><last>Camacho-Collados</last></author>
      <author><first>Mohammad Taher</first><last>Pilehvar</last></author>
      <pages>7193–7206</pages>
      <url hash="c77802bd">2020.emnlp-main.584</url>
    </paper>
    <paper id="585">
      <title>Generationary or: “How We Went beyond Word Sense Inventories and Learned to Gloss”</title>
      <author><first>Michele</first><last>Bevilacqua</last></author>
      <author><first>Marco</first><last>Maru</last></author>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>7207–7221</pages>
      <url hash="77309689">2020.emnlp-main.585</url>
    </paper>
    <paper id="586">
      <title>Probing Pretrained Language Models for Lexical Semantics</title>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Edoardo Maria</first><last>Ponti</last></author>
      <author><first>Robert</first><last>Litschko</last></author>
      <author><first>Goran</first><last>Glavaš</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>7222–7240</pages>
      <url hash="eed781e9">2020.emnlp-main.586</url>
      <attachment type="OptionalSupplementaryMaterial" hash="3564d434">2020.emnlp-main.586.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="587">
      <title>Cross-lingual Spoken Language Understanding with Regularized Representation Alignment</title>
      <author><first>Zihan</first><last>Liu</last></author>
      <author><first>Genta Indra</first><last>Winata</last></author>
      <author><first>Peng</first><last>Xu</last></author>
      <author><first>Zhaojiang</first><last>Lin</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <pages>7241–7251</pages>
      <url hash="94aa31b0">2020.emnlp-main.587</url>
    </paper>
    <paper id="588">
      <title><fixed-case>SLURP</fixed-case>: A Spoken Language Understanding Resource Package</title>
      <author><first>Emanuele</first><last>Bastianelli</last></author>
      <author><first>Andrea</first><last>Vanzo</last></author>
      <author><first>Pawel</first><last>Swietojanski</last></author>
      <author><first>Verena</first><last>Rieser</last></author>
      <pages>7252–7262</pages>
      <url hash="9cba915b">2020.emnlp-main.588</url>
    </paper>
    <paper id="589">
      <title>Neural Conversational <fixed-case>QA</fixed-case>: Learning to Reason vs Exploiting Patterns</title>
      <author><first>Nikhil</first><last>Verma</last></author>
      <author><first>Abhishek</first><last>Sharma</last></author>
      <author><first>Dhiraj</first><last>Madan</last></author>
      <author><first>Danish</first><last>Contractor</last></author>
      <author><first>Harshit</first><last>Kumar</last></author>
      <author><first>Sachindra</first><last>Joshi</last></author>
      <pages>7263–7269</pages>
      <url hash="a2b16a53">2020.emnlp-main.589</url>
    </paper>
    <paper id="590">
      <title>Counterfactual Generator: A Weakly-Supervised Method for Named Entity Recognition</title>
      <author><first>Xiangji</first><last>Zeng</last></author>
      <author><first>Yunliang</first><last>Li</last></author>
      <author><first>Yuchen</first><last>Zhai</last></author>
      <author><first>Yin</first><last>Zhang</last></author>
      <pages>7270–7280</pages>
      <url hash="bf4c5314">2020.emnlp-main.590</url>
    </paper>
    <paper id="591">
      <title>Understanding Procedural Text Using Interactive Entity Networks</title>
      <author><first>Jizhi</first><last>Tang</last></author>
      <author><first>Yansong</first><last>Feng</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <pages>7281–7290</pages>
      <url hash="0c5235e7">2020.emnlp-main.591</url>
    </paper>
    <paper id="592">
      <title>A Rigorous Study on Named Entity Recognition: Can Fine-tuning Pretrained Model Lead to the Promised Land?</title>
      <author><first>Hongyu</first><last>Lin</last></author>
      <author><first>Yaojie</first><last>Lu</last></author>
      <author><first>Jialong</first><last>Tang</last></author>
      <author><first>Xianpei</first><last>Han</last></author>
      <author><first>Le</first><last>Sun</last></author>
      <author><first>Zhicheng</first><last>Wei</last></author>
      <author><first>Nicholas Jing</first><last>Yuan</last></author>
      <pages>7291–7300</pages>
      <url hash="3c734e89">2020.emnlp-main.592</url>
    </paper>
    <paper id="593">
      <title><fixed-case>D</fixed-case>y<fixed-case>ERNIE</fixed-case>: Dynamic Evolution of <fixed-case>R</fixed-case>iemannian Manifold Embeddings for Temporal Knowledge Graph Completion</title>
      <author><first>Zhen</first><last>Han</last></author>
      <author><first>Peng</first><last>Chen</last></author>
      <author><first>Yunpu</first><last>Ma</last></author>
      <author><first>Volker</first><last>Tresp</last></author>
      <pages>7301–7316</pages>
      <url hash="c65647b8">2020.emnlp-main.593</url>
    </paper>
    <paper id="594">
      <title>Embedding Words in Non-Vector Space with Unsupervised Graph Learning</title>
      <author><first>Max</first><last>Ryabinin</last></author>
      <author><first>Sergei</first><last>Popov</last></author>
      <author><first>Liudmila</first><last>Prokhorenkova</last></author>
      <author><first>Elena</first><last>Voita</last></author>
      <pages>7317–7331</pages>
      <url hash="3f29e5b9">2020.emnlp-main.594</url>
    </paper>
    <paper id="595">
      <title>Debiasing Knowledge Graph Embeddings</title>
      <author><first>Joseph</first><last>Fisher</last></author>
      <author><first>Arpit</first><last>Mittal</last></author>
      <author><first>Dave</first><last>Palfrey</last></author>
      <author><first>Christos</first><last>Christodoulopoulos</last></author>
      <pages>7332–7345</pages>
      <url hash="1f5ff710">2020.emnlp-main.595</url>
    </paper>
    <paper id="596">
      <title>Message Passing for Hyper-Relational Knowledge Graphs</title>
      <author><first>Mikhail</first><last>Galkin</last></author>
      <author><first>Priyansh</first><last>Trivedi</last></author>
      <author><first>Gaurav</first><last>Maheshwari</last></author>
      <author><first>Ricardo</first><last>Usbeck</last></author>
      <author><first>Jens</first><last>Lehmann</last></author>
      <pages>7346–7359</pages>
      <url hash="7b211947">2020.emnlp-main.596</url>
      <attachment type="OptionalSupplementaryMaterial" hash="18233761">2020.emnlp-main.596.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="597">
      <title>Relation-aware Graph Attention Networks with Relational Position Encodings for Emotion Recognition in Conversations</title>
      <author><first>Taichi</first><last>Ishiwatari</last></author>
      <author><first>Yuki</first><last>Yasuda</last></author>
      <author><first>Taro</first><last>Miyazaki</last></author>
      <author><first>Jun</first><last>Goto</last></author>
      <pages>7360–7370</pages>
      <url hash="aa4b5e79">2020.emnlp-main.597</url>
    </paper>
    <paper id="598">
      <title><fixed-case>BERT</fixed-case> Knows Punta Cana Is Not Just Beautiful, It’s Gorgeous: Ranking Scalar Adjectives with Contextualised Representations</title>
      <author><first>Aina</first><last>Garí Soler</last></author>
      <author><first>Marianna</first><last>Apidianaki</last></author>
      <pages>7371–7385</pages>
      <url hash="194d2b5d">2020.emnlp-main.598</url>
    </paper>
    <paper id="599">
      <title>Feature Adaptation of Pre-Trained Language Models across Languages and Domains with Robust Self-Training</title>
      <author><first>Hai</first><last>Ye</last></author>
      <author><first>Qingyu</first><last>Tan</last></author>
      <author><first>Ruidan</first><last>He</last></author>
      <author><first>Juntao</first><last>Li</last></author>
      <author><first>Hwee Tou</first><last>Ng</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <pages>7386–7399</pages>
      <url hash="a9a059cd">2020.emnlp-main.599</url>
    </paper>
    <paper id="600">
      <title>Textual Data Augmentation for Efficient Active Learning on Tiny Datasets</title>
      <author><first>Husam</first><last>Quteineh</last></author>
      <author><first>Spyridon</first><last>Samothrakis</last></author>
      <author><first>Richard</first><last>Sutcliffe</last></author>
      <pages>7400–7410</pages>
      <url hash="70a79ba4">2020.emnlp-main.600</url>
    </paper>
    <paper id="601">
      <title>“<fixed-case>I</fixed-case>’<fixed-case>D</fixed-case> Rather Just Go to Bed”: Understanding Indirect Answers</title>
      <author><first>Annie</first><last>Louis</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <author><first>Filip</first><last>Radlinski</last></author>
      <pages>7411–7425</pages>
      <url hash="2ffd9a5a">2020.emnlp-main.601</url>
    </paper>
    <paper id="602">
      <title><fixed-case>P</fixed-case>ower<fixed-case>T</fixed-case>ransformer: Unsupervised Controllable Revision for Biased Language Correction</title>
      <author><first>Xinyao</first><last>Ma</last></author>
      <author><first>Maarten</first><last>Sap</last></author>
      <author><first>Hannah</first><last>Rashkin</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>7426–7441</pages>
      <url hash="80539b31">2020.emnlp-main.602</url>
    </paper>
    <paper id="603">
      <title><fixed-case>MEGA</fixed-case> <fixed-case>RST</fixed-case> Discourse Treebanks with Structure and Nuclearity from Scalable Distant Sentiment Supervision</title>
      <author><first>Patrick</first><last>Huber</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <pages>7442–7457</pages>
      <url hash="f3e6349f">2020.emnlp-main.603</url>
    </paper>
    <paper id="604">
      <title>A Centering Approach for Discourse Structure-aware Coherence Modeling</title>
      <author><first>Sungho</first><last>Jeon</last></author>
      <author><first>Michael</first><last>Strube</last></author>
      <pages>7458–7472</pages>
      <url hash="f4fa74ee">2020.emnlp-main.604</url>
    </paper>
    <paper id="605">
      <title>Keeping up Appearances: Computational Modeling of Face Acts in Persuasion Oriented Discussions</title>
      <author><first>Ritam</first><last>Dutt</last></author>
      <author><first>Rishabh</first><last>Joshi</last></author>
      <author><first>Carolyn</first><last>Rose</last></author>
      <pages>7473–7485</pages>
      <url hash="8a8c45a5">2020.emnlp-main.605</url>
    </paper>
    <paper id="606">
      <title><fixed-case>HABERTOR</fixed-case>: An Efficient and Effective Deep Hatespeech Detector</title>
      <author><first>Thanh</first><last>Tran</last></author>
      <author><first>Yifan</first><last>Hu</last></author>
      <author><first>Changwei</first><last>Hu</last></author>
      <author><first>Kevin</first><last>Yen</last></author>
      <author><first>Fei</first><last>Tan</last></author>
      <author><first>Kyumin</first><last>Lee</last></author>
      <author><first>Se Rim</first><last>Park</last></author>
      <pages>7486–7502</pages>
      <url hash="077219f7">2020.emnlp-main.606</url>
    </paper>
    <paper id="607">
      <title>An Empirical Study on Large-Scale Multi-Label Text Classification Including Few and Zero-Shot Labels</title>
      <author><first>Ilias</first><last>Chalkidis</last></author>
      <author><first>Manos</first><last>Fergadiotis</last></author>
      <author><first>Sotiris</first><last>Kotitsas</last></author>
      <author><first>Prodromos</first><last>Malakasiotis</last></author>
      <author><first>Nikolaos</first><last>Aletras</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <pages>7503–7515</pages>
      <url hash="8de21ab8">2020.emnlp-main.607</url>
    </paper>
    <paper id="608">
      <title>Which *<fixed-case>BERT</fixed-case>? A Survey Organizing Contextualized Encoders</title>
      <author><first>Patrick</first><last>Xia</last></author>
      <author><first>Shijie</first><last>Wu</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>7516–7533</pages>
      <url hash="7c61ffa2">2020.emnlp-main.608</url>
    </paper>
    <paper id="609">
      <title>Fact or Fiction: Verifying Scientific Claims</title>
      <author><first>David</first><last>Wadden</last></author>
      <author><first>Shanchuan</first><last>Lin</last></author>
      <author><first>Kyle</first><last>Lo</last></author>
      <author><first>Lucy Lu</first><last>Wang</last></author>
      <author><first>Madeleine</first><last>van Zuylen</last></author>
      <author><first>Arman</first><last>Cohan</last></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last></author>
      <pages>7534–7550</pages>
      <url hash="f9041c2a">2020.emnlp-main.609</url>
    </paper>
    <paper id="610">
      <title>Semantic Role Labeling as Syntactic Dependency Parsing</title>
      <author><first>Tianze</first><last>Shi</last></author>
      <author><first>Igor</first><last>Malioutov</last></author>
      <author><first>Ozan</first><last>Irsoy</last></author>
      <pages>7551–7571</pages>
      <url hash="bccc2aeb">2020.emnlp-main.610</url>
    </paper>
    <paper id="611">
      <title><fixed-case>PARADE</fixed-case>: A New Dataset for Paraphrase Identification Requiring Computer Science Domain Knowledge</title>
      <author><first>Yun</first><last>He</last></author>
      <author><first>Zhuoer</first><last>Wang</last></author>
      <author><first>Yin</first><last>Zhang</last></author>
      <author><first>Ruihong</first><last>Huang</last></author>
      <author><first>James</first><last>Caverlee</last></author>
      <pages>7572–7582</pages>
      <url hash="89b7188f">2020.emnlp-main.611</url>
    </paper>
    <paper id="612">
      <title>Causal Inference of Script Knowledge</title>
      <author><first>Noah</first><last>Weber</last></author>
      <author><first>Rachel</first><last>Rudinger</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>7583–7596</pages>
      <url hash="4efc02fd">2020.emnlp-main.612</url>
    </paper>
    <paper id="613">
      <title>Towards Debiasing <fixed-case>NLU</fixed-case> Models from Unknown Biases</title>
      <author><first>Prasetya Ajie</first><last>Utama</last></author>
      <author><first>Nafise Sadat</first><last>Moosavi</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>7597–7610</pages>
      <url hash="02ca6918">2020.emnlp-main.613</url>
    </paper>
    <paper id="614">
      <title>On the Role of Supervision in Unsupervised Constituency Parsing</title>
      <author><first>Haoyue</first><last>Shi</last></author>
      <author><first>Karen</first><last>Livescu</last></author>
      <author><first>Kevin</first><last>Gimpel</last></author>
      <pages>7611–7621</pages>
      <url hash="78ee7d1d">2020.emnlp-main.614</url>
    </paper>
    <paper id="615">
      <title>Language Model Prior for Low-Resource Neural Machine Translation</title>
      <author><first>Christos</first><last>Baziotis</last></author>
      <author><first>Barry</first><last>Haddow</last></author>
      <author><first>Alexandra</first><last>Birch</last></author>
      <pages>7622–7634</pages>
      <url hash="51202eb8">2020.emnlp-main.615</url>
    </paper>
    <paper id="616">
      <title>Towards Detecting and Exploiting Disambiguation Biases in Neural Machine Translation</title>
      <author><first>Denis</first><last>Emelin</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <author><first>Rico</first><last>Sennrich</last></author>
      <pages>7635–7653</pages>
      <url hash="bc879035">2020.emnlp-main.616</url>
    </paper>
    <paper id="617">
      <title><fixed-case>MAD</fixed-case>-<fixed-case>X</fixed-case>: An Adapter-based Framework for Multi-task Cross-lingual Transfer</title>
      <author><first>Jonas</first><last>Pfeiffer</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <pages>7654–7673</pages>
      <url hash="c0fffcd0">2020.emnlp-main.617</url>
    </paper>
    <paper id="618">
      <title>Translation Artifacts in Cross-lingual Transfer Learning</title>
      <author><first>Mikel</first><last>Artetxe</last></author>
      <author><first>Gorka</first><last>Labaka</last></author>
      <author><first>Eneko</first><last>Agirre</last></author>
      <pages>7674–7684</pages>
      <url hash="c674698c">2020.emnlp-main.618</url>
    </paper>
    <paper id="619">
      <title>A Time-Aware Transformer Based Model for Suicide Ideation Detection on Social Media</title>
      <author><first>Ramit</first><last>Sawhney</last></author>
      <author><first>Harshit</first><last>Joshi</last></author>
      <author><first>Saumya</first><last>Gandhi</last></author>
      <author><first>Rajiv Ratn</first><last>Shah</last></author>
      <pages>7685–7697</pages>
      <url hash="8b8e971b">2020.emnlp-main.619</url>
    </paper>
    <paper id="620">
      <title>Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization in News Media</title>
      <author><first>Shamik</first><last>Roy</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>7698–7716</pages>
      <url hash="12fab490">2020.emnlp-main.620</url>
      <attachment type="OptionalSupplementaryMaterial" hash="4e5f8605">2020.emnlp-main.620.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="621">
      <title>Where Are the Facts? Searching for Fact-checked Information to Alleviate the Spread of Fake News</title>
      <author><first>Nguyen</first><last>Vo</last></author>
      <author><first>Kyumin</first><last>Lee</last></author>
      <pages>7717–7731</pages>
      <url hash="be2fc20f">2020.emnlp-main.621</url>
    </paper>
    <paper id="622">
      <title>Fortifying Toxic Speech Detectors against Disguised Toxicity</title>
      <author><first>Xiaochuang</first><last>Han</last></author>
      <author><first>Yulia</first><last>Tsvetkov</last></author>
      <pages>7732–7739</pages>
      <url hash="c53c4a53">2020.emnlp-main.622</url>
    </paper>
    <paper id="623">
      <title>Explainable Automated Fact-Checking for Public Health Claims</title>
      <author><first>Neema</first><last>Kotonya</last></author>
      <author><first>Francesca</first><last>Toni</last></author>
      <pages>7740–7754</pages>
      <url hash="e51a6c3f">2020.emnlp-main.623</url>
    </paper>
    <paper id="624">
      <title>Interactive Fiction Game Playing as Multi-Paragraph Reading Comprehension with Reinforcement Learning</title>
      <author><first>Xiaoxiao</first><last>Guo</last></author>
      <author><first>Mo</first><last>Yu</last></author>
      <author><first>Yupeng</first><last>Gao</last></author>
      <author><first>Chuang</first><last>Gan</last></author>
      <author><first>Murray</first><last>Campbell</last></author>
      <author><first>Shiyu</first><last>Chang</last></author>
      <pages>7755–7765</pages>
      <url hash="a71b456e">2020.emnlp-main.624</url>
      <attachment type="OptionalSupplementaryMaterial" hash="763509d5">2020.emnlp-main.624.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="625">
      <title><fixed-case>DORB</fixed-case>: Dynamically Optimizing Multiple Rewards with Bandits</title>
      <author><first>Ramakanth</first><last>Pasunuru</last></author>
      <author><first>Han</first><last>Guo</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>7766–7780</pages>
      <url hash="7d52362b">2020.emnlp-main.625</url>
    </paper>
    <paper id="626">
      <title>Improving Detection and Categorization of Task-relevant Utterances through Integration of Discourse Structure and Ontological Knowledge</title>
      <author><first>Sopan</first><last>Khosla</last></author>
      <author><first>Shikhar</first><last>Vashishth</last></author>
      <author><first>Jill Fain</first><last>Lehman</last></author>
      <author><first>Carolyn</first><last>Rose</last></author>
      <pages>7781–7797</pages>
      <url hash="0b6b542c">2020.emnlp-main.626</url>
      <attachment type="OptionalSupplementaryMaterial" hash="d1ff0796">2020.emnlp-main.626.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="627">
      <title>Hierarchical Evidence Set Modeling for Automated Fact Extraction and Verification</title>
      <author><first>Shyam</first><last>Subramanian</last></author>
      <author><first>Kyumin</first><last>Lee</last></author>
      <pages>7798–7809</pages>
      <url hash="09379a29">2020.emnlp-main.627</url>
    </paper>
    <paper id="628">
      <title>Program Enhanced Fact Verification with Verbalization and Graph Attention Network</title>
      <author><first>Xiaoyu</first><last>Yang</last></author>
      <author><first>Feng</first><last>Nie</last></author>
      <author><first>Yufei</first><last>Feng</last></author>
      <author><first>Quan</first><last>Liu</last></author>
      <author><first>Zhigang</first><last>Chen</last></author>
      <author><first>Xiaodan</first><last>Zhu</last></author>
      <pages>7810–7825</pages>
      <url hash="e5542a3e">2020.emnlp-main.628</url>
      <attachment type="OptionalSupplementaryMaterial" hash="0de70f8b">2020.emnlp-main.628.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="629">
      <title>Constrained Fact Verification for <fixed-case>FEVER</fixed-case></title>
      <author><first>Adithya</first><last>Pratapa</last></author>
      <author><first>Sai Muralidhar</first><last>Jayanthi</last></author>
      <author><first>Kavya</first><last>Nerella</last></author>
      <pages>7826–7832</pages>
      <url hash="a139392c">2020.emnlp-main.629</url>
    </paper>
    <paper id="630">
      <title>Entity Linking in 100 Languages</title>
      <author><first>Jan A.</first><last>Botha</last></author>
      <author><first>Zifei</first><last>Shan</last></author>
      <author><first>Daniel</first><last>Gillick</last></author>
      <pages>7833–7845</pages>
      <url hash="9d50dc53">2020.emnlp-main.630</url>
    </paper>
    <paper id="631">
      <title><fixed-case>P</fixed-case>atch<fixed-case>BERT</fixed-case>: Just-in-Time, Out-of-Vocabulary Patching</title>
      <author><first>Sangwhan</first><last>Moon</last></author>
      <author><first>Naoaki</first><last>Okazaki</last></author>
      <pages>7846–7852</pages>
      <url hash="564f8927">2020.emnlp-main.631</url>
    </paper>
    <paper id="632">
      <title>On the Importance of Pre-training Data Volume for Compact Language Models</title>
      <author><first>Vincent</first><last>Micheli</last></author>
      <author><first>Martin</first><last>d’Hoffschmidt</last></author>
      <author><first>François</first><last>Fleuret</last></author>
      <pages>7853–7858</pages>
      <url hash="dc9a3254">2020.emnlp-main.632</url>
    </paper>
    <paper id="633">
      <title><fixed-case>BERT</fixed-case>-of-Theseus: Compressing <fixed-case>BERT</fixed-case> by Progressive Module Replacing</title>
      <author><first>Canwen</first><last>Xu</last></author>
      <author><first>Wangchunshu</first><last>Zhou</last></author>
      <author><first>Tao</first><last>Ge</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>7859–7869</pages>
      <url hash="e4025915">2020.emnlp-main.633</url>
    </paper>
    <paper id="634">
      <title>Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting</title>
      <author><first>Sanyuan</first><last>Chen</last></author>
      <author><first>Yutai</first><last>Hou</last></author>
      <author><first>Yiming</first><last>Cui</last></author>
      <author><first>Wanxiang</first><last>Che</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>Xiangzhan</first><last>Yu</last></author>
      <pages>7870–7881</pages>
      <url hash="3f63c06a">2020.emnlp-main.634</url>
      <attachment type="OptionalSupplementaryMaterial" hash="5770ff6a">2020.emnlp-main.634.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="635">
      <title>Exploring and Predicting Transferability across <fixed-case>NLP</fixed-case> Tasks</title>
      <author><first>Tu</first><last>Vu</last></author>
      <author><first>Tong</first><last>Wang</last></author>
      <author><first>Tsendsuren</first><last>Munkhdalai</last></author>
      <author><first>Alessandro</first><last>Sordoni</last></author>
      <author><first>Adam</first><last>Trischler</last></author>
      <author><first>Andrew</first><last>Mattarella-Micke</last></author>
      <author><first>Subhransu</first><last>Maji</last></author>
      <author><first>Mohit</first><last>Iyyer</last></author>
      <pages>7882–7926</pages>
      <url hash="459d10d4">2020.emnlp-main.635</url>
    </paper>
    <paper id="636">
      <title>To <fixed-case>BERT</fixed-case> or Not to <fixed-case>BERT</fixed-case>: Comparing Task-specific and Task-agnostic Semi-Supervised Approaches for Sequence Tagging</title>
      <author><first>Kasturi</first><last>Bhattacharjee</last></author>
      <author><first>Miguel</first><last>Ballesteros</last></author>
      <author><first>Rishita</first><last>Anubhai</last></author>
      <author><first>Smaranda</first><last>Muresan</last></author>
      <author><first>Jie</first><last>Ma</last></author>
      <author><first>Faisal</first><last>Ladhak</last></author>
      <author><first>Yaser</first><last>Al-Onaizan</last></author>
      <pages>7927–7934</pages>
      <url hash="d160c724">2020.emnlp-main.636</url>
    </paper>
    <paper id="637">
      <title>Cold-start Active Learning through Self-Supervised Language Modeling</title>
      <author><first>Michelle</first><last>Yuan</last></author>
      <author><first>Hsuan-Tien</first><last>Lin</last></author>
      <author><first>Jordan</first><last>Boyd-Graber</last></author>
      <pages>7935–7948</pages>
      <url hash="11ef26f5">2020.emnlp-main.637</url>
    </paper>
    <paper id="638">
      <title>Active Learning for <fixed-case>BERT</fixed-case>: An Empirical Study</title>
      <author><first>Liat</first><last>Ein-Dor</last></author>
      <author><first>Alon</first><last>Halfon</last></author>
      <author><first>Ariel</first><last>Gera</last></author>
      <author><first>Eyal</first><last>Shnarch</last></author>
      <author><first>Lena</first><last>Dankin</last></author>
      <author><first>Leshem</first><last>Choshen</last></author>
      <author><first>Marina</first><last>Danilevsky</last></author>
      <author><first>Ranit</first><last>Aharonov</last></author>
      <author><first>Yoav</first><last>Katz</last></author>
      <author><first>Noam</first><last>Slonim</last></author>
      <pages>7949–7962</pages>
      <url hash="0a2e080f">2020.emnlp-main.638</url>
    </paper>
    <paper id="639">
      <title>Transformer Based Multi-Source Domain Adaptation</title>
      <author><first>Dustin</first><last>Wright</last></author>
      <author><first>Isabelle</first><last>Augenstein</last></author>
      <pages>7963–7974</pages>
      <url hash="fee352e1">2020.emnlp-main.639</url>
    </paper>
    <paper id="640">
      <title>Vector-Vector-Matrix Architecture: A Novel Hardware-Aware Framework for Low-Latency Inference in <fixed-case>NLP</fixed-case> Applications</title>
      <author><first>Matthew</first><last>Khoury</last></author>
      <author><first>Rumen</first><last>Dangovski</last></author>
      <author><first>Longwu</first><last>Ou</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <author><first>Yichen</first><last>Shen</last></author>
      <author><first>Li</first><last>Jing</last></author>
      <pages>7975–7984</pages>
      <url hash="3911055f">2020.emnlp-main.640</url>
    </paper>
    <paper id="641">
      <title>The Importance of Fillers for Text Representations of Speech Transcripts</title>
      <author><first>Tanvi</first><last>Dinkar</last></author>
      <author><first>Pierre</first><last>Colombo</last></author>
      <author><first>Matthieu</first><last>Labeau</last></author>
      <author><first>Chloé</first><last>Clavel</last></author>
      <pages>7985–7993</pages>
      <url hash="35cc3d88">2020.emnlp-main.641</url>
    </paper>
    <paper id="642">
      <title>The Role of Context in Neural Pitch Accent Detection in <fixed-case>E</fixed-case>nglish</title>
      <author><first>Elizabeth</first><last>Nielsen</last></author>
      <author><first>Mark</first><last>Steedman</last></author>
      <author><first>Sharon</first><last>Goldwater</last></author>
      <pages>7994–8000</pages>
      <url hash="c557c54e">2020.emnlp-main.642</url>
    </paper>
    <paper id="643">
      <title><fixed-case>V</fixed-case>ol<fixed-case>TAGE</fixed-case>: Volatility Forecasting via Text-Audio Fusion with Graph Convolution Networks for Earnings Calls</title>
      <author><first>Ramit</first><last>Sawhney</last></author>
      <author><first>Piyush</first><last>Khanna</last></author>
      <author><first>Arshiya</first><last>Aggarwal</last></author>
      <author><first>Taru</first><last>Jain</last></author>
      <author><first>Puneet</first><last>Mathur</last></author>
      <author><first>Rajiv Ratn</first><last>Shah</last></author>
      <pages>8001–8013</pages>
      <url hash="6546e461">2020.emnlp-main.643</url>
    </paper>
    <paper id="644">
      <title>Effectively Pretraining a Speech Translation Decoder with Machine Translation Data</title>
      <author><first>Ashkan</first><last>Alinejad</last></author>
      <author><first>Anoop</first><last>Sarkar</last></author>
      <pages>8014–8020</pages>
      <url hash="684b3700">2020.emnlp-main.644</url>
    </paper>
    <paper id="645">
      <title>A Preliminary Exploration of <fixed-case>GAN</fixed-case>s for Keyphrase Generation</title>
      <author><first>Avinash</first><last>Swaminathan</last></author>
      <author><first>Haimin</first><last>Zhang</last></author>
      <author><first>Debanjan</first><last>Mahata</last></author>
      <author><first>Rakesh</first><last>Gosangi</last></author>
      <author><first>Rajiv Ratn</first><last>Shah</last></author>
      <author><first>Amanda</first><last>Stent</last></author>
      <pages>8021–8030</pages>
      <url hash="cf78f526">2020.emnlp-main.645</url>
    </paper>
    <paper id="646">
      <title><fixed-case>TESA</fixed-case>: A Task in Entity Semantic Aggregation for Abstractive Summarization</title>
      <author><first>Clément</first><last>Jumel</last></author>
      <author><first>Annie</first><last>Louis</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <pages>8031–8050</pages>
      <url hash="fefa09eb">2020.emnlp-main.646</url>
    </paper>
    <paper id="647">
      <title><fixed-case>MLSUM</fixed-case>: The Multilingual Summarization Corpus</title>
      <author><first>Thomas</first><last>Scialom</last></author>
      <author><first>Paul-Alexis</first><last>Dray</last></author>
      <author><first>Sylvain</first><last>Lamprier</last></author>
      <author><first>Benjamin</first><last>Piwowarski</last></author>
      <author><first>Jacopo</first><last>Staiano</last></author>
      <pages>8051–8067</pages>
      <url hash="175e4729">2020.emnlp-main.647</url>
    </paper>
    <paper id="648">
      <title>Multi-<fixed-case>XS</fixed-case>cience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles</title>
      <author><first>Yao</first><last>Lu</last></author>
      <author><first>Yue</first><last>Dong</last></author>
      <author><first>Laurent</first><last>Charlin</last></author>
      <pages>8068–8074</pages>
      <url hash="5db4bf79">2020.emnlp-main.648</url>
    </paper>
    <paper id="649">
      <title>Intrinsic Evaluation of Summarization Datasets</title>
      <author><first>Rishi</first><last>Bommasani</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <pages>8075–8096</pages>
      <url hash="28540860">2020.emnlp-main.649</url>
    </paper>
    <paper id="650">
      <title>Iterative Feature Mining for Constraint-Based Data Collection to Increase Data Diversity and Model Robustness</title>
      <author><first>Stefan</first><last>Larson</last></author>
      <author><first>Anthony</first><last>Zheng</last></author>
      <author><first>Anish</first><last>Mahendran</last></author>
      <author><first>Rishi</first><last>Tekriwal</last></author>
      <author><first>Adrian</first><last>Cheung</last></author>
      <author><first>Eric</first><last>Guldan</last></author>
      <author><first>Kevin</first><last>Leach</last></author>
      <author><first>Jonathan K.</first><last>Kummerfeld</last></author>
      <pages>8097–8106</pages>
      <url hash="091d5b6f">2020.emnlp-main.650</url>
      <attachment type="OptionalSupplementaryMaterial" hash="69235d06">2020.emnlp-main.650.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="651">
      <title>Conversational Semantic Parsing for Dialog State Tracking</title>
      <author><first>Jianpeng</first><last>Cheng</last></author>
      <author><first>Devang</first><last>Agrawal</last></author>
      <author><first>Héctor</first><last>Martínez Alonso</last></author>
      <author><first>Shruti</first><last>Bhargava</last></author>
      <author><first>Joris</first><last>Driesen</last></author>
      <author><first>Federico</first><last>Flego</last></author>
      <author><first>Dain</first><last>Kaplan</last></author>
      <author><first>Dimitri</first><last>Kartsaklis</last></author>
      <author><first>Lin</first><last>Li</last></author>
      <author><first>Dhivya</first><last>Piraviperumal</last></author>
      <author><first>Jason D</first><last>Williams</last></author>
      <author><first>Hong</first><last>Yu</last></author>
      <author><first>Diarmuid</first><last>Ó Séaghdha</last></author>
      <author><first>Anders</first><last>Johannsen</last></author>
      <pages>8107–8117</pages>
      <url hash="304c3119">2020.emnlp-main.651</url>
    </paper>
    <paper id="652">
      <title><fixed-case>D</fixed-case>oc2<fixed-case>D</fixed-case>ial: A Goal-Oriented Document-Grounded Dialogue Dataset</title>
      <author><first>Song</first><last>Feng</last></author>
      <author><first>Hui</first><last>Wan</last></author>
      <author><first>Chulaka</first><last>Gunasekara</last></author>
      <author><first>Siva</first><last>Patel</last></author>
      <author><first>Sachindra</first><last>Joshi</last></author>
      <author><first>Luis</first><last>Lastras</last></author>
      <pages>8118–8128</pages>
      <url hash="3abf1e95">2020.emnlp-main.652</url>
    </paper>
    <paper id="653">
      <title>Interview: Large-scale Modeling of Media Dialog with Discourse Patterns and Knowledge Grounding</title>
      <author><first>Bodhisattwa Prasad</first><last>Majumder</last></author>
      <author><first>Shuyang</first><last>Li</last></author>
      <author><first>Jianmo</first><last>Ni</last></author>
      <author><first>Julian</first><last>McAuley</last></author>
      <pages>8129–8141</pages>
      <url hash="b18d7304">2020.emnlp-main.653</url>
    </paper>
    <paper id="654">
      <title><fixed-case>INSPIRED</fixed-case>: Toward Sociable Recommendation Dialog Systems</title>
      <author><first>Shirley Anugrah</first><last>Hayati</last></author>
      <author><first>Dongyeop</first><last>Kang</last></author>
      <author><first>Qingxiaoyang</first><last>Zhu</last></author>
      <author><first>Weiyan</first><last>Shi</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <pages>8142–8152</pages>
      <url hash="9b008ce5">2020.emnlp-main.654</url>
      <attachment type="OptionalSupplementaryMaterial" hash="c34faaff">2020.emnlp-main.654.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="655">
      <title>Information Seeking in the Spirit of Learning: A Dataset for Conversational Curiosity</title>
      <author><first>Pedro</first><last>Rodriguez</last></author>
      <author><first>Paul</first><last>Crook</last></author>
      <author><first>Seungwhan</first><last>Moon</last></author>
      <author><first>Zhiguang</first><last>Wang</last></author>
      <pages>8153–8172</pages>
      <url hash="fe497cc2">2020.emnlp-main.655</url>
    </paper>
    <paper id="656">
      <title>Queens Are Powerful Too: Mitigating Gender Bias in Dialogue Generation</title>
      <author><first>Emily</first><last>Dinan</last></author>
      <author><first>Angela</first><last>Fan</last></author>
      <author><first>Adina</first><last>Williams</last></author>
      <author><first>Jack</first><last>Urbanek</last></author>
      <author><first>Douwe</first><last>Kiela</last></author>
      <author><first>Jason</first><last>Weston</last></author>
      <pages>8173–8188</pages>
      <url hash="fbb4d665">2020.emnlp-main.656</url>
    </paper>
    <paper id="657">
      <title>Discriminatively-Tuned Generative Classifiers for Robust Natural Language Inference</title>
      <author><first>Xiaoan</first><last>Ding</last></author>
      <author><first>Tianyu</first><last>Liu</last></author>
      <author><first>Baobao</first><last>Chang</last></author>
      <author><first>Zhifang</first><last>Sui</last></author>
      <author><first>Kevin</first><last>Gimpel</last></author>
      <pages>8189–8202</pages>
      <url hash="fdfbd242">2020.emnlp-main.657</url>
    </paper>
    <paper id="658">
      <title>Collecting Entailment Data for Pretraining: New Protocols and Negative Results</title>
      <author><first>Samuel R.</first><last>Bowman</last></author>
      <author><first>Jennimaria</first><last>Palomaki</last></author>
      <author><first>Livio</first><last>Baldini Soares</last></author>
      <author><first>Emily</first><last>Pitler</last></author>
      <pages>8203–8214</pages>
      <url hash="acd75469">2020.emnlp-main.658</url>
    </paper>
    <paper id="659">
      <title>The Curse of Performance Instability in Analysis Datasets: Consequences, Source, and Suggestions</title>
      <author><first>Xiang</first><last>Zhou</last></author>
      <author><first>Yixin</first><last>Nie</last></author>
      <author><first>Hao</first><last>Tan</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>8215–8228</pages>
      <url hash="70ac3c7b">2020.emnlp-main.659</url>
    </paper>
    <paper id="660">
      <title>Universal Natural Language Processing with Limited Annotations: Try Few-shot Textual Entailment as a Start</title>
      <author><first>Wenpeng</first><last>Yin</last></author>
      <author><first>Nazneen Fatema</first><last>Rajani</last></author>
      <author><first>Dragomir</first><last>Radev</last></author>
      <author><first>Richard</first><last>Socher</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <pages>8229–8239</pages>
      <url hash="8d97c7a1">2020.emnlp-main.660</url>
    </paper>
    <paper id="661">
      <title><fixed-case>C</fixed-case>onj<fixed-case>NLI</fixed-case>: Natural Language Inference over Conjunctive Sentences</title>
      <author><first>Swarnadeep</first><last>Saha</last></author>
      <author><first>Yixin</first><last>Nie</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>8240–8252</pages>
      <url hash="b34844f6">2020.emnlp-main.661</url>
    </paper>
    <paper id="662">
      <title>Data and Representation for <fixed-case>T</fixed-case>urkish Natural Language Inference</title>
      <author><first>Emrah</first><last>Budur</last></author>
      <author><first>Rıza</first><last>Özçelik</last></author>
      <author><first>Tunga</first><last>Gungor</last></author>
      <author><first>Christopher</first><last>Potts</last></author>
      <pages>8253–8267</pages>
      <url hash="11f6a774">2020.emnlp-main.662</url>
    </paper>
    <paper id="663">
      <title>Multitask Learning for Cross-Lingual Transfer of Broad-coverage Semantic Dependencies</title>
      <author><first>Maryam</first><last>Aminian</last></author>
      <author><first>Mohammad Sadegh</first><last>Rasooli</last></author>
      <author><first>Mona</first><last>Diab</last></author>
      <pages>8268–8274</pages>
      <url hash="c452cabe">2020.emnlp-main.663</url>
    </paper>
    <paper id="664">
      <title>Precise Task Formalization Matters in <fixed-case>W</fixed-case>inograd Schema Evaluations</title>
      <author><first>Haokun</first><last>Liu</last></author>
      <author><first>William</first><last>Huang</last></author>
      <author><first>Dhara</first><last>Mungra</last></author>
      <author><first>Samuel R.</first><last>Bowman</last></author>
      <pages>8275–8280</pages>
      <url hash="d4b45e09">2020.emnlp-main.664</url>
    </paper>
    <paper id="665">
      <title>Gone at Last: Removing the Hypothesis-Only Bias in Natural Language Inference via Ensemble Adversarial Training</title>
      <author><first>Joe</first><last>Stacey</last></author>
      <author><first>Pasquale</first><last>Minervini</last></author>
      <author><first>Haim</first><last>Dubossarsky</last></author>
      <author><first>Sebastian</first><last>Riedel</last></author>
      <author><first>Tim</first><last>Rocktäschel</last></author>
      <pages>8281–8291</pages>
      <url hash="5986b675">2020.emnlp-main.665</url>
      <attachment type="OptionalSupplementaryMaterial" hash="ab7ade33">2020.emnlp-main.665.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="666">
      <title><fixed-case>S</fixed-case>yn<fixed-case>S</fixed-case>et<fixed-case>E</fixed-case>xpan: An Iterative Framework for Joint Entity Set Expansion and Synonym Discovery</title>
      <author><first>Jiaming</first><last>Shen</last></author>
      <author><first>Wenda</first><last>Qiu</last></author>
      <author><first>Jingbo</first><last>Shang</last></author>
      <author><first>Michelle</first><last>Vanni</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <pages>8292–8307</pages>
      <url hash="dadf79ba">2020.emnlp-main.666</url>
    </paper>
    <paper id="667">
      <title>Evaluating the Calibration of Knowledge Graph Embeddings for Trustworthy Link Prediction</title>
      <author><first>Tara</first><last>Safavi</last></author>
      <author><first>Danai</first><last>Koutra</last></author>
      <author><first>Edgar</first><last>Meij</last></author>
      <pages>8308–8321</pages>
      <url hash="8faec7db">2020.emnlp-main.667</url>
    </paper>
    <paper id="668">
      <title>Text Graph Transformer for Document Classification</title>
      <author><first>Haopeng</first><last>Zhang</last></author>
      <author><first>Jiawei</first><last>Zhang</last></author>
      <pages>8322–8327</pages>
      <url hash="a72d2530">2020.emnlp-main.668</url>
    </paper>
    <paper id="669">
      <title><fixed-case>C</fixed-case>o<fixed-case>DE</fixed-case>x: A Comprehensive Knowledge Graph Completion Benchmark</title>
      <author><first>Tara</first><last>Safavi</last></author>
      <author><first>Danai</first><last>Koutra</last></author>
      <pages>8328–8350</pages>
      <url hash="b3f4ae23">2020.emnlp-main.669</url>
    </paper>
    <paper id="670">
      <title><fixed-case>META</fixed-case>: Metadata-Empowered Weak Supervision for Text Classification</title>
      <author><first>Dheeraj</first><last>Mekala</last></author>
      <author><first>Xinyang</first><last>Zhang</last></author>
      <author><first>Jingbo</first><last>Shang</last></author>
      <pages>8351–8361</pages>
      <url hash="57d75817">2020.emnlp-main.670</url>
    </paper>
    <paper id="671">
      <title>Towards More Accurate Uncertainty Estimation in Text Classification</title>
      <author><first>Jianfeng</first><last>He</last></author>
      <author><first>Xuchao</first><last>Zhang</last></author>
      <author><first>Shuo</first><last>Lei</last></author>
      <author><first>Zhiqian</first><last>Chen</last></author>
      <author><first>Fanglan</first><last>Chen</last></author>
      <author><first>Abdulaziz</first><last>Alhamadani</last></author>
      <author><first>Bei</first><last>Xiao</last></author>
      <author><first>ChangTien</first><last>Lu</last></author>
      <pages>8362–8372</pages>
      <url hash="46aa7f1b">2020.emnlp-main.671</url>
      <attachment type="OptionalSupplementaryMaterial" hash="0b50b231">2020.emnlp-main.671.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="672">
      <title>Chapter Captor: Text Segmentation in Novels</title>
      <author><first>Charuta</first><last>Pethe</last></author>
      <author><first>Allen</first><last>Kim</last></author>
      <author><first>Steve</first><last>Skiena</last></author>
      <pages>8373–8383</pages>
      <url hash="e4960543">2020.emnlp-main.672</url>
    </paper>
    <paper id="673">
      <title>Authorship Attribution for Neural Text Generation</title>
      <author><first>Adaku</first><last>Uchendu</last></author>
      <author><first>Thai</first><last>Le</last></author>
      <author><first>Kai</first><last>Shu</last></author>
      <author><first>Dongwon</first><last>Lee</last></author>
      <pages>8384–8395</pages>
      <url hash="37a29b0f">2020.emnlp-main.673</url>
    </paper>
    <paper id="674">
      <title><fixed-case>N</fixed-case>w<fixed-case>QM</fixed-case>: A Neural Quality Assessment Framework for <fixed-case>W</fixed-case>ikipedia</title>
      <author><first>Bhanu Prakash Reddy</first><last>Guda</last></author>
      <author><first>Sasi Bhushan</first><last>Seelaboyina</last></author>
      <author><first>Soumya</first><last>Sarkar</last></author>
      <author><first>Animesh</first><last>Mukherjee</last></author>
      <pages>8396–8406</pages>
      <url hash="c6bba904">2020.emnlp-main.674</url>
    </paper>
    <paper id="675">
      <title>Towards Modeling Revision Requirements in wiki<fixed-case>H</fixed-case>ow Instructions</title>
      <author><first>Irshad</first><last>Bhat</last></author>
      <author><first>Talita</first><last>Anthonio</last></author>
      <author><first>Michael</first><last>Roth</last></author>
      <pages>8407–8414</pages>
      <url hash="2fda4e64">2020.emnlp-main.675</url>
    </paper>
    <paper id="676">
      <title>Deep Attentive Learning for Stock Movement Prediction from Social Media Text and Company Correlations</title>
      <author><first>Ramit</first><last>Sawhney</last></author>
      <author><first>Shivam</first><last>Agarwal</last></author>
      <author><first>Arnav</first><last>Wadhwa</last></author>
      <author><first>Rajiv Ratn</first><last>Shah</last></author>
      <pages>8415–8426</pages>
      <url hash="cc71a5d3">2020.emnlp-main.676</url>
    </paper>
    <paper id="677">
      <title>Natural Language Processing for Achieving Sustainable Development: The Case of Neural Labelling to Enhance Community Profiling</title>
      <author><first>Costanza</first><last>Conforti</last></author>
      <author><first>Stephanie</first><last>Hirmer</last></author>
      <author><first>Dai</first><last>Morgan</last></author>
      <author><first>Marco</first><last>Basaldella</last></author>
      <author><first>Yau</first><last>Ben Or</last></author>
      <pages>8427–8444</pages>
      <url hash="41105bb5">2020.emnlp-main.677</url>
    </paper>
    <paper id="678">
      <title>To Schedule or Not to Schedule: Extracting Task Specific Temporal Entities and Associated Negation Constraints</title>
      <author><first>Barun</first><last>Patra</last></author>
      <author><first>Chala</first><last>Fufa</last></author>
      <author><first>Pamela</first><last>Bhattacharya</last></author>
      <author><first>Charles</first><last>Lee</last></author>
      <pages>8445–8455</pages>
      <url hash="f33b89dc">2020.emnlp-main.678</url>
    </paper>
    <paper id="679">
      <title>Competence-Level Prediction and Resume-<fixed-case>J</fixed-case>ob_<fixed-case>D</fixed-case>escription Matching Using Context-Aware Transformer Models</title>
      <author><first>Changmao</first><last>Li</last></author>
      <author><first>Elaine</first><last>Fisher</last></author>
      <author><first>Rebecca</first><last>Thomas</last></author>
      <author><first>Steve</first><last>Pittard</last></author>
      <author><first>Vicki</first><last>Hertzberg</last></author>
      <author><first>Jinho D.</first><last>Choi</last></author>
      <pages>8456–8466</pages>
      <url hash="7ed2c91c">2020.emnlp-main.679</url>
    </paper>
    <paper id="680">
      <title>Grammatical Error Correction in Low Error Density Domains: A New Benchmark and Analyses</title>
      <author><first>Simon</first><last>Flachs</last></author>
      <author><first>Ophélie</first><last>Lacroix</last></author>
      <author><first>Helen</first><last>Yannakoudakis</last></author>
      <author><first>Marek</first><last>Rei</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>8467–8478</pages>
      <url hash="478b914d">2020.emnlp-main.680</url>
    </paper>
    <paper id="681">
      <title>Deconstructing Word Embedding Algorithms</title>
      <author><first>Kian</first><last>Kenyon-Dean</last></author>
      <author><first>Edward</first><last>Newell</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <pages>8479–8484</pages>
      <url hash="c9802480">2020.emnlp-main.681</url>
    </paper>
    <paper id="682">
      <title>Sequential Modelling of the Evolution of Word Representations for Semantic Change Detection</title>
      <author><first>Adam</first><last>Tsakalidis</last></author>
      <author><first>Maria</first><last>Liakata</last></author>
      <pages>8485–8497</pages>
      <url hash="f1f674b6">2020.emnlp-main.682</url>
    </paper>
    <paper id="683">
      <title>Sparsity Makes Sense: Word Sense Disambiguation Using Sparse Contextualized Word Representations</title>
      <author><first>Gábor</first><last>Berend</last></author>
      <pages>8498–8508</pages>
      <url hash="af833764">2020.emnlp-main.683</url>
    </paper>
    <paper id="684">
      <title>Exploring Semantic Capacity of Terms</title>
      <author><first>Jie</first><last>Huang</last></author>
      <author><first>Zilong</first><last>Wang</last></author>
      <author><first>Kevin</first><last>Chang</last></author>
      <author><first>Wen-mei</first><last>Hwu</last></author>
      <author><first>JinJun</first><last>Xiong</last></author>
      <pages>8509–8518</pages>
      <url hash="ea1c2ddd">2020.emnlp-main.684</url>
    </paper>
    <paper id="685">
      <title>Learning to Ignore: Long Document Coreference with Bounded Memory Neural Networks</title>
      <author><first>Shubham</first><last>Toshniwal</last></author>
      <author><first>Sam</first><last>Wiseman</last></author>
      <author><first>Allyson</first><last>Ettinger</last></author>
      <author><first>Karen</first><last>Livescu</last></author>
      <author><first>Kevin</first><last>Gimpel</last></author>
      <pages>8519–8526</pages>
      <url hash="ed3e8414">2020.emnlp-main.685</url>
    </paper>
    <paper id="686">
      <title>Revealing the Myth of Higher-Order Inference in Coreference Resolution</title>
      <author><first>Liyan</first><last>Xu</last></author>
      <author><first>Jinho D.</first><last>Choi</last></author>
      <pages>8527–8533</pages>
      <url hash="74212469">2020.emnlp-main.686</url>
    </paper>
    <paper id="687">
      <title>Pre-training of Mention Representations in Coreference Models</title>
      <author><first>Yuval</first><last>Varkel</last></author>
      <author><first>Amir</first><last>Globerson</last></author>
      <pages>8534–8540</pages>
      <url hash="95d27e8d">2020.emnlp-main.687</url>
    </paper>
    <paper id="688">
      <title>Learning Collaborative Agents with Rule Guidance for Knowledge Graph Reasoning</title>
      <author><first>Deren</first><last>Lei</last></author>
      <author><first>Gangrong</first><last>Jiang</last></author>
      <author><first>Xiaotao</first><last>Gu</last></author>
      <author><first>Kexuan</first><last>Sun</last></author>
      <author><first>Yuning</first><last>Mao</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <pages>8541–8547</pages>
      <url hash="976c7a79">2020.emnlp-main.688</url>
    </paper>
    <paper id="689">
      <title>Exploring Contextualized Neural Language Models for Temporal Dependency Parsing</title>
      <author><first>Hayley</first><last>Ross</last></author>
      <author><first>Jonathon</first><last>Cai</last></author>
      <author><first>Bonan</first><last>Min</last></author>
      <pages>8548–8553</pages>
      <url hash="8105caef">2020.emnlp-main.689</url>
    </paper>
    <paper id="690">
      <title>Systematic Comparison of Neural Architectures and Training Approaches for Open Information Extraction</title>
      <author><first>Patrick</first><last>Hohenecker</last></author>
      <author><first>Frank</first><last>Mtumbuka</last></author>
      <author><first>Vid</first><last>Kocijan</last></author>
      <author><first>Thomas</first><last>Lukasiewicz</last></author>
      <pages>8554–8565</pages>
      <url hash="3a11b2f4">2020.emnlp-main.690</url>
    </paper>
    <paper id="691">
      <title><fixed-case>S</fixed-case>eq<fixed-case>M</fixed-case>ix: Augmenting Active Sequence Labeling via Sequence Mixup</title>
      <author><first>Rongzhi</first><last>Zhang</last></author>
      <author><first>Yue</first><last>Yu</last></author>
      <author><first>Chao</first><last>Zhang</last></author>
      <pages>8566–8579</pages>
      <url hash="aa50ebdf">2020.emnlp-main.691</url>
      <attachment type="OptionalSupplementaryMaterial" hash="e7150c9e">2020.emnlp-main.691.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="692">
      <title><fixed-case>A</fixed-case>x<fixed-case>C</fixed-case>ell: Automatic Extraction of Results from Machine Learning Papers</title>
      <author><first>Marcin</first><last>Kardas</last></author>
      <author><first>Piotr</first><last>Czapla</last></author>
      <author><first>Pontus</first><last>Stenetorp</last></author>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <author><first>Sebastian</first><last>Riedel</last></author>
      <author><first>Ross</first><last>Taylor</last></author>
      <author><first>Robert</first><last>Stojnic</last></author>
      <pages>8580–8594</pages>
      <url hash="999c691d">2020.emnlp-main.692</url>
    </paper>
    <paper id="693">
      <title>Knowledge-guided Open Attribute Value Extraction with Reinforcement Learning</title>
      <author><first>Ye</first><last>Liu</last></author>
      <author><first>Sheng</first><last>Zhang</last></author>
      <author><first>Rui</first><last>Song</last></author>
      <author><first>Suo</first><last>Feng</last></author>
      <author><first>Yanghua</first><last>Xiao</last></author>
      <pages>8595–8604</pages>
      <url hash="37822935">2020.emnlp-main.693</url>
    </paper>
    <paper id="694">
      <title><fixed-case>D</fixed-case>ual<fixed-case>TKB</fixed-case>: A Dual Learning Bridge between Text and Knowledge Base</title>
      <author><first>Pierre</first><last>Dognin</last></author>
      <author><first>Igor</first><last>Melnyk</last></author>
      <author><first>Inkit</first><last>Padhi</last></author>
      <author><first>Cicero</first><last>Nogueira dos Santos</last></author>
      <author><first>Payel</first><last>Das</last></author>
      <pages>8605–8616</pages>
      <url hash="0d84c0a7">2020.emnlp-main.694</url>
    </paper>
    <paper id="695">
      <title>Incremental Neural Coreference Resolution in Constant Memory</title>
      <author><first>Patrick</first><last>Xia</last></author>
      <author><first>João</first><last>Sedoc</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>8617–8624</pages>
      <url hash="f33d3434">2020.emnlp-main.695</url>
    </paper>
    <paper id="696">
      <title>Improving Low Compute Language Modeling with In-Domain Embedding Initialisation</title>
      <author><first>Charles</first><last>Welch</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <author><first>Jonathan K.</first><last>Kummerfeld</last></author>
      <pages>8625–8634</pages>
      <url hash="895ecc70">2020.emnlp-main.696</url>
      <attachment type="OptionalSupplementaryMaterial" hash="69b990b0">2020.emnlp-main.696.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="697">
      <title><fixed-case>KGLM</fixed-case>: Pretrained Knowledge-Grounded Language Model for Data-to-Text Generation</title>
      <author><first>Wenhu</first><last>Chen</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <author><first>Xifeng</first><last>Yan</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>8635–8648</pages>
      <url hash="586e5db4">2020.emnlp-main.697</url>
    </paper>
    <paper id="698">
      <title>Pointer: Constrained Text Generation via Insertion-based Generative Pre-training</title>
      <author><first>Yizhe</first><last>Zhang</last></author>
      <author><first>Guoyin</first><last>Wang</last></author>
      <author><first>Chunyuan</first><last>Li</last></author>
      <author><first>Zhe</first><last>Gan</last></author>
      <author><first>Chris</first><last>Brockett</last></author>
      <author><first>Bill</first><last>Dolan</last></author>
      <pages>8649–8670</pages>
      <url hash="3028060f">2020.emnlp-main.698</url>
    </paper>
    <paper id="699">
      <title>Unsupervised Text Style Transfer with Masked Language Models</title>
      <author><first>Eric</first><last>Malmi</last></author>
      <author><first>Aliaksei</first><last>Severyn</last></author>
      <author><first>Sascha</first><last>Rothe</last></author>
      <pages>8671–8680</pages>
      <url hash="3991b386">2020.emnlp-main.699</url>
    </paper>
    <paper id="700">
      <title><fixed-case>PALM</fixed-case>: Pre-training an Autoencoding&amp;autoregressive Language Model for Context-conditioned Generation</title>
      <author><first>Bin</first><last>Bi</last></author>
      <author><first>Chenliang</first><last>Li</last></author>
      <author><first>Chen</first><last>Wu</last></author>
      <author><first>Ming</first><last>Yan</last></author>
      <author><first>Wei</first><last>Wang</last></author>
      <author><first>Songfang</first><last>Huang</last></author>
      <author><first>Fei</first><last>Huang</last></author>
      <author><first>Luo</first><last>Si</last></author>
      <pages>8681–8691</pages>
      <url hash="a9f01fc6">2020.emnlp-main.700</url>
    </paper>
    <paper id="701">
      <title>Gradient-guided Unsupervised Lexically Constrained Text Generation</title>
      <author><first>Lei</first><last>Sha</last></author>
      <pages>8692–8703</pages>
      <url hash="9a0bf558">2020.emnlp-main.701</url>
    </paper>
    <paper id="702">
      <title><fixed-case>T</fixed-case>ea<fixed-case>F</fixed-case>or<fixed-case>N</fixed-case>: Teacher-Forcing with N-grams</title>
      <author><first>Sebastian</first><last>Goodman</last></author>
      <author><first>Nan</first><last>Ding</last></author>
      <author><first>Radu</first><last>Soricut</last></author>
      <pages>8704–8717</pages>
      <url hash="594f687f">2020.emnlp-main.702</url>
    </paper>
    <paper id="703">
      <title>Experience Grounds Language</title>
      <author><first>Yonatan</first><last>Bisk</last></author>
      <author><first>Ari</first><last>Holtzman</last></author>
      <author><first>Jesse</first><last>Thomason</last></author>
      <author><first>Jacob</first><last>Andreas</last></author>
      <author><first>Yoshua</first><last>Bengio</last></author>
      <author><first>Joyce</first><last>Chai</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <author><first>Angeliki</first><last>Lazaridou</last></author>
      <author><first>Jonathan</first><last>May</last></author>
      <author><first>Aleksandr</first><last>Nisnevich</last></author>
      <author><first>Nicolas</first><last>Pinto</last></author>
      <author><first>Joseph</first><last>Turian</last></author>
      <pages>8718–8735</pages>
      <url hash="d1170c00">2020.emnlp-main.703</url>
    </paper>
    <paper id="704">
      <title>Keep <fixed-case>CALM</fixed-case> and Explore: Language Models for Action Generation in Text-based Games</title>
      <author><first>Shunyu</first><last>Yao</last></author>
      <author><first>Rohan</first><last>Rao</last></author>
      <author><first>Matthew</first><last>Hausknecht</last></author>
      <author><first>Karthik</first><last>Narasimhan</last></author>
      <pages>8736–8754</pages>
      <url hash="584517eb">2020.emnlp-main.704</url>
    </paper>
    <paper id="705">
      <title><fixed-case>C</fixed-case>ap<fixed-case>WAP</fixed-case>: Captioning with a Purpose</title>
      <author><first>Adam</first><last>Fisch</last></author>
      <author><first>Kenton</first><last>Lee</last></author>
      <author><first>Ming-Wei</first><last>Chang</last></author>
      <author><first>Jonathan</first><last>Clark</last></author>
      <author><first>Regina</first><last>Barzilay</last></author>
      <pages>8755–8768</pages>
      <url hash="db1d0213">2020.emnlp-main.705</url>
    </paper>
    <paper id="706">
      <title>What Is More Likely to Happen Next? Video-and-Language Future Event Prediction</title>
      <author><first>Jie</first><last>Lei</last></author>
      <author><first>Licheng</first><last>Yu</last></author>
      <author><first>Tamara</first><last>Berg</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>8769–8784</pages>
      <url hash="55b19d31">2020.emnlp-main.706</url>
    </paper>
    <paper id="707">
      <title><fixed-case>X</fixed-case>-<fixed-case>LXMERT</fixed-case>: Paint, Caption and Answer Questions with Multi-Modal Transformers</title>
      <author><first>Jaemin</first><last>Cho</last></author>
      <author><first>Jiasen</first><last>Lu</last></author>
      <author><first>Dustin</first><last>Schwenk</last></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last></author>
      <author><first>Aniruddha</first><last>Kembhavi</last></author>
      <pages>8785–8805</pages>
      <url hash="ba590616">2020.emnlp-main.707</url>
    </paper>
    <paper id="708">
      <title>Towards Understanding Sample Variance in Visually Grounded Language Generation: Evaluations and Observations</title>
      <author><first>Wanrong</first><last>Zhu</last></author>
      <author><first>Xin</first><last>Wang</last></author>
      <author><first>Pradyumna</first><last>Narayana</last></author>
      <author><first>Kazoo</first><last>Sone</last></author>
      <author><first>Sugato</first><last>Basu</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>8806–8811</pages>
      <url hash="9cd02c4a">2020.emnlp-main.708</url>
    </paper>
    <paper id="709">
      <title>Beyond Instructional Videos: Probing for More Diverse Visual-Textual Grounding on <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube</title>
      <author><first>Jack</first><last>Hessel</last></author>
      <author><first>Zhenhai</first><last>Zhu</last></author>
      <author><first>Bo</first><last>Pang</last></author>
      <author><first>Radu</first><last>Soricut</last></author>
      <pages>8812–8822</pages>
      <url hash="793d921b">2020.emnlp-main.709</url>
    </paper>
    <paper id="710">
      <title>Hierarchical Graph Network for Multi-hop Question Answering</title>
      <author><first>Yuwei</first><last>Fang</last></author>
      <author><first>Siqi</first><last>Sun</last></author>
      <author><first>Zhe</first><last>Gan</last></author>
      <author><first>Rohit</first><last>Pillai</last></author>
      <author><first>Shuohang</first><last>Wang</last></author>
      <author><first>Jingjing</first><last>Liu</last></author>
      <pages>8823–8838</pages>
      <url hash="0fcfe961">2020.emnlp-main.710</url>
    </paper>
    <paper id="711">
      <title>A Simple Yet Strong Pipeline for <fixed-case>H</fixed-case>otpot<fixed-case>QA</fixed-case></title>
      <author><first>Dirk</first><last>Groeneveld</last></author>
      <author><first>Tushar</first><last>Khot</last></author>
      <author><first></first><last>Mausam</last></author>
      <author><first>Ashish</first><last>Sabharwal</last></author>
      <pages>8839–8845</pages>
      <url hash="f1f3482d">2020.emnlp-main.711</url>
    </paper>
    <paper id="712">
      <title>Is Multihop <fixed-case>QA</fixed-case> in <fixed-case>D</fixed-case>i<fixed-case>R</fixed-case>e Condition? Measuring and Reducing Disconnected Reasoning</title>
      <author><first>Harsh</first><last>Trivedi</last></author>
      <author><first>Niranjan</first><last>Balasubramanian</last></author>
      <author><first>Tushar</first><last>Khot</last></author>
      <author><first>Ashish</first><last>Sabharwal</last></author>
      <pages>8846–8863</pages>
      <url hash="d373e949">2020.emnlp-main.712</url>
    </paper>
    <paper id="713">
      <title>Unsupervised Question Decomposition for Question Answering</title>
      <author><first>Ethan</first><last>Perez</last></author>
      <author><first>Patrick</first><last>Lewis</last></author>
      <author><first>Wen-tau</first><last>Yih</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <author><first>Douwe</first><last>Kiela</last></author>
      <pages>8864–8880</pages>
      <url hash="b39e105f">2020.emnlp-main.713</url>
    </paper>
    <paper id="714">
      <title><fixed-case>SRLGRN</fixed-case>: Semantic Role Labeling Graph Reasoning Network</title>
      <author><first>Chen</first><last>Zheng</last></author>
      <author><first>Parisa</first><last>Kordjamshidi</last></author>
      <pages>8881–8891</pages>
      <url hash="3e072eab">2020.emnlp-main.714</url>
    </paper>
    <paper id="715">
      <title><fixed-case>C</fixed-case>ancer<fixed-case>E</fixed-case>mo: A Dataset for Fine-Grained Emotion Detection</title>
      <author><first>Tiberiu</first><last>Sosea</last></author>
      <author><first>Cornelia</first><last>Caragea</last></author>
      <pages>8892–8904</pages>
      <url hash="6cd5a642">2020.emnlp-main.715</url>
    </paper>
    <paper id="716">
      <title>Exploring the Role of Argument Structure in Online Debate Persuasion</title>
      <author><first>Jialu</first><last>Li</last></author>
      <author><first>Esin</first><last>Durmus</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <pages>8905–8912</pages>
      <url hash="0843fcb2">2020.emnlp-main.716</url>
    </paper>
    <paper id="717">
      <title>Zero-Shot Stance Detection: A Dataset and Model Using Generalized Topic Representations</title>
      <author><first>Emily</first><last>Allaway</last></author>
      <author><first>Kathleen</first><last>McKeown</last></author>
      <pages>8913–8931</pages>
      <url hash="1f34965e">2020.emnlp-main.717</url>
    </paper>
    <paper id="718">
      <title>Sentiment Analysis of Tweets Using Heterogeneous Multi-layer Network Representation and Embedding</title>
      <author><first>Loitongbam</first><last>Gyanendro Singh</last></author>
      <author><first>Anasua</first><last>Mitra</last></author>
      <author><first>Sanasam</first><last>Ranbir Singh</last></author>
      <pages>8932–8946</pages>
      <url hash="4a3a68ab">2020.emnlp-main.718</url>
    </paper>
    <paper id="719">
      <title>Introducing Syntactic Structures into Target Opinion Word Extraction with Deep Learning</title>
      <author><first>Amir</first><last>Pouran Ben Veyseh</last></author>
      <author><first>Nasim</first><last>Nouri</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Dejing</first><last>Dou</last></author>
      <author><first>Thien Huu</first><last>Nguyen</last></author>
      <pages>8947–8956</pages>
      <url hash="46351962">2020.emnlp-main.719</url>
    </paper>
    <paper id="720">
      <title>Can Emojis Convey Human Emotions? A Study to Understand the Association between Emojis and Emotions</title>
      <author><first>Abu Awal Md</first><last>Shoeb</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <pages>8957–8967</pages>
      <url hash="cf6a5fa5">2020.emnlp-main.720</url>
    </paper>
    <paper id="721">
      <title><fixed-case>MIME</fixed-case>: <fixed-case>MIM</fixed-case>icking Emotions for Empathetic Response Generation</title>
      <author><first>Navonil</first><last>Majumder</last></author>
      <author><first>Pengfei</first><last>Hong</last></author>
      <author><first>Shanshan</first><last>Peng</last></author>
      <author><first>Jiankun</first><last>Lu</last></author>
      <author><first>Deepanway</first><last>Ghosal</last></author>
      <author><first>Alexander</first><last>Gelbukh</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <author><first>Soujanya</first><last>Poria</last></author>
      <pages>8968–8979</pages>
      <url hash="f45f9bdb">2020.emnlp-main.721</url>
    </paper>
    <paper id="722">
      <title>Exploiting Structured Knowledge in Text via Graph-Guided Representation Learning</title>
      <author><first>Tao</first><last>Shen</last></author>
      <author><first>Yi</first><last>Mao</last></author>
      <author><first>Pengcheng</first><last>He</last></author>
      <author><first>Guodong</first><last>Long</last></author>
      <author><first>Adam</first><last>Trischler</last></author>
      <author><first>Weizhu</first><last>Chen</last></author>
      <pages>8980–8994</pages>
      <url hash="77069e91">2020.emnlp-main.722</url>
    </paper>
    <paper id="723">
      <title>Named Entity Recognition Only from Word Embeddings</title>
      <author><first>Ying</first><last>Luo</last></author>
      <author><first>Hai</first><last>Zhao</last></author>
      <author><first>Junlang</first><last>Zhan</last></author>
      <pages>8995–9005</pages>
      <url hash="056f91b5">2020.emnlp-main.723</url>
    </paper>
    <paper id="724">
      <title>Weakly-Supervised Text Classification Using Label Names Only</title>
      <author><first>Yu</first><last>Meng</last></author>
      <author><first>Yunyi</first><last>Zhang</last></author>
      <author><first>Jiaxin</first><last>Huang</last></author>
      <author><first>Chenyan</first><last>Xiong</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Chao</first><last>Zhang</last></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <pages>9006–9017</pages>
      <url hash="2af30e42">2020.emnlp-main.724</url>
    </paper>
    <paper id="725">
      <title>Neural Topic Modeling with Cycle-Consistent Adversarial Training</title>
      <author><first>Xuemeng</first><last>Hu</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Deyu</first><last>Zhou</last></author>
      <author><first>Yuxuan</first><last>Xiong</last></author>
      <pages>9018–9030</pages>
      <url hash="348eb5d1">2020.emnlp-main.725</url>
    </paper>
    <paper id="726">
      <title>Data Boost: Text Data Augmentation through Reinforcement Learning Guided Conditional Generation</title>
      <author><first>Ruibo</first><last>Liu</last></author>
      <author><first>Guangxuan</first><last>Xu</last></author>
      <author><first>Chenyan</first><last>Jia</last></author>
      <author><first>Weicheng</first><last>Ma</last></author>
      <author><first>Lili</first><last>Wang</last></author>
      <author><first>Soroush</first><last>Vosoughi</last></author>
      <pages>9031–9041</pages>
      <url hash="2b25b7ff">2020.emnlp-main.726</url>
    </paper>
    <paper id="727">
      <title>A State-independent and Time-evolving Network with Applications to Early Rumor Detection</title>
      <author><first>Rui</first><last>Xia</last></author>
      <author><first>Kaizhou</first><last>Xuan</last></author>
      <author><first>Jianfei</first><last>Yu</last></author>
      <pages>9042–9051</pages>
      <url hash="ab939713">2020.emnlp-main.727</url>
    </paper>
    <paper id="728">
      <title><fixed-case>P</fixed-case>y<fixed-case>MT</fixed-case>5: Multi-mode Translation of Natural Language and Python Code with Transformers</title>
      <author><first>Colin</first><last>Clement</last></author>
      <author><first>Dawn</first><last>Drain</last></author>
      <author><first>Jonathan</first><last>Timcheck</last></author>
      <author><first>Alexey</first><last>Svyatkovskiy</last></author>
      <author><first>Neel</first><last>Sundaresan</last></author>
      <pages>9052–9065</pages>
      <url hash="a2f77444">2020.emnlp-main.728</url>
    </paper>
    <paper id="729">
      <title><fixed-case>P</fixed-case>ath<fixed-case>QG</fixed-case>: Neural Question Generation from Facts</title>
      <author><first>Siyuan</first><last>Wang</last></author>
      <author><first>Zhongyu</first><last>Wei</last></author>
      <author><first>Zhihao</first><last>Fan</last></author>
      <author><first>Zengfeng</first><last>Huang</last></author>
      <author><first>Weijian</first><last>Sun</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>9066–9075</pages>
      <url hash="ee1eb1eb">2020.emnlp-main.729</url>
      <attachment type="OptionalSupplementaryMaterial" hash="d02fef01">2020.emnlp-main.729.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="730">
      <title>What Time Is It? Temporal Analysis of Novels</title>
      <author><first>Allen</first><last>Kim</last></author>
      <author><first>Charuta</first><last>Pethe</last></author>
      <author><first>Steve</first><last>Skiena</last></author>
      <pages>9076–9086</pages>
      <url hash="661ba663">2020.emnlp-main.730</url>
    </paper>
    <paper id="731">
      <title><fixed-case>COGS</fixed-case>: A Compositional Generalization Challenge Based on Semantic Interpretation</title>
      <author><first>Najoung</first><last>Kim</last></author>
      <author><first>Tal</first><last>Linzen</last></author>
      <pages>9087–9105</pages>
      <url hash="b338e673">2020.emnlp-main.731</url>
    </paper>
    <paper id="732">
      <title>An Analysis of Natural Language Inference Benchmarks through the Lens of Negation</title>
      <author><first>Md Mosharaf</first><last>Hossain</last></author>
      <author><first>Venelin</first><last>Kovatchev</last></author>
      <author><first>Pranoy</first><last>Dutta</last></author>
      <author><first>Tiffany</first><last>Kao</last></author>
      <author><first>Elizabeth</first><last>Wei</last></author>
      <author><first>Eduardo</first><last>Blanco</last></author>
      <pages>9106–9118</pages>
      <url hash="671d4a9c">2020.emnlp-main.732</url>
    </paper>
    <paper id="733">
      <title>On the Sentence Embeddings from <fixed-case>BERT</fixed-case> for Semantic Textual Similarity</title>
      <author><first>Bohan</first><last>Li</last></author>
      <author><first>Hao</first><last>Zhou</last></author>
      <author><first>Junxian</first><last>He</last></author>
      <author><first>Mingxuan</first><last>Wang</last></author>
      <author><first>Yiming</first><last>Yang</last></author>
      <author><first>Lei</first><last>Li</last></author>
      <pages>9119–9130</pages>
      <url hash="fd84be54">2020.emnlp-main.733</url>
    </paper>
    <paper id="734">
      <title>What Can We Learn from Collective Human Opinions on Natural Language Inference Data?</title>
      <author><first>Yixin</first><last>Nie</last></author>
      <author><first>Xiang</first><last>Zhou</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>9131–9143</pages>
      <url hash="91cf1b60">2020.emnlp-main.734</url>
    </paper>
    <paper id="735">
      <title>Improving Text Generation with Student-Forcing Optimal Transport</title>
      <author><first>Jianqiao</first><last>Li</last></author>
      <author><first>Chunyuan</first><last>Li</last></author>
      <author><first>Guoyin</first><last>Wang</last></author>
      <author><first>Hao</first><last>Fu</last></author>
      <author><first>Yuhchen</first><last>Lin</last></author>
      <author><first>Liqun</first><last>Chen</last></author>
      <author><first>Yizhe</first><last>Zhang</last></author>
      <author><first>Chenyang</first><last>Tao</last></author>
      <author><first>Ruiyi</first><last>Zhang</last></author>
      <author><first>Wenlin</first><last>Wang</last></author>
      <author><first>Dinghan</first><last>Shen</last></author>
      <author><first>Qian</first><last>Yang</last></author>
      <author><first>Lawrence</first><last>Carin</last></author>
      <pages>9144–9156</pages>
      <url hash="89bdf95c">2020.emnlp-main.735</url>
    </paper>
    <paper id="736">
      <title><fixed-case>UNION</fixed-case>: An Unreferenced Metric for Evaluating Open-ended Story Generation</title>
      <author><first>Jian</first><last>Guan</last></author>
      <author><first>Minlie</first><last>Huang</last></author>
      <pages>9157–9166</pages>
      <url hash="03c03431">2020.emnlp-main.736</url>
      <attachment type="OptionalSupplementaryMaterial" hash="fe3e2a8a">2020.emnlp-main.736.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="737">
      <title>Fˆ2-Softmax: Diversifying Neural Text Generation via Frequency Factorized Softmax</title>
      <author><first>Byung-Ju</first><last>Choi</last></author>
      <author><first>Jimin</first><last>Hong</last></author>
      <author><first>David</first><last>Park</last></author>
      <author><first>Sang Wan</first><last>Lee</last></author>
      <pages>9167–9182</pages>
      <url hash="3d0f3732">2020.emnlp-main.737</url>
      <attachment type="OptionalSupplementaryMaterial" hash="0b2bb6e3">2020.emnlp-main.737.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="738">
      <title>Partially-Aligned Data-to-Text Generation with Distant Supervision</title>
      <author><first>Zihao</first><last>Fu</last></author>
      <author><first>Bei</first><last>Shi</last></author>
      <author><first>Wai</first><last>Lam</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <pages>9183–9193</pages>
      <url hash="d18434db">2020.emnlp-main.738</url>
    </paper>
    <paper id="739">
      <title>Like Hiking? You Probably Enjoy Nature: Persona-grounded Dialog with Commonsense Expansions</title>
      <author><first>Bodhisattwa Prasad</first><last>Majumder</last></author>
      <author><first>Harsh</first><last>Jhamtani</last></author>
      <author><first>Taylor</first><last>Berg-Kirkpatrick</last></author>
      <author><first>Julian</first><last>McAuley</last></author>
      <pages>9194–9206</pages>
      <url hash="44bcd9c6">2020.emnlp-main.739</url>
    </paper>
    <paper id="740">
      <title>A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning</title>
      <author><first>Yichi</first><last>Zhang</last></author>
      <author><first>Zhijian</first><last>Ou</last></author>
      <author><first>Min</first><last>Hu</last></author>
      <author><first>Junlan</first><last>Feng</last></author>
      <pages>9207–9219</pages>
      <url hash="ea3eda4b">2020.emnlp-main.740</url>
    </paper>
    <paper id="741">
      <title>The World Is Not Binary: Learning to Rank with Grayscale Data for Dialogue Response Selection</title>
      <author><first>Zibo</first><last>Lin</last></author>
      <author><first>Deng</first><last>Cai</last></author>
      <author><first>Yan</first><last>Wang</last></author>
      <author><first>Xiaojiang</first><last>Liu</last></author>
      <author><first>Haitao</first><last>Zheng</last></author>
      <author><first>Shuming</first><last>Shi</last></author>
      <pages>9220–9229</pages>
      <url hash="321de580">2020.emnlp-main.741</url>
    </paper>
    <paper id="742">
      <title><fixed-case>GRADE</fixed-case>: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems</title>
      <author><first>Lishan</first><last>Huang</last></author>
      <author><first>Zheng</first><last>Ye</last></author>
      <author><first>Jinghui</first><last>Qin</last></author>
      <author><first>Liang</first><last>Lin</last></author>
      <author><first>Xiaodan</first><last>Liang</last></author>
      <pages>9230–9240</pages>
      <url hash="92dc5e93">2020.emnlp-main.742</url>
    </paper>
    <paper id="743">
      <title><fixed-case>M</fixed-case>ed<fixed-case>D</fixed-case>ialog: A Large-scale Medical Dialogue Dataset</title>
      <author><first>Guangtao</first><last>Zeng</last></author>
      <author><first>Wenmian</first><last>Yang</last></author>
      <author><first>Zeqian</first><last>Ju</last></author>
      <author><first>Yue</first><last>Yang</last></author>
      <author><first>Sicheng</first><last>Wang</last></author>
      <author><first>Ruisi</first><last>Zhang</last></author>
      <author><first>Meng</first><last>Zhou</last></author>
      <author><first>Jiaqi</first><last>Zeng</last></author>
      <author><first>Xiangyu</first><last>Dong</last></author>
      <author><first>Ruoyu</first><last>Zhang</last></author>
      <author><first>Hongchao</first><last>Fang</last></author>
      <author><first>Penghui</first><last>Zhu</last></author>
      <author><first>Shu</first><last>Chen</last></author>
      <author><first>Pengtao</first><last>Xie</last></author>
      <pages>9241–9250</pages>
      <url hash="b19ec492">2020.emnlp-main.743</url>
    </paper>
    <paper id="744">
      <title>An Information Theoretic View on Selecting Linguistic Probes</title>
      <author><first>Zining</first><last>Zhu</last></author>
      <author><first>Frank</first><last>Rudzicz</last></author>
      <pages>9251–9262</pages>
      <url hash="0afa51fd">2020.emnlp-main.744</url>
    </paper>
    <paper id="745">
      <title>With Little Power Comes Great Responsibility</title>
      <author><first>Dallas</first><last>Card</last></author>
      <author><first>Peter</first><last>Henderson</last></author>
      <author><first>Urvashi</first><last>Khandelwal</last></author>
      <author><first>Robin</first><last>Jia</last></author>
      <author><first>Kyle</first><last>Mahowald</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <pages>9263–9274</pages>
      <url hash="c7e1b324">2020.emnlp-main.745</url>
      <attachment type="OptionalSupplementaryMaterial" hash="c8550856">2020.emnlp-main.745.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="746">
      <title>Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics</title>
      <author><first>Swabha</first><last>Swayamdipta</last></author>
      <author><first>Roy</first><last>Schwartz</last></author>
      <author><first>Nicholas</first><last>Lourie</last></author>
      <author><first>Yizhong</first><last>Wang</last></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last></author>
      <author><first>Noah A.</first><last>Smith</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>9275–9293</pages>
      <url hash="d9a06e7c">2020.emnlp-main.746</url>
    </paper>
    <paper id="747">
      <title>Evaluating and Characterizing Human Rationales</title>
      <author><first>Samuel</first><last>Carton</last></author>
      <author><first>Anirudh</first><last>Rathore</last></author>
      <author><first>Chenhao</first><last>Tan</last></author>
      <pages>9294–9307</pages>
      <url hash="6ae1598c">2020.emnlp-main.747</url>
    </paper>
    <paper id="748">
      <title>On Extractive and Abstractive Neural Document Summarization with Transformer Language Models</title>
      <author><first>Jonathan</first><last>Pilault</last></author>
      <author><first>Raymond</first><last>Li</last></author>
      <author><first>Sandeep</first><last>Subramanian</last></author>
      <author><first>Chris</first><last>Pal</last></author>
      <pages>9308–9319</pages>
      <url hash="42f410a6">2020.emnlp-main.748</url>
    </paper>
    <paper id="749">
      <title>Multi-Fact Correction in Abstractive Text Summarization</title>
      <author><first>Yue</first><last>Dong</last></author>
      <author><first>Shuohang</first><last>Wang</last></author>
      <author><first>Zhe</first><last>Gan</last></author>
      <author><first>Yu</first><last>Cheng</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <author><first>Jingjing</first><last>Liu</last></author>
      <pages>9320–9331</pages>
      <url hash="ead146aa">2020.emnlp-main.749</url>
    </paper>
    <paper id="750">
      <title>Evaluating the Factual Consistency of Abstractive Text Summarization</title>
      <author><first>Wojciech</first><last>Kryscinski</last></author>
      <author><first>Bryan</first><last>McCann</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <author><first>Richard</first><last>Socher</last></author>
      <pages>9332–9346</pages>
      <url hash="e249fe90">2020.emnlp-main.750</url>
    </paper>
    <paper id="751">
      <title>Re-evaluating Evaluation in Text Summarization</title>
      <author><first>Manik</first><last>Bhandari</last></author>
      <author><first>Pranav Narayan</first><last>Gour</last></author>
      <author><first>Atabak</first><last>Ashfaq</last></author>
      <author><first>Pengfei</first><last>Liu</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>9347–9359</pages>
      <url hash="e8f69f8e">2020.emnlp-main.751</url>
    </paper>
    <paper id="752">
      <title><fixed-case>VMSMO</fixed-case>: Learning to Generate Multimodal Summary for Video-based News Articles</title>
      <author><first>Mingzhe</first><last>Li</last></author>
      <author><first>Xiuying</first><last>Chen</last></author>
      <author><first>Shen</first><last>Gao</last></author>
      <author><first>Zhangming</first><last>Chan</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <pages>9360–9369</pages>
      <url hash="90398dfd">2020.emnlp-main.752</url>
    </paper>
  </volume>
  <volume id="demos" ingest-date="2020-11-05">
    <meta>
      <booktitle>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</booktitle>
      <editor><first>Qun</first><last>Liu</last></editor>
      <editor><first>David</first><last>Schlangen</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>October</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="b657487c">2020.emnlp-demos.0</url>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>O</fixed-case>pen<fixed-case>UE</fixed-case>: An Open Toolkit of Universal Extraction from Text</title>
      <author><first>Ningyu</first><last>Zhang</last></author>
      <author><first>Shumin</first><last>Deng</last></author>
      <author><first>Zhen</first><last>Bi</last></author>
      <author><first>Haiyang</first><last>Yu</last></author>
      <author><first>Jiacheng</first><last>Yang</last></author>
      <author><first>Mosha</first><last>Chen</last></author>
      <author><first>Fei</first><last>Huang</last></author>
      <author><first>Wei</first><last>Zhang</last></author>
      <author><first>Huajun</first><last>Chen</last></author>
      <pages>1–8</pages>
      <abstract>Natural language processing covers a wide variety of tasks with token-level or sentence-level understandings. In this paper, we provide a simple insight that most tasks can be represented in a single universal extraction format. We introduce a prototype model and provide an open-source and extensible toolkit called OpenUE for various extraction tasks. OpenUE allows developers to train custom models to extract information from the text and supports quick model validation for researchers. Besides, OpenUE provides various functional modules to maintain sufficient modularity and extensibility. Except for the toolkit, we also deploy an online demo with restful APIs to support real-time extraction without training and deploying. Additionally, the online system can extract information in various tasks, including relational triple extraction, slot &amp; intent detection, event extraction, and so on. We release the source code, datasets, and pre-trained models to promote future researches in http://github.com/zjunlp/openue.</abstract>
      <url hash="1c22e577">2020.emnlp-demos.1</url>
    </paper>
    <paper id="2">
      <title><fixed-case>BERT</fixed-case>weet: A pre-trained language model for <fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>Dat Quoc</first><last>Nguyen</last></author>
      <author><first>Thanh</first><last>Vu</last></author>
      <author><first>Anh</first><last>Tuan Nguyen</last></author>
      <pages>9–14</pages>
      <abstract>We present BERTweet, the first public large-scale pre-trained language model for English Tweets. Our BERTweet, having the same architecture as BERT-base (Devlin et al., 2019), is trained using the RoBERTa pre-training procedure (Liu et al., 2019). Experiments show that BERTweet outperforms strong baselines RoBERTa-base and XLM-R-base (Conneau et al., 2020), producing better performance results than the previous state-of-the-art models on three Tweet NLP tasks: Part-of-speech tagging, Named-entity recognition and text classification. We release BERTweet under the MIT License to facilitate future research and applications on Tweet data. Our BERTweet is available at https://github.com/VinAIResearch/BERTweet</abstract>
      <url hash="97707e21">2020.emnlp-demos.2</url>
    </paper>
    <paper id="3">
      <title><fixed-case>N</fixed-case>eural<fixed-case>QA</fixed-case>: A Usable Library for Question Answering (Contextual Query Expansion + <fixed-case>BERT</fixed-case>) on Large Datasets</title>
      <author><first>Victor</first><last>Dibia</last></author>
      <pages>15–22</pages>
      <abstract>Existing tools for Question Answering (QA) have challenges that limit their use in practice. They can be complex to set up or integrate with existing infrastructure, do not offer configurable interactive interfaces, and do not cover the full set of subtasks that frequently comprise the QA pipeline (query expansion, retrieval, reading, and explanation/sensemaking). To help address these issues, we introduce NeuralQA - a usable library for QA on large datasets. NeuralQA integrates well with existing infrastructure (e.g., ElasticSearch instances and reader models trained with the HuggingFace Transformers API) and offers helpful defaults for QA subtasks. It introduces and implements contextual query expansion (CQE) using a masked language model (MLM) as well as relevant snippets (<tex-math>RelSnip</tex-math>) - a method for condensing large documents into smaller passages that can be speedily processed by a document reader model. Finally, it offers a flexible user interface to support workflows for research explorations (e.g., visualization of gradient-based explanations to support qualitative inspection of model behaviour) and large scale search deployment. Code and documentation for NeuralQA is available as open source on Github.</abstract>
      <url hash="4dff58ad">2020.emnlp-demos.3</url>
    </paper>
    <paper id="4">
      <title><fixed-case>W</fixed-case>ikipedia2<fixed-case>V</fixed-case>ec: An Efficient Toolkit for Learning and Visualizing the Embeddings of Words and Entities from <fixed-case>W</fixed-case>ikipedia</title>
      <author><first>Ikuya</first><last>Yamada</last></author>
      <author><first>Akari</first><last>Asai</last></author>
      <author><first>Jin</first><last>Sakuma</last></author>
      <author><first>Hiroyuki</first><last>Shindo</last></author>
      <author><first>Hideaki</first><last>Takeda</last></author>
      <author><first>Yoshiyasu</first><last>Takefuji</last></author>
      <author><first>Yuji</first><last>Matsumoto</last></author>
      <pages>23–30</pages>
      <abstract>The embeddings of entities in a large knowledge base (e.g., Wikipedia) are highly beneficial for solving various natural language tasks that involve real world knowledge. In this paper, we present Wikipedia2Vec, a Python-based open-source tool for learning the embeddings of words and entities from Wikipedia. The proposed tool enables users to learn the embeddings efficiently by issuing a single command with a Wikipedia dump file as an argument. We also introduce a web-based demonstration of our tool that allows users to visualize and explore the learned embeddings. In our experiments, our tool achieved a state-of-the-art result on the KORE entity relatedness dataset, and competitive results on various standard benchmark datasets. Furthermore, our tool has been used as a key component in various recent studies. We publicize the source code, demonstration, and the pretrained embeddings for 12 languages at https://wikipedia2vec.github.io/.</abstract>
      <url hash="d7e02b98">2020.emnlp-demos.4</url>
    </paper>
    <paper id="5">
      <title><fixed-case>ARES</fixed-case>: A Reading Comprehension Ensembling Service</title>
      <author><first>Anthony</first><last>Ferritto</last></author>
      <author><first>Lin</first><last>Pan</last></author>
      <author><first>Rishav</first><last>Chakravarti</last></author>
      <author><first>Salim</first><last>Roukos</last></author>
      <author><first>Radu</first><last>Florian</last></author>
      <author><first>J. William</first><last>Murdock</last></author>
      <author><first>Avi</first><last>Sil</last></author>
      <pages>31–37</pages>
      <abstract>We introduce ARES (A Reading Comprehension Ensembling Service): a novel Machine Reading Comprehension (MRC) demonstration system which utilizes an ensemble of models to increase F1 by 2.3 points. While many of the top leaderboard submissions in popular MRC benchmarks such as the Stanford Question Answering Dataset (SQuAD) and Natural Questions (NQ) use model ensembles, the accompanying papers do not publish their ensembling strategies. In this work, we detail and evaluate various ensembling strategies using the NQ dataset. ARES leverages the CFO (Chakravarti et al., 2019) and ReactJS distributed frameworks to provide a scalable interactive Question Answering experience that capitalizes on the agreement (or lack thereof) between models to improve the answer visualization experience.</abstract>
      <url hash="846870fd">2020.emnlp-demos.5</url>
    </paper>
    <paper id="6">
      <title>Transformers: State-of-the-Art Natural Language Processing</title>
      <author><first>Thomas</first><last>Wolf</last></author>
      <author><first>Julien</first><last>Chaumond</last></author>
      <author><first>Lysandre</first><last>Debut</last></author>
      <author><first>Victor</first><last>Sanh</last></author>
      <author><first>Clement</first><last>Delangue</last></author>
      <author><first>Anthony</first><last>Moi</last></author>
      <author><first>Pierric</first><last>Cistac</last></author>
      <author><first>Morgan</first><last>Funtowicz</last></author>
      <author><first>Joe</first><last>Davison</last></author>
      <author><first>Sam</first><last>Shleifer</last></author>
      <author><first>Remi</first><last>Louf</last></author>
      <author><first>Patrick</first><last>von Platen</last></author>
      <author><first>Tim</first><last>Rault</last></author>
      <author><first>Yacine</first><last>Jernite</last></author>
      <author><first>Teven</first><last>Le Scao</last></author>
      <author><first>Sylvain</first><last>Gugger</last></author>
      <author><first>Julien</first><last>Plu</last></author>
      <author><first>Clara</first><last>Ma</last></author>
      <author><first>Canwei</first><last>Shen</last></author>
      <author><first>Mariama</first><last>Drame</last></author>
      <author><first>Quentin</first><last>Lhoest</last></author>
      <author><first>Alexander</first><last>Rush</last></author>
      <pages>38–45</pages>
      <abstract>Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/huggingface/transformers.</abstract>
      <url hash="bdef05b9">2020.emnlp-demos.6</url>
    </paper>
    <paper id="7">
      <title><fixed-case>A</fixed-case>dapter<fixed-case>H</fixed-case>ub: A Framework for Adapting Transformers</title>
      <author><first>Jonas</first><last>Pfeiffer</last></author>
      <author><first>Andreas</first><last>Rücklé</last></author>
      <author><first>Clifton</first><last>Poth</last></author>
      <author><first>Aishwarya</first><last>Kamath</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>46–54</pages>
      <abstract>The current modus operandi in NLP involves downloading and fine-tuning pre-trained models consisting of millions or billions of parameters. Storing and sharing such large trained models is expensive, slow, and time-consuming, which impedes progress towards more general and versatile NLP methods that learn from and for many tasks. Adapters—small learnt bottleneck layers inserted within each layer of a pre-trained model— ameliorate this issue by avoiding full fine-tuning of the entire model. However, sharing and integrating adapter layers is not straightforward. We propose AdapterHub, a framework that allows dynamic “stiching-in” of pre-trained adapters for different tasks and languages. The framework, built on top of the popular HuggingFace Transformers library, enables extremely easy and quick adaptations of state-of-the-art pre-trained models (e.g., BERT, RoBERTa, XLM-R) across tasks and languages. Downloading, sharing, and training adapters is as seamless as possible using minimal changes to the training scripts and a specialized infrastructure. Our framework enables scalable and easy access to sharing of task-specific models, particularly in low-resource scenarios. AdapterHub includes all recent adapter architectures and can be found at AdapterHub.ml</abstract>
      <url hash="cebd65f8">2020.emnlp-demos.7</url>
      <attachment type="OptionalSupplementaryMaterial" hash="cff067f3">2020.emnlp-demos.7.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="8">
      <title><fixed-case>HUMAN</fixed-case>: Hierarchical Universal Modular <fixed-case>AN</fixed-case>notator</title>
      <author><first>Moritz</first><last>Wolf</last></author>
      <author><first>Dana</first><last>Ruiter</last></author>
      <author><first>Ashwin Geet</first><last>D’Sa</last></author>
      <author><first>Liane</first><last>Reiners</last></author>
      <author><first>Jan</first><last>Alexandersson</last></author>
      <author><first>Dietrich</first><last>Klakow</last></author>
      <pages>55–61</pages>
      <abstract>A lot of real-world phenomena are complex and cannot be captured by single task annotations. This causes a need for subsequent annotations, with interdependent questions and answers describing the nature of the subject at hand. Even in the case a phenomenon is easily captured by a single task, the high specialisation of most annotation tools can result in having to switch to another tool if the task only slightly changes. We introduce HUMAN, a novel web-based annotation tool that addresses the above problems by a) covering a variety of annotation tasks on both textual and image data, and b) the usage of an internal deterministic state machine, allowing the researcher to chain different annotation tasks in an interdependent manner. Further, the modular nature of the tool makes it easy to define new annotation tasks and integrate machine learning algorithms e.g., for active learning. HUMAN comes with an easy-to-use graphical user interface that simplifies the annotation task and management.</abstract>
      <url hash="c0a94154">2020.emnlp-demos.8</url>
    </paper>
    <paper id="9">
      <title><fixed-case>D</fixed-case>eezy<fixed-case>M</fixed-case>atch: A Flexible Deep Learning Approach to Fuzzy String Matching</title>
      <author><first>Kasra</first><last>Hosseini</last></author>
      <author><first>Federico</first><last>Nanni</last></author>
      <author><first>Mariona</first><last>Coll Ardanuy</last></author>
      <pages>62–69</pages>
      <abstract>We present DeezyMatch, a free, open-source software library written in Python for fuzzy string matching and candidate ranking. Its pair classifier supports various deep neural network architectures for training new classifiers and for fine-tuning a pretrained model, which paves the way for transfer learning in fuzzy string matching. This approach is especially useful where only limited training examples are available. The learned DeezyMatch models can be used to generate rich vector representations from string inputs. The candidate ranker component in DeezyMatch uses these vector representations to find, for a given query, the best matching candidates in a knowledge base. It uses an adaptive searching algorithm applicable to large knowledge bases and query sets. We describe DeezyMatch’s functionality, design and implementation, accompanied by a use case in toponym matching and candidate ranking in realistic noisy datasets.</abstract>
      <url hash="ea7e2915">2020.emnlp-demos.9</url>
    </paper>
    <paper id="10">
      <title><fixed-case>C</fixed-case>o<fixed-case>S</fixed-case>a<fixed-case>T</fixed-case>a: A Constraint Satisfaction Solver and Interpreted Language for Semi-Structured Tables of Sentences</title>
      <author><first>Peter</first><last>Jansen</last></author>
      <pages>70–76</pages>
      <abstract>This work presents CoSaTa, an intuitive constraint satisfaction solver and interpreted language for knowledge bases of semi-structured tables expressed as text. The stand-alone CoSaTa solver allows easily expressing complex compositional “inference patterns” for how knowledge from different tables tends to connect to support inference and explanation construction in question answering and other downstream tasks, while including advanced declarative features and the ability to operate over multiple representations of text (words, lemmas, or part-of-speech tags). CoSaTa also includes a hybrid imperative/declarative interpreted language for expressing simple models through minimally-specified simulations grounded in constraint patterns, helping bridge the gap between question answering, question explanation, and model simulation. The solver and interpreter are released as open source. Screencast Demo: https://youtu.be/t93Acsz7LyE</abstract>
      <url hash="c1b464c2">2020.emnlp-demos.10</url>
    </paper>
    <paper id="11">
      <title><fixed-case>I</fixed-case>n<fixed-case>V</fixed-case>e<fixed-case>R</fixed-case>o: Making Semantic Role Labeling Accessible with Intelligible Verbs and Roles</title>
      <author><first>Simone</first><last>Conia</last></author>
      <author><first>Fabrizio</first><last>Brignone</last></author>
      <author><first>Davide</first><last>Zanfardino</last></author>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>77–84</pages>
      <abstract>Semantic Role Labeling (SRL) is deeply dependent on complex linguistic resources and sophisticated neural models, which makes the task difficult to approach for non-experts. To address this issue we present a new platform named Intelligible Verbs and Roles (InVeRo). This platform provides access to a new verb resource, VerbAtlas, and a state-of-the-art pretrained implementation of a neural, span-based architecture for SRL. Both the resource and the system provide human-readable verb sense and semantic role information, with an easy to use Web interface and RESTful APIs available at http://nlp.uniroma1.it/invero.</abstract>
      <url hash="aeafae47">2020.emnlp-demos.11</url>
    </paper>
    <paper id="12">
      <title>Youling: an <fixed-case>AI</fixed-case>-assisted Lyrics Creation System</title>
      <author><first>Rongsheng</first><last>Zhang</last></author>
      <author><first>Xiaoxi</first><last>Mao</last></author>
      <author><first>Le</first><last>Li</last></author>
      <author><first>Lin</first><last>Jiang</last></author>
      <author><first>Lin</first><last>Chen</last></author>
      <author><first>Zhiwei</first><last>Hu</last></author>
      <author><first>Yadong</first><last>Xi</last></author>
      <author><first>Changjie</first><last>Fan</last></author>
      <author><first>Minlie</first><last>Huang</last></author>
      <pages>85–91</pages>
      <abstract>Recently, a variety of neural models have been proposed for lyrics generation. However, most previous work completes the generation process in a single pass with little human intervention. We believe that lyrics creation is a creative process with human intelligence centered. AI should play a role as an assistant in the lyrics creation process, where human interactions are crucial for high-quality creation. This paper demonstrates <i>Youling</i>, an AI-assisted lyrics creation system, designed to collaborate with music creators. In the lyrics generation process, <i>Youling</i> supports traditional one pass full-text generation mode as well as an interactive generation mode, which allows users to select the satisfactory sentences from generated candidates conditioned on preceding context. The system also provides a revision module which enables users to revise undesired sentences or words of lyrics repeatedly. Besides, <i>Youling</i> allows users to use multifaceted attributes to control the content and format of generated lyrics. The demo video of the system is available at https://youtu.be/DFeNpHk0pm4.</abstract>
      <url hash="2901f09c">2020.emnlp-demos.12</url>
    </paper>
    <paper id="13">
      <title>A Technical Question Answering System with Transfer Learning</title>
      <author><first>Wenhao</first><last>Yu</last></author>
      <author><first>Lingfei</first><last>Wu</last></author>
      <author><first>Yu</first><last>Deng</last></author>
      <author><first>Ruchi</first><last>Mahindru</last></author>
      <author><first>Qingkai</first><last>Zeng</last></author>
      <author><first>Sinem</first><last>Guven</last></author>
      <author><first>Meng</first><last>Jiang</last></author>
      <pages>92–99</pages>
      <abstract>In recent years, the need for community technical question-answering sites has increased significantly. However, it is often expensive for human experts to provide timely and helpful responses on those forums. We develop TransTQA, which is a novel system that offers automatic responses by retrieving proper answers based on correctly answered similar questions in the past. TransTQA is built upon a siamese ALBERT network, which enables it to respond quickly and accurately. Furthermore, TransTQA adopts a standard deep transfer learning strategy to improve its capability of supporting multiple technical domains.</abstract>
      <url hash="49626f9e">2020.emnlp-demos.13</url>
      <attachment type="OptionalSupplementaryMaterial" hash="27fdf124">2020.emnlp-demos.13.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="14">
      <title><fixed-case>ENTYFI</fixed-case>: A System for Fine-grained Entity Typing in Fictional Texts</title>
      <author><first>Cuong Xuan</first><last>Chu</last></author>
      <author><first>Simon</first><last>Razniewski</last></author>
      <author><first>Gerhard</first><last>Weikum</last></author>
      <pages>100–106</pages>
      <abstract>Fiction and fantasy are archetypes of long-tail domains that lack suitable NLP methodologies and tools. We present ENTYFI, a web-based system for fine-grained typing of entity mentions in fictional texts. It builds on 205 automatically induced high-quality type systems for popular fictional domains, and provides recommendations towards reference type systems for given input texts. Users can exploit the richness and diversity of these reference type systems for fine-grained supervised typing, in addition, they can choose among and combine four other typing modules: pre-trained real-world models, unsupervised dependency-based typing, knowledge base lookups, and constraint-based candidate consolidation. The demonstrator is available at: https://d5demos.mpi-inf.mpg.de/entyfi.</abstract>
      <url hash="5a650959">2020.emnlp-demos.14</url>
    </paper>
    <paper id="15">
      <title>The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for <fixed-case>NLP</fixed-case> Models</title>
      <author><first>Ian</first><last>Tenney</last></author>
      <author><first>James</first><last>Wexler</last></author>
      <author><first>Jasmijn</first><last>Bastings</last></author>
      <author><first>Tolga</first><last>Bolukbasi</last></author>
      <author><first>Andy</first><last>Coenen</last></author>
      <author><first>Sebastian</first><last>Gehrmann</last></author>
      <author><first>Ellen</first><last>Jiang</last></author>
      <author><first>Mahima</first><last>Pushkarna</last></author>
      <author><first>Carey</first><last>Radebaugh</last></author>
      <author><first>Emily</first><last>Reif</last></author>
      <author><first>Ann</first><last>Yuan</last></author>
      <pages>107–118</pages>
      <abstract>We present the Language Interpretability Tool (LIT), an open-source platform for visualization and understanding of NLP models. We focus on core questions about model behavior: Why did my model make this prediction? When does it perform poorly? What happens under a controlled change in the input? LIT integrates local explanations, aggregate analysis, and counterfactual generation into a streamlined, browser-based interface to enable rapid exploration and error analysis. We include case studies for a diverse set of workflows, including exploring counterfactuals for sentiment analysis, measuring gender bias in coreference systems, and exploring local behavior in text generation. LIT supports a wide range of models—including classification, seq2seq, and structured prediction—and is highly extensible through a declarative, framework-agnostic API. LIT is under active development, with code and full documentation available at https://github.com/pair-code/lit.</abstract>
      <url hash="eceae4d3">2020.emnlp-demos.15</url>
    </paper>
    <paper id="16">
      <title><fixed-case>T</fixed-case>ext<fixed-case>A</fixed-case>ttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in <fixed-case>NLP</fixed-case></title>
      <author><first>John</first><last>Morris</last></author>
      <author><first>Eli</first><last>Lifland</last></author>
      <author><first>Jin Yong</first><last>Yoo</last></author>
      <author><first>Jake</first><last>Grigsby</last></author>
      <author><first>Di</first><last>Jin</last></author>
      <author><first>Yanjun</first><last>Qi</last></author>
      <pages>119–126</pages>
      <abstract>While there has been substantial research using adversarial attacks to analyze NLP models, each attack is implemented in its own code repository. It remains challenging to develop NLP attacks and utilize them to improve model performance. This paper introduces TextAttack, a Python framework for adversarial attacks, data augmentation, and adversarial training in NLP. TextAttack builds attacks from four components: a goal function, a set of constraints, a transformation, and a search method. TextAttack’s modular design enables researchers to easily construct attacks from combinations of novel and existing components. TextAttack provides implementations of 16 adversarial attacks from the literature and supports a variety of models and datasets, including BERT and other transformers, and all GLUE tasks. TextAttack also includes data augmentation and adversarial training modules for using components of adversarial attacks to improve model accuracy and robustness.TextAttack is democratizing NLP: anyone can try data augmentation and adversarial training on any model or dataset, with just a few lines of code. Code and tutorials are available at https://github.com/QData/TextAttack.</abstract>
      <url hash="27e206c2">2020.emnlp-demos.16</url>
      <attachment type="OptionalSupplementaryMaterial" hash="03f47d69">2020.emnlp-demos.16.OptionalSupplementaryMaterial.zip</attachment>
    </paper>
    <paper id="17">
      <title>Easy, Reproducible and Quality-Controlled Data Collection with <fixed-case>CROWDAQ</fixed-case></title>
      <author><first>Qiang</first><last>Ning</last></author>
      <author><first>Hao</first><last>Wu</last></author>
      <author><first>Pradeep</first><last>Dasigi</last></author>
      <author><first>Dheeru</first><last>Dua</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <author><first>Robert L.</first><last>Logan IV</last></author>
      <author><first>Ana</first><last>Marasović</last></author>
      <author><first>Zhen</first><last>Nie</last></author>
      <pages>127–134</pages>
      <abstract>High-quality and large-scale data are key to success for AI systems. However, large-scale data annotation efforts are often confronted with a set of common challenges: (1) designing a user-friendly annotation interface; (2) training enough annotators efficiently; and (3) reproducibility. To address these problems, we introduce CROWDAQ, an open-source platform that standardizes the data collection pipeline with customizable user-interface components, automated annotator qualification, and saved pipelines in a re-usable format. We show that CROWDAQ simplifies data annotation significantly on a diverse set of data collection use cases and we hope it will be a convenient tool for the community.</abstract>
      <url hash="76ee9fe4">2020.emnlp-demos.17</url>
      <attachment type="OptionalSupplementaryMaterial" hash="efb16808">2020.emnlp-demos.17.OptionalSupplementaryMaterial.pdf</attachment>
    </paper>
    <paper id="18">
      <title><fixed-case>S</fixed-case>ci<fixed-case>S</fixed-case>ight: Combining faceted navigation and research group detection for <fixed-case>COVID</fixed-case>-19 exploratory scientific search</title>
      <author><first>Tom</first><last>Hope</last></author>
      <author><first>Jason</first><last>Portenoy</last></author>
      <author><first>Kishore</first><last>Vasan</last></author>
      <author><first>Jonathan</first><last>Borchardt</last></author>
      <author><first>Eric</first><last>Horvitz</last></author>
      <author><first>Daniel</first><last>Weld</last></author>
      <author><first>Marti</first><last>Hearst</last></author>
      <author><first>Jevin</first><last>West</last></author>
      <pages>135–143</pages>
      <abstract>The COVID-19 pandemic has sparked unprecedented mobilization of scientists, generating a deluge of papers that makes it hard for researchers to keep track and explore new directions. Search engines are designed for targeted queries, not for discovery of connections across a corpus. In this paper, we present SciSight, a system for exploratory search of COVID-19 research integrating two key capabilities: first, exploring associations between biomedical facets automatically extracted from papers (e.g., genes, drugs, diseases, patient outcomes); second, combining textual and network information to search and visualize groups of researchers and their ties. SciSight has so far served over 15K users with over 42K page views and 13% returns.</abstract>
      <url hash="c9b66e5b">2020.emnlp-demos.18</url>
    </paper>
    <paper id="19">
      <title><fixed-case>SIMULEVAL</fixed-case>: An Evaluation Toolkit for Simultaneous Translation</title>
      <author><first>Xutai</first><last>Ma</last></author>
      <author><first>Mohammad Javad</first><last>Dousti</last></author>
      <author><first>Changhan</first><last>Wang</last></author>
      <author><first>Jiatao</first><last>Gu</last></author>
      <author><first>Juan</first><last>Pino</last></author>
      <pages>144–150</pages>
      <abstract>Simultaneous translation on both text and speech focuses on a real-time and low-latency scenario where the model starts translating before reading the complete source input. Evaluating simultaneous translation models is more complex than offline models because the latency is another factor to consider in addition to translation quality. The research community, despite its growing focus on novel modeling approaches to simultaneous translation, currently lacks a universal evaluation procedure. Therefore, we present SimulEval, an easy-to-use and general evaluation toolkit for both simultaneous text and speech translation. A server-client scheme is introduced to create a simultaneous translation scenario, where the server sends source input and receives predictions for evaluation and the client executes customized policies. Given a policy, it automatically performs simultaneous decoding and collectively reports several popular latency metrics. We also adapt latency metrics from text simultaneous translation to the speech task. Additionally, SimulEval is equipped with a visualization interface to provide better understanding of the simultaneous decoding process of a system. SimulEval has already been extensively used for the IWSLT 2020 shared task on simultaneous speech translation. Code will be released upon publication.</abstract>
      <url hash="96c543b8">2020.emnlp-demos.19</url>
    </paper>
    <paper id="20">
      <title>Agent Assist through Conversation Analysis</title>
      <author><first>Kshitij</first><last>Fadnis</last></author>
      <author><first>Nathaniel</first><last>Mills</last></author>
      <author><first>Jatin</first><last>Ganhotra</last></author>
      <author><first>Haggai</first><last>Roitman</last></author>
      <author><first>Gaurav</first><last>Pandey</last></author>
      <author><first>Doron</first><last>Cohen</last></author>
      <author><first>Yosi</first><last>Mass</last></author>
      <author><first>Shai</first><last>Erera</last></author>
      <author><first>Chulaka</first><last>Gunasekara</last></author>
      <author><first>Danish</first><last>Contractor</last></author>
      <author><first>Siva</first><last>Patel</last></author>
      <author><first>Q. Vera</first><last>Liao</last></author>
      <author><first>Sachindra</first><last>Joshi</last></author>
      <author><first>Luis</first><last>Lastras</last></author>
      <author><first>David</first><last>Konopnicki</last></author>
      <pages>151–157</pages>
      <abstract>Customer support agents play a crucial role as an interface between an organization and its end-users. We propose CAIRAA: Conversational Approach to Information Retrieval for Agent Assistance, to reduce the cognitive workload of support agents who engage with users through conversation systems. CAIRAA monitors an evolving conversation and recommends both responses and URLs of documents the agent can use in replies to their client. We combine traditional information retrieval (IR) approaches with more recent Deep Learning (DL) models to ensure high accuracy and efficient run-time performance in the deployed system. Here, we describe the CAIRAA system and demonstrate its effectiveness in a pilot study via a short video.</abstract>
      <url hash="d0385ac8">2020.emnlp-demos.20</url>
    </paper>
    <paper id="21">
      <title><fixed-case>N</fixed-case>eu<fixed-case>S</fixed-case>pell: A Neural Spelling Correction Toolkit</title>
      <author><first>Sai Muralidhar</first><last>Jayanthi</last></author>
      <author><first>Danish</first><last>Pruthi</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>158–164</pages>
      <abstract>We introduce NeuSpell, an open-source toolkit for spelling correction in English. Our toolkit comprises ten different models, and benchmarks them on naturally occurring misspellings from multiple sources. We find that many systems do not adequately leverage the context around the misspelt token. To remedy this, (i) we train neural models using spelling errors in context, synthetically constructed by reverse engineering isolated misspellings; and (ii) use richer representations of the context. By training on our synthetic examples, correction rates improve by 9% (absolute) compared to the case when models are trained on randomly sampled character perturbations. Using richer contextual representations boosts the correction rate by another 3%. Our toolkit enables practitioners to use our proposed and existing spelling correction systems, both via a simple unified command line, as well as a web interface. Among many potential applications, we demonstrate the utility of our spell-checkers in combating adversarial misspellings. The toolkit can be accessed at neuspell.github.io.</abstract>
      <url hash="08ed08a1">2020.emnlp-demos.21</url>
    </paper>
    <paper id="22">
      <title><fixed-case>L</fixed-case>ib<fixed-case>KGE</fixed-case> - A knowledge graph embedding library for reproducible research</title>
      <author><first>Samuel</first><last>Broscheit</last></author>
      <author><first>Daniel</first><last>Ruffinelli</last></author>
      <author><first>Adrian</first><last>Kochsiek</last></author>
      <author><first>Patrick</first><last>Betz</last></author>
      <author><first>Rainer</first><last>Gemulla</last></author>
      <pages>165–174</pages>
      <abstract>LibKGE ( https://github.com/uma-pi1/kge ) is an open-source PyTorch-based library for training, hyperparameter optimization, and evaluation of knowledge graph embedding models for link prediction. The key goals of LibKGE are to enable reproducible research, to provide a framework for comprehensive experimental studies, and to facilitate analyzing the contributions of individual components of training methods, model architectures, and evaluation methods. LibKGE is highly configurable and every experiment can be fully reproduced with a single configuration file. Individual components are decoupled to the extent possible so that they can be mixed and matched with each other. Implementations in LibKGE aim to be as efficient as possible without leaving the scope of Python/Numpy/PyTorch. A comprehensive logging mechanism and tooling facilitates in-depth analysis. LibKGE provides implementations of common knowledge graph embedding models and training methods, and new ones can be easily added. A comparative study (Ruffinelli et al., 2020) showed that LibKGE reaches competitive to state-of-the-art performance for many models with a modest amount of automatic hyperparameter tuning.</abstract>
      <url hash="f4badc31">2020.emnlp-demos.22</url>
    </paper>
    <paper id="23">
      <title><fixed-case>W</fixed-case>ant<fixed-case>W</fixed-case>ords: An Open-source Online Reverse Dictionary System</title>
      <author><first>Fanchao</first><last>Qi</last></author>
      <author><first>Lei</first><last>Zhang</last></author>
      <author><first>Yanhui</first><last>Yang</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <pages>175–181</pages>
      <abstract>A reverse dictionary takes descriptions of words as input and outputs words semantically matching the input descriptions. Reverse dictionaries have great practical value such as solving the tip-of-the-tongue problem and helping new language learners. There have been some online reverse dictionary systems, but they support English reverse dictionary queries only and their performance is far from perfect. In this paper, we present a new open-source online reverse dictionary system named WantWords (https://wantwords.thunlp.org/). It not only significantly outperforms other reverse dictionary systems on English reverse dictionary performance, but also supports Chinese and English-Chinese as well as Chinese-English cross-lingual reverse dictionary queries for the first time. Moreover, it has user-friendly front-end design which can help users find the words they need quickly and easily. All the code and data are available at https://github.com/thunlp/WantWords.</abstract>
      <url hash="6735a48a">2020.emnlp-demos.23</url>
    </paper>
    <paper id="24">
      <title><fixed-case>BENNERD</fixed-case>: A Neural Named Entity Linking System for <fixed-case>COVID</fixed-case>-19</title>
      <author><first>Mohammad Golam</first><last>Sohrab</last></author>
      <author><first>Khoa</first><last>Duong</last></author>
      <author><first>Makoto</first><last>Miwa</last></author>
      <author><first>Goran</first><last>Topic</last></author>
      <author><first>Ikeda</first><last>Masami</last></author>
      <author><first>Takamura</first><last>Hiroya</last></author>
      <pages>182–188</pages>
      <abstract>We present a biomedical entity linking (EL) system BENNERD that detects named enti- ties in text and links them to the unified medical language system (UMLS) knowledge base (KB) entries to facilitate the corona virus disease 2019 (COVID-19) research. BEN- NERD mainly covers biomedical domain, es- pecially new entity types (e.g., coronavirus, vi- ral proteins, immune responses) by address- ing CORD-NER dataset. It includes several NLP tools to process biomedical texts includ- ing tokenization, flat and nested entity recog- nition, and candidate generation and rank- ing for EL that have been pre-trained using the CORD-NER corpus. To the best of our knowledge, this is the first attempt that ad- dresses NER and EL on COVID-19-related entities, such as COVID-19 virus, potential vaccines, and spreading mechanism, that may benefit research on COVID-19. We release an online system to enable real-time entity annotation with linking for end users. We also release the manually annotated test set and CORD-NERD dataset for leveraging EL task. The BENNERD system is available at https://aistairc.github.io/BENNERD/.</abstract>
      <url hash="c7aceff6">2020.emnlp-demos.24</url>
    </paper>
    <paper id="25">
      <title><fixed-case>R</fixed-case>o<fixed-case>FT</fixed-case>: A Tool for Evaluating Human Detection of Machine-Generated Text</title>
      <author><first>Liam</first><last>Dugan</last></author>
      <author><first>Daphne</first><last>Ippolito</last></author>
      <author><first>Arun</first><last>Kirubarajan</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>189–196</pages>
      <abstract>In recent years, large neural networks for natural language generation (NLG) have made leaps and bounds in their ability to generate fluent text. However, the tasks of evaluating quality differences between NLG systems and understanding how humans perceive the generated text remain both crucial and difficult. In this system demonstration, we present Real or Fake Text (RoFT), a website that tackles both of these challenges by inviting users to try their hand at detecting machine-generated text in a variety of domains. We introduce a novel evaluation task based on detecting the boundary at which a text passage that starts off human-written transitions to being machine-generated. We show preliminary results of using RoFT to evaluate detection of machine-generated news articles.</abstract>
      <url hash="c09cbdaf">2020.emnlp-demos.25</url>
    </paper>
    <paper id="26">
      <title>A Data-Centric Framework for Composable <fixed-case>NLP</fixed-case> Workflows</title>
      <author><first>Zhengzhong</first><last>Liu</last></author>
      <author><first>Guanxiong</first><last>Ding</last></author>
      <author><first>Avinash</first><last>Bukkittu</last></author>
      <author><first>Mansi</first><last>Gupta</last></author>
      <author><first>Pengzhi</first><last>Gao</last></author>
      <author><first>Atif</first><last>Ahmed</last></author>
      <author><first>Shikun</first><last>Zhang</last></author>
      <author><first>Xin</first><last>Gao</last></author>
      <author><first>Swapnil</first><last>Singhavi</last></author>
      <author><first>Linwei</first><last>Li</last></author>
      <author><first>Wei</first><last>Wei</last></author>
      <author><first>Zecong</first><last>Hu</last></author>
      <author><first>Haoran</first><last>Shi</last></author>
      <author><first>Xiaodan</first><last>Liang</last></author>
      <author><first>Teruko</first><last>Mitamura</last></author>
      <author><first>Eric</first><last>Xing</last></author>
      <author><first>Zhiting</first><last>Hu</last></author>
      <pages>197–204</pages>
      <abstract>Empirical natural language processing (NLP) systems in application domains (e.g., healthcare, finance, education) involve interoperation among multiple components, ranging from data ingestion, human annotation, to text retrieval, analysis, generation, and visualization. We establish a unified open-source framework to support fast development of such sophisticated NLP workflows in a composable manner. The framework introduces a uniform data representation to encode heterogeneous results by a wide range of NLP tasks. It offers a large repository of processors for NLP tasks, visualization, and annotation, which can be easily assembled with full interoperability under the unified representation. The highly extensible framework allows plugging in custom processors from external off-the-shelf NLP and deep learning libraries. The whole framework is delivered through two modularized yet integratable open-source projects, namely Forte (for workflow infrastructure and NLP function processors) and Stave (for user interaction, visualization, and annotation).</abstract>
      <url hash="8483bbe8">2020.emnlp-demos.26</url>
    </paper>
    <paper id="27">
      <title><fixed-case>C</fixed-case>o<fixed-case>R</fixed-case>efi: A Crowd Sourcing Suite for Coreference Annotation</title>
      <author><first>Ari</first><last>Bornstein</last></author>
      <author><first>Arie</first><last>Cattan</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>205–215</pages>
      <abstract>Coreference annotation is an important, yet expensive and time consuming, task, which often involved expert annotators trained on complex decision guidelines. To enable cheaper and more efficient annotation, we present CoRefi, a web-based coreference annotation suite, oriented for crowdsourcing. Beyond the core coreference annotation tool, CoRefi provides guided onboarding for the task as well as a novel algorithm for a reviewing phase. CoRefi is open source and directly embeds into any website, including popular crowdsourcing platforms. CoRefi Demo: aka.ms/corefi Video Tour: aka.ms/corefivideo Github Repo: https://github.com/aribornstein/corefi</abstract>
      <url hash="471da4d2">2020.emnlp-demos.27</url>
    </paper>
    <paper id="28">
      <title>Langsmith: An Interactive Academic Text Revision System</title>
      <author><first>Takumi</first><last>Ito</last></author>
      <author><first>Tatsuki</first><last>Kuribayashi</last></author>
      <author><first>Masatoshi</first><last>Hidaka</last></author>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>216–226</pages>
      <abstract>Despite the current diversity and inclusion initiatives in the academic community, researchers with a non-native command of English still face significant obstacles when writing papers in English. This paper presents the Langsmith editor, which assists inexperienced, non-native researchers to write English papers, especially in the natural language processing (NLP) field. Our system can suggest fluent, academic-style sentences to writers based on their rough, incomplete phrases or sentences. The system also encourages interaction between human writers and the computerized revision system. The experimental results demonstrated that Langsmith helps non-native English-speaker students write papers in English. The system is available at https://emnlp-demo.editor. langsmith.co.jp/.</abstract>
      <url hash="f7cf2024">2020.emnlp-demos.28</url>
    </paper>
    <paper id="29">
      <title><fixed-case>I</fixed-case>s<fixed-case>OBS</fixed-case>: An Information System for Oracle Bone Script</title>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Yuzhuo</first><last>Bai</last></author>
      <author><first>Keyue</first><last>Qiu</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <pages>227–233</pages>
      <abstract>Oracle bone script (OBS) is the earliest known ancient Chinese writing system and the ancestor of modern Chinese. As the Chinese writing system is the oldest continuously-used system in the world, the study of OBS plays an important role in both linguistic and historical research. In order to utilize advanced machine learning methods to automatically process OBS, we construct an information system for OBS (IsOBS) to symbolize, serialize, and store OBS data at the character-level, based on efficient databases and retrieval modules. Moreover, we also apply few-shot learning methods to build an effective OBS character recognition module, which can recognize a large number of OBS characters (especially those characters with a handful of examples) and make the system easy to use. The demo system of IsOBS can be found from <url>http://isobs.thunlp.org/</url>. In the future, we will add more OBS data to the system, and hopefully our IsOBS can support further efforts in automatically processing OBS and advance the scientific progress in this field.</abstract>
      <url hash="3c65079f">2020.emnlp-demos.29</url>
    </paper>
  </volume>
  <volume id="tutorials" ingest-date="2020-11-05">
    <meta>
      <booktitle>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts</booktitle>
      <editor><first>Aline</first><last>Villavicencio</last></editor>
      <editor><first>Benjamin</first><last>Van Durme</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="1434ceba">2020.emnlp-tutorials.0</url>
    </frontmatter>
    <paper id="1">
      <title>Machine Reasoning: Technology, Dilemma and Future</title>
      <author><first>Nan</first><last>Duan</last></author>
      <author><first>Duyu</first><last>Tang</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>1–6</pages>
      <abstract>Machine reasoning research aims to build interpretable AI systems that can solve problems or draw conclusions from what they are told (i.e. facts and observations) and already know (i.e. models, common sense and knowledge) under certain constraints. In this tutorial, we will (1) describe the motivation of this tutorial and give our definition on machine reasoning; (2) introduce typical machine reasoning frameworks, including symbolic reasoning, probabilistic reasoning, neural-symbolic reasoning and neural-evidence reasoning, and show their successful applications in real-world scenarios; (3) talk about the dilemma between black-box neural networks with state-of-the-art performance and machine reasoning approaches with better interpretability; (4) summarize the content of this tutorial and discuss possible future directions.</abstract>
      <url hash="2e04e2c0">2020.emnlp-tutorials.1</url>
    </paper>
    <paper id="2">
      <title>Fact-Checking, Fake News, Propaganda, and Media Bias: Truth Seeking in the Post-Truth Era</title>
      <author><first>Preslav</first><last>Nakov</last></author>
      <author><first>Giovanni</first><last>Da San Martino</last></author>
      <pages>7–19</pages>
      <abstract>The rise of social media has democratized content creation and has made it easy for everybody to share and spread information online. On the positive side, this has given rise to citizen journalism, thus enabling much faster dissemination of information compared to what was possible with newspapers, radio, and TV. On the negative side, stripping traditional media from their gate-keeping role has left the public unprotected against the spread of misinformation, which could now travel at breaking-news speed over the same democratic channel. This has given rise to the proliferation of false information specifically created to affect individual people’s beliefs, and ultimately to influence major events such as political elections. There are strong indications that false information was weaponized at an unprecedented scale during Brexit and the 2016 U.S. presidential elections. “Fake news,” which can be defined as fabricated information that mimics news media content in form but not in organizational process or intent, became the Word of the Year for 2017, according to Collins Dictionary. Thus, limiting the spread of “fake news” and its impact has become a major focus for computer scientists, journalists, social media companies, and regulatory authorities. The tutorial will offer an overview of the broad and emerging research area of disinformation, with focus on the latest developments and research directions.</abstract>
      <url hash="a657ae1b">2020.emnlp-tutorials.2</url>
    </paper>
    <paper id="3">
      <title>Interpreting Predictions of <fixed-case>NLP</fixed-case> Models</title>
      <author><first>Eric</first><last>Wallace</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <author><first>Sameer</first><last>Singh</last></author>
      <pages>20–23</pages>
      <abstract>Although neural NLP models are highly expressive and empirically successful, they also systematically fail in counterintuitive ways and are opaque in their decision-making process. This tutorial will provide a background on interpretation techniques, i.e., methods for explaining the predictions of NLP models. We will first situate example-specific interpretations in the context of other ways to understand models (e.g., probing, dataset analyses). Next, we will present a thorough study of example-specific interpretations, including saliency maps, input perturbations (e.g., LIME, input reduction), adversarial attacks, and influence functions. Alongside these descriptions, we will walk through source code that creates and visualizes interpretations for a diverse set of NLP tasks. Finally, we will discuss open problems in the field, e.g., evaluating, extending, and improving interpretation methods.</abstract>
      <url hash="d38f363f">2020.emnlp-tutorials.3</url>
    </paper>
    <paper id="4">
      <title>High Performance Natural Language Processing</title>
      <author><first>Gabriel</first><last>Ilharco</last></author>
      <author><first>Cesar</first><last>Ilharco</last></author>
      <author><first>Iulia</first><last>Turc</last></author>
      <author><first>Tim</first><last>Dettmers</last></author>
      <author><first>Felipe</first><last>Ferreira</last></author>
      <author><first>Kenton</first><last>Lee</last></author>
      <pages>24–27</pages>
      <abstract>Scale has played a central role in the rapid progress natural language processing has enjoyed in recent years. While benchmarks are dominated by ever larger models, efficient hardware use is critical for their widespread adoption and further progress in the field. In this cutting-edge tutorial, we will recapitulate the state-of-the-art in natural language processing with scale in perspective. After establishing these foundations, we will cover a wide range of techniques for improving efficiency, including knowledge distillation, quantization, pruning, more efficient architectures, along with case studies and practical implementation tricks.</abstract>
      <url hash="2eba1327">2020.emnlp-tutorials.4</url>
    </paper>
    <paper id="5">
      <title>Representation, Learning and Reasoning on Spatial Language for Downstream <fixed-case>NLP</fixed-case> Tasks</title>
      <author><first>Parisa</first><last>Kordjamshidi</last></author>
      <author><first>James</first><last>Pustejovsky</last></author>
      <author><first>Marie-Francine</first><last>Moens</last></author>
      <pages>28–33</pages>
      <abstract>Understating spatial semantics expressed in natural language can become highly complex in real-world applications. This includes applications of language grounding, navigation, visual question answering, and more generic human-machine interaction and dialogue systems. In many of such downstream tasks, explicit representation of spatial concepts and relationships can improve the capabilities of machine learning models in reasoning and deep language understanding. In this tutorial, we overview the cutting-edge research results and existing challenges related to spatial language understanding including semantic annotations, existing corpora, symbolic and sub-symbolic representations, qualitative spatial reasoning, spatial common sense, deep and structured learning models. We discuss the recent results on the above-mentioned applications –that need spatial language learning and reasoning – and highlight the research gaps and future directions.</abstract>
      <url hash="870c860b">2020.emnlp-tutorials.5</url>
    </paper>
    <paper id="6">
      <title>Simultaneous Translation</title>
      <author><first>Liang</first><last>Huang</last></author>
      <author><first>Colin</first><last>Cherry</last></author>
      <author><first>Mingbo</first><last>Ma</last></author>
      <author><first>Naveen</first><last>Arivazhagan</last></author>
      <author><first>Zhongjun</first><last>He</last></author>
      <pages>34–36</pages>
      <abstract>Simultaneous translation, which performs translation concurrently with the source speech, is widely useful in many scenarios such as international conferences, negotiations, press releases, legal proceedings, and medicine. This problem has long been considered one of the hardest problems in AI and one of its holy grails. Recently, with rapid improvements in machine translation, speech recognition, and speech synthesis, there has been exciting progress towards simultaneous translation. This tutorial will focus on the design and evaluation of policies for simultaneous translation, to leave attendees with a deep technical understanding of the history, the recent advances, and the remaining challenges in this field.</abstract>
      <url hash="75bb7259">2020.emnlp-tutorials.6</url>
    </paper>
    <paper id="7">
      <title>The Amazing World of Neural Language Generation</title>
      <author><first>Yangfeng</first><last>Ji</last></author>
      <author><first>Antoine</first><last>Bosselut</last></author>
      <author><first>Thomas</first><last>Wolf</last></author>
      <author><first>Asli</first><last>Celikyilmaz</last></author>
      <pages>37–42</pages>
      <abstract>Neural Language Generation (NLG) – using neural network models to generate coherent text – is among the most promising methods for automated text creation. Recent years have seen a paradigm shift in neural text generation, caused by the advances in deep contextual language modeling (e.g., LSTMs, GPT, GPT2) and transfer learning (e.g., ELMo, BERT). While these tools have dramatically improved the state of NLG, particularly for low resources tasks, state-of-the-art NLG models still face many challenges: a lack of diversity in generated text, commonsense violations in depicted situations, difficulties in making use of factual information, and difficulties in designing reliable evaluation metrics. In this tutorial, we will present an overview of the current state-of-the-art in neural network architectures, and how they shaped recent research directions in text generation. We will discuss how and why these models succeed/fail at generating coherent text, and provide insights on several applications.</abstract>
      <url hash="15b4fef1">2020.emnlp-tutorials.7</url>
    </paper>
  </volume>
</collection>
