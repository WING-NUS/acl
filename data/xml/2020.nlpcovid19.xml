<?xml version='1.0' encoding='UTF-8'?>
<collection id="2020.nlpcovid19">
  <volume id="acl" ingest-date="2020-10-13">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on <fixed-case>NLP</fixed-case> for <fixed-case>COVID-19</fixed-case></booktitle>
      <editor><first>Karin</first><last>Verspoor</last></editor>
      <editor><first>Kevin Bretonnel</first><last>Cohen</last></editor>
      <editor><first>Mark</first><last>Dredze</last></editor>
      <editor><first>Emilio</first><last>Ferrara</last></editor>
      <editor><first>Jonathan</first><last>May</last></editor>
      <editor><first>Robert</first><last>Munro</last></editor>
      <editor><first>Cecile</first><last>Paris</last></editor>
      <editor><first>Byron</first><last>Wallace</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>July</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="fddac610">2020.nlpcovid19-acl.0</url>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>CORD-19</fixed-case>: The <fixed-case>COVID-19</fixed-case> Open Research Dataset</title>
      <author><first>Lucy Lu</first><last>Wang</last></author>
      <author><first>Kyle</first><last>Lo</last></author>
      <author><first>Yoganand</first><last>Chandrasekhar</last></author>
      <author><first>Russell</first><last>Reas</last></author>
      <author><first>Jiangjiang</first><last>Yang</last></author>
      <author><first>Doug</first><last>Burdick</last></author>
      <author><first>Darrin</first><last>Eide</last></author>
      <author><first>Kathryn</first><last>Funk</last></author>
      <author><first>Yannis</first><last>Katsis</last></author>
      <author><first>Rodney Michael</first><last>Kinney</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>Ziyang</first><last>Liu</last></author>
      <author><first>William</first><last>Merrill</last></author>
      <author><first>Paul</first><last>Mooney</last></author>
      <author><first>Dewey A.</first><last>Murdick</last></author>
      <author><first>Devvret</first><last>Rishi</last></author>
      <author><first>Jerry</first><last>Sheehan</last></author>
      <author><first>Zhihong</first><last>Shen</last></author>
      <author><first>Brandon</first><last>Stilson</last></author>
      <author><first>Alex D.</first><last>Wade</last></author>
      <author><first>Kuansan</first><last>Wang</last></author>
      <author><first>Nancy Xin Ru</first><last>Wang</last></author>
      <author><first>Christopher</first><last>Wilhelm</last></author>
      <author><first>Boya</first><last>Xie</last></author>
      <author><first>Douglas M.</first><last>Raymond</last></author>
      <author><first>Daniel S.</first><last>Weld</last></author>
      <author><first>Oren</first><last>Etzioni</last></author>
      <author><first>Sebastian</first><last>Kohlmeier</last></author>
      <abstract>The COVID-19 Open Research Dataset (CORD-19) is a growing resource of scientific papers on COVID-19 and related historical coronavirus research. CORD-19 is designed to facilitate the development of text mining and information retrieval systems over its rich collection of metadata and structured full text papers. Since its release, CORD-19 has been downloaded over 200K times and has served as the basis of many COVID-19 text mining and discovery systems. In this article, we describe the mechanics of dataset construction, highlighting challenges and key design decisions, provide an overview of how CORD-19 has been used, and describe several shared tasks built around the dataset. We hope this resource will continue to bring together the computing community, biomedical experts, and policy makers in the search for effective treatments and management policies for COVID-19.</abstract>
      <url hash="f3ee0bb6">2020.nlpcovid19-acl.1</url>
    </paper>
    <paper id="2">
      <title>Rapidly Deploying a Neural Search Engine for the <fixed-case>COVID-19</fixed-case> <fixed-case>Open</fixed-case> <fixed-case>Research</fixed-case> <fixed-case>Dataset</fixed-case></title>
      <author><first>Edwin</first><last>Zhang</last></author>
      <author><first>Nikhil</first><last>Gupta</last></author>
      <author><first>Rodrigo</first><last>Nogueira</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <author><first>Jimmy</first><last>Lin</last></author>
      <abstract>The Neural Covidex is a search engine that exploits the latest neural ranking architectures to provide information access to the COVID-19 Open Research Dataset (CORD-19) curated by the Allen Institute for AI. It exists as part of a suite of tools we have developed to help domain experts tackle the ongoing global pandemic. We hope that improved information access capabilities to the scientific literature can inform evidence-based decision making and insight generation.</abstract>
      <url hash="5ecb67c9">2020.nlpcovid19-acl.2</url>
    </paper>
    <paper id="3">
      <title>Document Classification for <fixed-case>COVID-19</fixed-case> Literature</title>
      <author><first>Bernal</first><last>Jiménez Gutiérrez</last></author>
      <author><first>Juncheng</first><last>Zeng</last></author>
      <author><first>Dongdong</first><last>Zhang</last></author>
      <author><first>Ping</first><last>Zhang</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <abstract>The global pandemic has made it more important than ever to quickly and accurately retrieve relevant scientific literature for effective consumption by researchers in a wide range of fields. We provide an analysis of several multi-label document classification models on the LitCovid dataset. We find that pre-trained language models outperform other models in both low and high data regimes, achieving a maximum F1 score of around 86%. We note that even the highest performing models still struggle with label correlation, distraction from introductory text and CORD-19 generalization. Both data and code are available on GitHub.</abstract>
      <url hash="e5936d8e">2020.nlpcovid19-acl.3</url>
    </paper>
    <paper id="4">
      <title>Enabling Low-Resource Transfer Learning across <fixed-case>COVID-19</fixed-case> Corpora by Combining Event-Extraction and Co-Training</title>
      <author><first>Alexander</first><last>Spangher</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <author><first>Jonathan</first><last>May</last></author>
      <author><first>Emilio</first><last>Ferrara</last></author>
      <url hash="55e5fca9">2020.nlpcovid19-acl.4</url>
    </paper>
    <paper id="5">
      <title>Self-supervised context-aware <fixed-case>COVID-19</fixed-case> document exploration through atlas grounding</title>
      <author><first>Dusan</first><last>Grujicic</last></author>
      <author><first>Gorjan</first><last>Radevski</last></author>
      <author><first>Tinne</first><last>Tuytelaars</last></author>
      <author><first>Matthew</first><last>Blaschko</last></author>
      <abstract>In this paper, we aim to develop a self-supervised grounding of Covid-related medical text based on the actual spatial relationships between the referred anatomical concepts. More specifically, we learn to project sentences into a physical space defined by a three-dimensional anatomical atlas, allowing for a visual approach to navigating Covid-related literature. We design a straightforward and empirically effective training objective to reduce the curated data dependency issue. We use BERT as the main building block of our model and perform a quantitative analysis that demonstrates that the model learns a context-aware mapping. We illustrate two potential use-cases for our approach, one in interactive, 3D data exploration, and the other in document retrieval. To accelerate research in this direction, we make public all trained models, codebase and the developed tools, which can be accessed at https://github.com/gorjanradevski/macchina/.</abstract>
      <url hash="ea5b60e4">2020.nlpcovid19-acl.5</url>
    </paper>
    <paper id="6">
      <title><fixed-case>CODA-19</fixed-case>: Using a Non-Expert Crowd to Annotate Research Aspects on 10,000+ Abstracts in the <fixed-case>COVID-19</fixed-case> Open Research Dataset</title>
      <author><first>Ting-Hao Kenneth</first><last>Huang</last></author>
      <author><first>Chieh-Yang</first><last>Huang</last></author>
      <author><first>Chien-Kuang Cornelia</first><last>Ding</last></author>
      <author><first>Yen-Chia</first><last>Hsu</last></author>
      <author><first>C Lee</first><last>Giles</last></author>
      <abstract>This paper introduces CODA-19, a human-annotated dataset that codes the Background, Purpose, Method, Finding/Contribution, and Other sections of 10,966 English abstracts in the COVID-19 Open Research Dataset. CODA-19 was created by 248 crowd workers from Amazon Mechanical Turk within 10 days, and achieved labeling quality comparable to that of experts. Each abstract was annotated by nine different workers, and the final labels were acquired by majority vote. The inter-annotator agreement (Cohen’s kappa) between the crowd and the biomedical expert (0.741) is comparable to inter-expert agreement (0.788). CODA-19’s labels have an accuracy of 82.2% when compared to the biomedical expert’s labels, while the accuracy between experts was 85.0%. Reliable human annotations help scientists access and integrate the rapidly accelerating coronavirus literature, and also serve as the battery of AI/NLP research, but obtaining expert annotations can be slow. We demonstrated that a non-expert crowd can be rapidly employed at scale to join the fight against COVID-19.</abstract>
      <url hash="549ba9fe">2020.nlpcovid19-acl.6</url>
    </paper>
    <paper id="7">
      <title>Information Retrieval and Extraction on <fixed-case>COVID-19</fixed-case> Clinical Articles Using Graph Community Detection and <fixed-case>Bio-BERT</fixed-case> Embeddings</title>
      <author><first>Debasmita</first><last>Das</last></author>
      <author><first>Yatin</first><last>Katyal</last></author>
      <author><first>Janu</first><last>Verma</last></author>
      <author><first>Shashank</first><last>Dubey</last></author>
      <author><first>AakashDeep</first><last>Singh</last></author>
      <author><first>Kushagra</first><last>Agarwal</last></author>
      <author><first>Sourojit</first><last>Bhaduri</last></author>
      <author><first>RajeshKumar</first><last>Ranjan</last></author>
      <abstract>In this paper, we present an information retrieval system on a corpus of scientific articles related to COVID-19. We build a similarity network on the articles where similarity is determined via shared citations and biological domain-specific sentence embeddings. Ego-splitting community detection on the article network is employed to cluster the articles and then the queries are matched with the clusters. Extractive summarization using BERT and PageRank methods is used to provide responses to the query. We also provide a Question-Answer bot on a small set of intents to demonstrate the efficacy of our model for an information extraction module.</abstract>
      <url hash="689b3e4a">2020.nlpcovid19-acl.7</url>
    </paper>
    <paper id="8">
      <title>What Are People Asking About <fixed-case>COVID-19</fixed-case>? A Question Classification Dataset</title>
      <author><first>Jerry</first><last>Wei</last></author>
      <author><first>Chengyu</first><last>Huang</last></author>
      <author><first>Soroush</first><last>Vosoughi</last></author>
      <author><first>Jason</first><last>Wei</last></author>
      <abstract>We present COVID-Q, a set of 1,690 questions about COVID-19 from 13 sources, which we annotate into 15 question categories and 207 question clusters. The most common questions in our dataset asked about transmission, prevention, and societal effects of COVID, and we found that many questions that appeared in multiple sources were not answered by any FAQ websites of reputable organizations such as the CDC and FDA. We post our dataset publicly at https://github.com/JerryWei03/COVID-Q. For classifying questions into 15 categories, a BERT baseline scored 58.1% accuracy when trained on 20 examples per category, and for a question clustering task, a BERT + triplet loss baseline achieved 49.5% accuracy. We hope COVID-Q can help either for direct use in developing applied systems or as a domain-specific resource for model evaluation.</abstract>
      <url hash="490f073d">2020.nlpcovid19-acl.8</url>
    </paper>
    <paper id="9">
      <title>Jennifer for <fixed-case>COVID-19</fixed-case>: An <fixed-case>NLP</fixed-case>-Powered Chatbot Built for the People and by the People to Combat Misinformation</title>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>Tyrone</first><last>Grandison</last></author>
      <author><first>Patricia</first><last>Silveyra</last></author>
      <author><first>Ali</first><last>Douraghy</last></author>
      <author><first>Xinyu</first><last>Guan</last></author>
      <author><first>Thomas</first><last>Kieselbach</last></author>
      <author><first>Chengkai</first><last>Li</last></author>
      <author><first>Haiqi</first><last>Zhang</last></author>
      <abstract>Just as SARS-CoV-2, a new form of coronavirus continues to infect a growing number of people around the world, harmful misinformation about the outbreak also continues to spread. With the goal of combating misinformation, we designed and built Jennifer–a chatbot maintained by a global group of volunteers. With Jennifer, we hope to learn whether public information from reputable sources could be more effectively organized and shared in the wake of a crisis as well as to understand issues that the public were most immediately curious about. In this paper, we introduce Jennifer and describe the design of this proof-of-principle system. We also present lessons learned and discuss open challenges. Finally, to facilitate future research, we release COVID-19 Question Bank, a dataset of 3,924 COVID-19-related questions in 944 groups, gathered from our users and volunteers.</abstract>
      <url hash="375d78fd">2020.nlpcovid19-acl.9</url>
    </paper>
    <paper id="10">
      <title>A Natural Language Processing System for National <fixed-case>COVID-19</fixed-case> Surveillance in the <fixed-case>US Department of Veterans Affairs</fixed-case></title>
      <author><first>Alec</first><last>Chapman</last></author>
      <author><first>Kelly</first><last>Peterson</last></author>
      <author><first>Augie</first><last>Turano</last></author>
      <author><first>Tamára</first><last>Box</last></author>
      <author><first>Katherine</first><last>Wallace</last></author>
      <author><first>Makoto</first><last>Jones</last></author>
      <abstract>Timely and accurate accounting of positive cases has been an important part of the response to the COVID-19 pandemic. While most positive cases within Veterans Affairs (VA) are identified through structured laboratory results, some patients are tested or diagnosed outside VA so their clinical status is documented only in free-text narratives. We developed a Natural Language Processing pipeline for identifying positively diagnosed COVID19 patients and deployed this system to accelerate chart review. As part of the VA national response to COVID-19, this process identified 6,360 positive cases which did not have corresponding laboratory data. These cases accounted for 36.1% of total confirmed positive cases in VA to date. With available data, performance of the system is estimated as 82.4% precision and 94.2% recall. A public-facing implementation is released as open source and available to the community.</abstract>
      <url hash="cf291cd4">2020.nlpcovid19-acl.10</url>
    </paper>
    <paper id="11">
      <title>Measuring <fixed-case>Emotions</fixed-case> in the <fixed-case>COVID</fixed-case>-19 <fixed-case>Real</fixed-case> <fixed-case>World</fixed-case> <fixed-case>Worry</fixed-case> <fixed-case>Dataset</fixed-case></title>
      <author><first>Bennett</first><last>Kleinberg</last></author>
      <author><first>Isabelle</first><last>van der Vegt</last></author>
      <author><first>Maximilian</first><last>Mozes</last></author>
      <abstract>The COVID-19 pandemic is having a dramatic impact on societies and economies around the world. With various measures of lockdowns and social distancing in place, it becomes important to understand emotional responses on a large scale. In this paper, we present the first ground truth dataset of emotional responses to COVID-19. We asked participants to indicate their emotions and express these in text. This resulted in the Real World Worry Dataset of 5,000 texts (2,500 short + 2,500 long texts). Our analyses suggest that emotional responses correlated with linguistic measures. Topic modeling further revealed that people in the UK worry about their family and the economic situation. Tweet-sized texts functioned as a call for solidarity, while longer texts shed light on worries and concerns. Using predictive modeling approaches, we were able to approximate the emotional responses of participants from text within 14% of their actual value. We encourage others to use the dataset and improve how we can use automated methods to learn about emotional responses and worries about an urgent problem.</abstract>
      <url hash="3d5f99d0">2020.nlpcovid19-acl.11</url>
    </paper>
    <paper id="12">
      <title>Estimating the effect of <fixed-case>COVID-19</fixed-case> on mental health: Linguistic indicators of depression during a global pandemic</title>
      <author><first>JT</first><last>Wolohan</last></author>
      <abstract>This preliminary analysis uses a deep LSTM neural network with fastText embeddings to predict population rates of depression on Reddit in order to estimate the effect of COVID-19 on mental health. We find that year over year, depression rates on Reddit are up 50% , suggesting a 15-million person increase in the number of depressed Americans and a $7.5 billion increase in depression related spending. This finding suggests that utility in NLP approaches to longitudinal public-health surveillance.</abstract>
      <url hash="9bd09de3">2020.nlpcovid19-acl.12</url>
    </paper>
    <paper id="13">
      <title>Exploration of Gender Differences in <fixed-case>COVID-19</fixed-case> Discourse on <fixed-case>R</fixed-case>eddit</title>
      <author><first>Jai</first><last>Aggarwal</last></author>
      <author><first>Ella</first><last>Rabinovich</last></author>
      <author><first>Suzanne</first><last>Stevenson</last></author>
      <abstract>Decades of research on differences in the language of men and women have established postulates about the nature of lexical, topical, and emotional preferences between the two genders, along with their sociological underpinnings. Using a novel dataset of male and female linguistic productions collected from the Reddit discussion platform, we further confirm existing assumptions about gender-linked affective distinctions, and demonstrate that these distinctions are amplified in social media postings involving emotionally-charged discourse related to COVID-19. Our analysis also confirms considerable differences in topical preferences between male and female authors in pandemic-related discussions.</abstract>
      <url hash="a2380764">2020.nlpcovid19-acl.13</url>
    </paper>
    <paper id="14">
      <title>Cross-language sentiment analysis of <fixed-case>European</fixed-case> <fixed-case>Twitter</fixed-case> messages during the <fixed-case>COVID-19</fixed-case> pandemic</title>
      <author><first>Anna</first><last>Kruspe</last></author>
      <author><first>Matthias</first><last>Häberle</last></author>
      <author><first>Iona</first><last>Kuhn</last></author>
      <author><first>Xiao Xiang</first><last>Zhu</last></author>
      <abstract>In this paper, we analyze Twitter messages (tweets) collected during the first months of the COVID-19 pandemic in Europe with regard to their sentiment. This is implemented with a neural network for sentiment analysis using multilingual sentence embeddings. We separate the results by country of origin, and correlate their temporal development with events in those countries. This allows us to study the effect of the situation on people’s moods. We see, for example, that lockdown announcements correlate with a deterioration of mood in almost all surveyed countries, which recovers within a short time span.</abstract>
      <url hash="10474aa7">2020.nlpcovid19-acl.14</url>
    </paper>
    <paper id="15">
      <title>Cross-lingual Transfer Learning for <fixed-case>COVID-19</fixed-case> Outbreak Alignment</title>
      <author><first>Sharon</first><last>Levy</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <abstract>The spread of COVID-19 has become a significant and troubling aspect of society in 2020. With millions of cases reported across countries, new outbreaks have occurred and followed patterns of previously affected areas. Many disease detection models do not incorporate the wealth of social media data that can be utilized for modeling and predicting its spread. It is useful to ask, can we utilize this knowledge in one country to model the outbreak in another? To answer this, we propose the task of cross-lingual transfer learning for epidemiological alignment. Utilizing both macro and micro text features, we train on Italy’s early COVID-19 outbreak through Twitter and transfer to several other countries. Our experiments show strong results with up to 0.85 Spearman correlation in cross-country predictions.</abstract>
      <url hash="b944647e">2020.nlpcovid19-acl.15</url>
    </paper>
    <paper id="16">
      <title><fixed-case>COVID-19</fixed-case> and <fixed-case>Arabic</fixed-case> <fixed-case>Twitter</fixed-case>: How can <fixed-case>Arab</fixed-case> World Governments and Public Health Organizations Learn from Social Media?</title>
      <author><first>Lama</first><last>Alsudias</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <abstract>In March 2020, the World Health Organization announced the COVID-19 outbreak as a pandemic. Most previous social media related research has been on English tweets and COVID-19. In this study, we collect approximately 1 million Arabic tweets from the Twitter streaming API related to COVID-19. Focussing on outcomes that we believe will be useful for Public Health Organizations, we analyse them in three different ways: identifying the topics discussed during the period, detecting rumours, and predicting the source of the tweets. We use the k-means algorithm for the first goal with k=5. The topics discussed can be grouped as follows: COVID-19 statistics, prayers for God, COVID-19 locations, advise and education for prevention, and advertising. We sample 2000 tweets and label them manually for false information, correct information, and unrelated. Then, we apply three different machine learning algorithms, Logistic Regression, Support Vector Classification, and Naïve Bayes with two sets of features, word frequency approach and word embeddings. We find that Machine Learning classifiers are able to correctly identify the rumour related tweets with 84% accuracy. We also try to predict the source of the rumour related tweets depending on our previous model which is about classifying tweets into five categories: academic, media, government, health professional, and public. Around (60%) of the rumour related tweets are classified as written by health professionals and academics.</abstract>
      <url hash="f2d170a8">2020.nlpcovid19-acl.16</url>
    </paper>
    <paper id="17">
      <title><fixed-case>NLP</fixed-case>-based Feature Extraction for the Detection of <fixed-case>COVID</fixed-case>-19 Misinformation Videos on <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube</title>
      <author><first>Juan Carlos Medina</first><last>Serrano</last></author>
      <author><first>Orestis</first><last>Papakyriakopoulos</last></author>
      <author><first>Simon</first><last>Hegelich</last></author>
      <abstract>We present a simple NLP methodology for detecting COVID-19 misinformation videos on YouTube by leveraging user comments. We use transfer learning pre-trained models to generate a multi-label classifier that can categorize conspiratorial content. We use the percentage of misinformation comments on each video as a new feature for video classification.</abstract>
      <url hash="2520463f">2020.nlpcovid19-acl.17</url>
    </paper>
  </volume>
</collection>
